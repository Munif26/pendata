
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Pengenalan Clustering dan K-Means &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'algoritma_k-means_clustering';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="üìù UTS Penambangan Data - Klasifikasi Prediksi Survival Pasien Sirosis" href="proyek_ujiantengahsemester.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="My sample book - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="My sample book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to Penambangan Data
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="data_understanding.html"><strong>Data Understanding</strong></a></li>






<li class="toctree-l1"><a class="reference internal" href="outlier_detection.html"><strong>Outliers Detection Menggunakan Metode K-Nearest Neighbors (KNN)</strong></a></li>






<li class="toctree-l1"><a class="reference internal" href="local_outlier_factor_%28lof%29.html"><strong>Local Outlier Factor (LOF)</strong></a></li>







<li class="toctree-l1"><a class="reference internal" href="klasifikasi_naive_bayes.html"><strong>Klasifikasi Naive Bayes</strong></a></li>






<li class="toctree-l1"><a class="reference internal" href="proyek_ujiantengahsemester.html"><strong>üìù UTS Penambangan Data - Klasifikasi Prediksi Survival Pasien Sirosis</strong></a></li>



<li class="toctree-l1 current active"><a class="current reference internal" href="#"><strong>Pengenalan Clustering dan K-Means</strong></a></li>





</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Falgoritma_k-means_clustering.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/algoritma_k-means_clustering.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Pengenalan Clustering dan K-Means</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#"><strong>Pengenalan Clustering dan K-Means</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#apa-itu-clustering"><strong>Apa Itu Clustering‚Ä¶?</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#algoritma-k-means"><strong>Algoritma K-Means</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluasi-kualitas-clustering"><strong>Evaluasi Kualitas Clustering</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#implementasi-algoritma-k-means-menggunakan-python"><strong>Implementasi Algoritma K-Means Menggunakan Python</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#install-library-yang-dibutuhkan"><strong>1. Install Library yang dibutuhkan</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mengambil-database-dari-dbever"><strong>2. Mengambil Database dari DBever</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#menghilangkan-species-labelnya"><strong>3. Menghilangkan species / labelnya</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#clustering-pada-data-iris-menggunakan-k-means-dengan-jumlah-cluster-2"><strong>4. Clustering pada data Iris menggunakan K-Means dengan jumlah cluster 2</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#clustering-pada-data-iris-menggunakan-k-means-dengan-jumlah-cluster-3"><strong>5. Clustering pada data Iris menggunakan K-Means dengan jumlah cluster 3</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#clustering-pada-data-iris-menggunakan-k-means-dengan-jumlah-cluster-4"><strong>6. Clustering pada data Iris menggunakan K-Means dengan jumlah cluster 4</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kesimpulan"><strong>7. Kesimpulan</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metode-elbow"><strong>8. Metode Elbow</strong></a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#pengenalan-fuzzy-c-means"><strong>Pengenalan Fuzzy C-Means</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#konsep-fuzzy-c-means"><strong>Konsep Fuzzy C-Means</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-algoritma"><strong>Langkah Algoritma</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#contoh-penerapan-dalam-bentuk-code"><strong>Contoh penerapan dalam bentuk code</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementasi-kedalam-data-iris"><strong>Implementasi Kedalam Data Iris</strong></a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="pengenalan-clustering-dan-k-means">
<h1><strong>Pengenalan Clustering dan K-Means</strong><a class="headerlink" href="#pengenalan-clustering-dan-k-means" title="Link to this heading">#</a></h1>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="apa-itu-clustering">
<h1><strong>Apa Itu Clustering‚Ä¶?</strong><a class="headerlink" href="#apa-itu-clustering" title="Link to this heading">#</a></h1>
<p>Clustering adalah salah satu metode dalam unsupervised learning yang bertujuan untuk mengelompokkan sekumpulan data berdasarkan kemiripan karakteristik antar data. Dalam clustering, tidak ada label atau target output yang digunakan ‚Äî proses ini bersifat eksploratif, membantu kita memahami struktur atau pola tersembunyi dalam data.</p>
<p>Tujuan Clustering
Menemukan pola tersembunyi di data.</p>
<p>Mengelompokkan data berdasarkan kemiripan.</p>
<p>Membantu dalam pengambilan keputusan atau pemodelan lebih lanjut.</p>
<p>Clustering sangat bermanfaat dalam tahap eksplorasi data karena dapat memberikan gambaran tentang berapa banyak kelompok alami yang ada dalam dataset. Idealnya, data dalam satu klaster memiliki variansi internal yang kecil (homogen), sementara variansi antar klaster harus besar (heterogen).</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="algoritma-k-means">
<h1><strong>Algoritma K-Means</strong><a class="headerlink" href="#algoritma-k-means" title="Link to this heading">#</a></h1>
<p>K-Means adalah algoritma clustering berbasis centroid yang bekerja dengan cara mempartisi data ke dalam sejumlah klaster yang telah ditentukan sebelumnya (disebut k). Setiap klaster direpresentasikan oleh satu titik pusat yang disebut centroid. Tujuan dari algoritma ini adalah untuk meminimalkan jarak rata-rata antar data dengan centroid klasternya masing-masing.</p>
<p>Cara Kerja K-Means
Berikut adalah langkah-langkah dari algoritma K-Means:</p>
<ol class="arabic simple">
<li><p>Menentukan jumlah klaster k: Langkah awal adalah menetapkan berapa banyak kelompok (klaster) yang ingin dibentuk dari data.</p></li>
<li><p>Inisialisasi centroid: Sebanyak k centroid awal dipilih secara acak dari data.</p></li>
<li><p>Pengelompokan data:</p></li>
</ol>
<ul class="simple">
<li><p>Hitung jarak antara setiap data ke semua centroid menggunakan metrik seperti Euclidean Distance.</p></li>
<li><p>Setiap data akan dimasukkan ke klaster dengan centroid terdekat.</p></li>
</ul>
<ol class="arabic simple" start="4">
<li><p>Perbarui posisi centroid:</p></li>
</ol>
<ul class="simple">
<li><p>Hitung rata-rata dari semua data dalam tiap klaster, dan tetapkan hasilnya sebagai centroid baru.</p></li>
</ul>
<ol class="arabic simple" start="5">
<li><p>Iterasi:</p></li>
</ol>
<ul class="simple">
<li><p>Ulangi proses pengelompokan dan pembaruan centroid hingga data tidak berpindah klaster lagi atau centroid tidak berubah (konvergen).</p></li>
</ul>
<p>Catatan Penting :</p>
<ul class="simple">
<li><p>K-Means sensitif terhadap outlier. Kehadiran data ekstrem bisa sangat mempengaruhi posisi centroid.</p></li>
<li><p>K-Means bekerja optimal jika data memiliki bentuk klaster bulat/simetris dan berukuran seragam.</p></li>
</ul>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="evaluasi-kualitas-clustering">
<h1><strong>Evaluasi Kualitas Clustering</strong><a class="headerlink" href="#evaluasi-kualitas-clustering" title="Link to this heading">#</a></h1>
<ol class="arabic simple">
<li><p>Sum of Squared Error (SSE)
SSE mengukur jumlah kuadrat jarak antara data dengan centroid klasternya. Nilai SSE yang kecil menandakan bahwa data dalam klaster saling berdekatan (kompak).</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
SSE = \sum_{i=1}^{k} \sum_{x \in C_i} ||x - \mu_i||^2
\]</div>
<p>Keterangan:</p>
<p>ùê∂
ùëñ
C
i
‚Äã
: Klaster ke-i</p>
<p>ùúá
ùëñ
Œº
i
‚Äã
: Centroid dari klaster ke-i</p>
<p>‚à£
‚à£
ùë•
‚àí
ùúá
ùëñ
‚à£
‚à£
2
‚à£‚à£x‚àíŒº
i
‚Äã
‚à£‚à£
2
: Jarak Euclidean kuadrat antara data
ùë•
x dengan centroid
ùúá
ùëñ
Œº
i
‚Äã</p>
<ol class="arabic simple" start="2">
<li><p>Silhouette Score
Silhouette Score menunjukkan seberapa baik suatu data cocok dalam klasternya. Nilainya berkisar antara -1 hingga 1.</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
S = \frac{b - a}{\max(a, b)}
\]</div>
<p>Keterangan:</p>
<p>ùëé
a: Rata-rata jarak antara data dan seluruh anggota klasternya (intra-cluster distance)</p>
<p>ùëè
b: Rata-rata jarak antara data dan anggota klaster terdekat lainnya (nearest-cluster distance)</p>
<p>ùëÜ
S: Nilai silhouette</p>
<p>Interpretasi nilai:</p>
<p>ùëÜ
‚âà
1
S‚âà1: Data sangat cocok dengan klasternya</p>
<p>ùëÜ
‚âà
0
S‚âà0: Data berada di antara dua klaster</p>
<p>ùëÜ
&lt;
0
S&lt;0: Data mungkin salah klaster</p>
<p>Kesimpulan :</p>
<ul class="simple">
<li><p>Evaluasi menggunakan SSE dan Silhouette Score penting untuk menilai kualitas klastering.</p></li>
<li><p>Untuk menentukan jumlah klaster yang optimal, gunakan:</p></li>
<li><p>Metode Elbow ‚Üí analisis grafik SSE</p></li>
<li><p>Analisis Silhouette ‚Üí cari nilai rata-rata silhouette tertinggi</p></li>
</ul>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="implementasi-algoritma-k-means-menggunakan-python">
<h1><strong>Implementasi Algoritma K-Means Menggunakan Python</strong><a class="headerlink" href="#implementasi-algoritma-k-means-menggunakan-python" title="Link to this heading">#</a></h1>
<section id="install-library-yang-dibutuhkan">
<h2><strong>1. Install Library yang dibutuhkan</strong><a class="headerlink" href="#install-library-yang-dibutuhkan" title="Link to this heading">#</a></h2>
<p>Tujuan dari kode ini adalah untuk menginstal berbagai library yang diperlukan untuk menghubungkan Python dengan database, melakukan manipulasi data, serta membangun dan menerapkan modelnya.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Install Library yang dibutuhkan</span>

<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>pymysql
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>psycopg2-binary
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>pandas
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>SQLAlchemy<span class="w"> </span>pymysql
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>scikit-learn
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>numpy
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Collecting pymysql
  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)
Downloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)
?25l   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ <span class=" -Color -Color-Green">0.0/45.0 kB</span> <span class=" -Color -Color-Red">?</span> eta <span class=" -Color -Color-Cyan">-:--:--</span>
   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ <span class=" -Color -Color-Green">45.0/45.0 kB</span> <span class=" -Color -Color-Red">1.9 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:00</span>
?25h
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Installing collected packages: pymysql
Successfully installed pymysql-1.1.1
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Collecting psycopg2-binary
  Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)
Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)
?25l   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ <span class=" -Color -Color-Green">0.0/3.0 MB</span> <span class=" -Color -Color-Red">?</span> eta <span class=" -Color -Color-Cyan">-:--:--</span>
   ‚îÅ‚ï∫‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ <span class=" -Color -Color-Green">0.1/3.0 MB</span> <span class=" -Color -Color-Red">3.2 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:01</span>
   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ <span class=" -Color -Color-Green">0.9/3.0 MB</span> <span class=" -Color -Color-Red">12.8 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:01</span>
   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏ <span class=" -Color -Color-Green">3.0/3.0 MB</span> <span class=" -Color -Color-Red">32.4 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:01</span>
   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ <span class=" -Color -Color-Green">3.0/3.0 MB</span> <span class=" -Color -Color-Red">25.9 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:00</span>
?25h
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Installing collected packages: psycopg2-binary
Successfully installed psycopg2-binary-2.9.10
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)
Requirement already satisfied: numpy&gt;=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)
Requirement already satisfied: python-dateutil&gt;=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)
Requirement already satisfied: pytz&gt;=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)
Requirement already satisfied: tzdata&gt;=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil&gt;=2.8.2-&gt;pandas) (1.17.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: SQLAlchemy in /usr/local/lib/python3.11/dist-packages (2.0.41)
Requirement already satisfied: pymysql in /usr/local/lib/python3.11/dist-packages (1.1.1)
Requirement already satisfied: greenlet&gt;=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy) (3.2.2)
Requirement already satisfied: typing-extensions&gt;=4.6.0 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy) (4.13.2)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)
Requirement already satisfied: numpy&gt;=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)
Requirement already satisfied: scipy&gt;=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)
Requirement already satisfied: joblib&gt;=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)
Requirement already satisfied: threadpoolctl&gt;=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)
</pre></div>
</div>
</div>
</div>
</section>
<section id="mengambil-database-dari-dbever">
<h2><strong>2. Mengambil Database dari DBever</strong><a class="headerlink" href="#mengambil-database-dari-dbever" title="Link to this heading">#</a></h2>
<p>Kode ini bertujuan untuk menghubungkan Python ke database MySQL menggunakan library <code class="docutils literal notranslate"><span class="pre">pymysql</span></code>, mengambil data dari tabel <code class="docutils literal notranslate"><span class="pre">irissql</span></code> di database tersebut, mengubah data yang diambil menjadi format DataFrame menggunakan <code class="docutils literal notranslate"><span class="pre">pandas</span></code>, kemudian menampilkan data dalam bentuk tabel yang rapi, serta memastikan koneksi ke database ditutup dengan benar setelah proses selesai atau jika terjadi error.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Langkah Selanjutnya adalah mengambil Database dari dbever</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">pymysql</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tabulate</span><span class="w"> </span><span class="kn">import</span> <span class="n">tabulate</span>

<span class="n">MYSQL_HOST</span> <span class="o">=</span> <span class="s2">&quot;mysql-ce646e0-matakuliah.i.aivencloud.com&quot;</span>
<span class="n">MYSQL_PORT</span> <span class="o">=</span> <span class="mi">18376</span>
<span class="n">MYSQL_DB</span> <span class="o">=</span> <span class="s2">&quot;defaultdb&quot;</span>
<span class="n">MYSQL_USER</span> <span class="o">=</span> <span class="s2">&quot;avnadmin&quot;</span>
<span class="n">MYSQL_PASS</span> <span class="o">=</span> <span class="s2">&quot;AVNS_ttJDVCcji3xAatQ6zvd&quot;</span>

<span class="k">try</span><span class="p">:</span>
    <span class="c1"># Membuat koneksi ke MySQL</span>
    <span class="n">conn</span> <span class="o">=</span> <span class="n">pymysql</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span>
        <span class="n">host</span><span class="o">=</span><span class="n">MYSQL_HOST</span><span class="p">,</span>
        <span class="n">port</span><span class="o">=</span><span class="n">MYSQL_PORT</span><span class="p">,</span>
        <span class="n">user</span><span class="o">=</span><span class="n">MYSQL_USER</span><span class="p">,</span>
        <span class="n">password</span><span class="o">=</span><span class="n">MYSQL_PASS</span><span class="p">,</span>
        <span class="n">database</span><span class="o">=</span><span class="n">MYSQL_DB</span><span class="p">,</span>
        <span class="n">ssl</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;ssl&#39;</span><span class="p">:</span> <span class="p">{}},</span>  <span class="c1"># Aiven.io membutuhkan koneksi SSL</span>
    <span class="p">)</span>
    <span class="n">cur</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">cursor</span><span class="p">()</span>

    <span class="c1"># Menjalankan query (Ganti &#39;your_table&#39; dengan nama tabel yang benar)</span>
    <span class="n">cur</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;SELECT * FROM defaultdb.irissql;&quot;</span><span class="p">)</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="n">cur</span><span class="o">.</span><span class="n">fetchall</span><span class="p">()</span>

    <span class="c1"># Mengambil nama kolom</span>
    <span class="n">col_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">desc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">desc</span> <span class="ow">in</span> <span class="n">cur</span><span class="o">.</span><span class="n">description</span><span class="p">]</span>

    <span class="c1"># Menampilkan hasil dalam bentuk tabel</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">col_names</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tabulate</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="s2">&quot;keys&quot;</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="s2">&quot;psql&quot;</span><span class="p">))</span>

<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Error:&quot;</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>

<span class="k">finally</span><span class="p">:</span>
    <span class="c1"># Menutup koneksi</span>
    <span class="k">if</span> <span class="n">cur</span><span class="p">:</span>
        <span class="n">cur</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">conn</span><span class="p">:</span>
        <span class="n">conn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>+-----+------+-----------------+----------------+-----------------+----------------+-----------------+
|     |   id |   SepalLengthCm |   SepalWidthCm |   PetalLengthCm |   PetalWidthCm | species         |
|-----+------+-----------------+----------------+-----------------+----------------+-----------------|
|   0 |    1 |             5.1 |            3.5 |             1.4 |            0.2 | Iris-setosa     |
|   1 |    2 |             4.9 |            3   |             1.4 |            0.2 | Iris-setosa     |
|   2 |    3 |             4.7 |            3.2 |             1.3 |            0.2 | Iris-setosa     |
|   3 |    4 |             4.6 |            3.1 |             1.5 |            0.2 | Iris-setosa     |
|   4 |    5 |             5   |            3.6 |             1.4 |            0.2 | Iris-setosa     |
|   5 |    6 |             5.4 |            3.9 |             1.7 |            0.4 | Iris-setosa     |
|   6 |    7 |             4.6 |            3.4 |             1.4 |            0.3 | Iris-setosa     |
|   7 |    8 |             5   |            3.4 |             1.5 |            0.2 | Iris-setosa     |
|   8 |    9 |             4.4 |            2.9 |             1.4 |            0.2 | Iris-setosa     |
|   9 |   10 |             4.9 |            3.1 |             1.5 |            0.1 | Iris-setosa     |
|  10 |   11 |             5.4 |            3.7 |             1.5 |            0.2 | Iris-setosa     |
|  11 |   12 |             4.8 |            3.4 |             1.6 |            0.2 | Iris-setosa     |
|  12 |   13 |             4.8 |            3   |             1.4 |            0.1 | Iris-setosa     |
|  13 |   14 |             4.3 |            3   |             1.1 |            0.1 | Iris-setosa     |
|  14 |   15 |             5.8 |            4   |             1.2 |            0.2 | Iris-setosa     |
|  15 |   16 |             5.7 |            4.4 |             1.5 |            0.4 | Iris-setosa     |
|  16 |   17 |             5.4 |            3.9 |             1.3 |            0.4 | Iris-setosa     |
|  17 |   18 |             5.1 |            3.5 |             1.4 |            0.3 | Iris-setosa     |
|  18 |   19 |             5.7 |            3.8 |             1.7 |            0.3 | Iris-setosa     |
|  19 |   20 |             5.1 |            3.8 |             1.5 |            0.3 | Iris-setosa     |
|  20 |   21 |             5.4 |            3.4 |             1.7 |            0.2 | Iris-setosa     |
|  21 |   22 |             5.1 |            3.7 |             1.5 |            0.4 | Iris-setosa     |
|  22 |   23 |             4.6 |            3.6 |             1   |            0.2 | Iris-setosa     |
|  23 |   24 |             5.1 |            3.3 |             1.7 |            0.5 | Iris-setosa     |
|  24 |   25 |             4.8 |            3.4 |             1.9 |            0.2 | Iris-setosa     |
|  25 |   26 |             5   |            3   |             1.6 |            0.2 | Iris-setosa     |
|  26 |   27 |             5   |            3.4 |             1.6 |            0.4 | Iris-setosa     |
|  27 |   28 |             5.2 |            3.5 |             1.5 |            0.2 | Iris-setosa     |
|  28 |   29 |             5.2 |            3.4 |             1.4 |            0.2 | Iris-setosa     |
|  29 |   30 |             4.7 |            3.2 |             1.6 |            0.2 | Iris-setosa     |
|  30 |   31 |             4.8 |            3.1 |             1.6 |            0.2 | Iris-setosa     |
|  31 |   32 |             5.4 |            3.4 |             1.5 |            0.4 | Iris-setosa     |
|  32 |   33 |             5.2 |            4.1 |             1.5 |            0.1 | Iris-setosa     |
|  33 |   34 |             5.5 |            4.2 |             1.4 |            0.2 | Iris-setosa     |
|  34 |   35 |             4.9 |            3.1 |             1.5 |            0.1 | Iris-setosa     |
|  35 |   36 |             5   |            3.2 |             1.2 |            0.2 | Iris-setosa     |
|  36 |   37 |             5.5 |            3.5 |             1.3 |            0.2 | Iris-setosa     |
|  37 |   38 |             4.9 |            3.1 |             1.5 |            0.1 | Iris-setosa     |
|  38 |   39 |             4.4 |            3   |             1.3 |            0.2 | Iris-setosa     |
|  39 |   40 |             5.1 |            3.4 |             1.5 |            0.2 | Iris-setosa     |
|  40 |   41 |             5   |            3.5 |             1.3 |            0.3 | Iris-setosa     |
|  41 |   42 |             4.5 |            2.3 |             1.3 |            0.3 | Iris-setosa     |
|  42 |   43 |             4.4 |            3.2 |             1.3 |            0.2 | Iris-setosa     |
|  43 |   44 |             5   |            3.5 |             1.6 |            0.6 | Iris-setosa     |
|  44 |   45 |             5.1 |            3.8 |             1.9 |            0.4 | Iris-setosa     |
|  45 |   46 |             4.8 |            3   |             1.4 |            0.3 | Iris-setosa     |
|  46 |   47 |             5.1 |            3.8 |             1.6 |            0.2 | Iris-setosa     |
|  47 |   48 |             4.6 |            3.2 |             1.4 |            0.2 | Iris-setosa     |
|  48 |   49 |             5.3 |            3.7 |             1.5 |            0.2 | Iris-setosa     |
|  49 |   50 |             5   |            3.3 |             1.4 |            0.2 | Iris-setosa     |
|  50 |   51 |             7   |            3.2 |             4.7 |            1.4 | Iris-versicolor |
|  51 |   52 |             6.4 |            3.2 |             4.5 |            1.5 | Iris-versicolor |
|  52 |   53 |             6.9 |            3.1 |             4.9 |            1.5 | Iris-versicolor |
|  53 |   54 |             5.5 |            2.3 |             4   |            1.3 | Iris-versicolor |
|  54 |   55 |             6.5 |            2.8 |             4.6 |            1.5 | Iris-versicolor |
|  55 |   56 |             5.7 |            2.8 |             4.5 |            1.3 | Iris-versicolor |
|  56 |   57 |             6.3 |            3.3 |             4.7 |            1.6 | Iris-versicolor |
|  57 |   58 |             4.9 |            2.4 |             3.3 |            1   | Iris-versicolor |
|  58 |   59 |             6.6 |            2.9 |             4.6 |            1.3 | Iris-versicolor |
|  59 |   60 |             5.2 |            2.7 |             3.9 |            1.4 | Iris-versicolor |
|  60 |   61 |             5   |            2   |             3.5 |            1   | Iris-versicolor |
|  61 |   62 |             5.9 |            3   |             4.2 |            1.5 | Iris-versicolor |
|  62 |   63 |             6   |            2.2 |             4   |            1   | Iris-versicolor |
|  63 |   64 |             6.1 |            2.9 |             4.7 |            1.4 | Iris-versicolor |
|  64 |   65 |             5.6 |            2.9 |             3.6 |            1.3 | Iris-versicolor |
|  65 |   66 |             6.7 |            3.1 |             4.4 |            1.4 | Iris-versicolor |
|  66 |   67 |             5.6 |            3   |             4.5 |            1.5 | Iris-versicolor |
|  67 |   68 |             5.8 |            2.7 |             4.1 |            1   | Iris-versicolor |
|  68 |   69 |             6.2 |            2.2 |             4.5 |            1.5 | Iris-versicolor |
|  69 |   70 |             5.6 |            2.5 |             3.9 |            1.1 | Iris-versicolor |
|  70 |   71 |             5.9 |            3.2 |             4.8 |            1.8 | Iris-versicolor |
|  71 |   72 |             6.1 |            2.8 |             4   |            1.3 | Iris-versicolor |
|  72 |   73 |             6.3 |            2.5 |             4.9 |            1.5 | Iris-versicolor |
|  73 |   74 |             6.1 |            2.8 |             4.7 |            1.2 | Iris-versicolor |
|  74 |   75 |             6.4 |            2.9 |             4.3 |            1.3 | Iris-versicolor |
|  75 |   76 |             6.6 |            3   |             4.4 |            1.4 | Iris-versicolor |
|  76 |   77 |             6.8 |            2.8 |             4.8 |            1.4 | Iris-versicolor |
|  77 |   78 |             6.7 |            3   |             5   |            1.7 | Iris-versicolor |
|  78 |   79 |             6   |            2.9 |             4.5 |            1.5 | Iris-versicolor |
|  79 |   80 |             5.7 |            2.6 |             3.5 |            1   | Iris-versicolor |
|  80 |   81 |             5.5 |            2.4 |             3.8 |            1.1 | Iris-versicolor |
|  81 |   82 |             5.5 |            2.4 |             3.7 |            1   | Iris-versicolor |
|  82 |   83 |             5.8 |            2.7 |             3.9 |            1.2 | Iris-versicolor |
|  83 |   84 |             6   |            2.7 |             5.1 |            1.6 | Iris-versicolor |
|  84 |   85 |             5.4 |            3   |             4.5 |            1.5 | Iris-versicolor |
|  85 |   86 |             6   |            3.4 |             4.5 |            1.6 | Iris-versicolor |
|  86 |   87 |             6.7 |            3.1 |             4.7 |            1.5 | Iris-versicolor |
|  87 |   88 |             6.3 |            2.3 |             4.4 |            1.3 | Iris-versicolor |
|  88 |   89 |             5.6 |            3   |             4.1 |            1.3 | Iris-versicolor |
|  89 |   90 |             5.5 |            2.5 |             4   |            1.3 | Iris-versicolor |
|  90 |   91 |             5.5 |            2.6 |             4.4 |            1.2 | Iris-versicolor |
|  91 |   92 |             6.1 |            3   |             4.6 |            1.4 | Iris-versicolor |
|  92 |   93 |             5.8 |            2.6 |             4   |            1.2 | Iris-versicolor |
|  93 |   94 |             5   |            2.3 |             3.3 |            1   | Iris-versicolor |
|  94 |   95 |             5.6 |            2.7 |             4.2 |            1.3 | Iris-versicolor |
|  95 |   96 |             5.7 |            3   |             4.2 |            1.2 | Iris-versicolor |
|  96 |   97 |             5.7 |            2.9 |             4.2 |            1.3 | Iris-versicolor |
|  97 |   98 |             6.2 |            2.9 |             4.3 |            1.3 | Iris-versicolor |
|  98 |   99 |             5.1 |            2.5 |             3   |            1.1 | Iris-versicolor |
|  99 |  100 |             5.7 |            2.8 |             4.1 |            1.3 | Iris-versicolor |
| 100 |  101 |             6.3 |            3.3 |             6   |            2.5 | Iris-virginica  |
| 101 |  102 |             5.8 |            2.7 |             5.1 |            1.9 | Iris-virginica  |
| 102 |  103 |             7.1 |            3   |             5.9 |            2.1 | Iris-virginica  |
| 103 |  104 |             6.3 |            2.9 |             5.6 |            1.8 | Iris-virginica  |
| 104 |  105 |             6.5 |            3   |             5.8 |            2.2 | Iris-virginica  |
| 105 |  106 |             7.6 |            3   |             6.6 |            2.1 | Iris-virginica  |
| 106 |  107 |             4.9 |            2.5 |             4.5 |            1.7 | Iris-virginica  |
| 107 |  108 |             7.3 |            2.9 |             6.3 |            1.8 | Iris-virginica  |
| 108 |  109 |             6.7 |            2.5 |             5.8 |            1.8 | Iris-virginica  |
| 109 |  110 |             7.2 |            3.6 |             6.1 |            2.5 | Iris-virginica  |
| 110 |  111 |             6.5 |            3.2 |             5.1 |            2   | Iris-virginica  |
| 111 |  112 |             6.4 |            2.7 |             5.3 |            1.9 | Iris-virginica  |
| 112 |  113 |             6.8 |            3   |             5.5 |            2.1 | Iris-virginica  |
| 113 |  114 |             5.7 |            2.5 |             5   |            2   | Iris-virginica  |
| 114 |  115 |             5.8 |            2.8 |             5.1 |            2.4 | Iris-virginica  |
| 115 |  116 |             6.4 |            3.2 |             5.3 |            2.3 | Iris-virginica  |
| 116 |  117 |             6.5 |            3   |             5.5 |            1.8 | Iris-virginica  |
| 117 |  118 |             7.7 |            3.8 |             6.7 |            2.2 | Iris-virginica  |
| 118 |  119 |             7.7 |            2.6 |             6.9 |            2.3 | Iris-virginica  |
| 119 |  120 |             6   |            2.2 |             5   |            1.5 | Iris-virginica  |
| 120 |  121 |             6.9 |            3.2 |             5.7 |            2.3 | Iris-virginica  |
| 121 |  122 |             5.6 |            2.8 |             4.9 |            2   | Iris-virginica  |
| 122 |  123 |             7.7 |            2.8 |             6.7 |            2   | Iris-virginica  |
| 123 |  124 |             6.3 |            2.7 |             4.9 |            1.8 | Iris-virginica  |
| 124 |  125 |             6.7 |            3.3 |             5.7 |            2.1 | Iris-virginica  |
| 125 |  126 |             7.2 |            3.2 |             6   |            1.8 | Iris-virginica  |
| 126 |  127 |             6.2 |            2.8 |             4.8 |            1.8 | Iris-virginica  |
| 127 |  128 |             6.1 |            3   |             4.9 |            1.8 | Iris-virginica  |
| 128 |  129 |             6.4 |            2.8 |             5.6 |            2.1 | Iris-virginica  |
| 129 |  130 |             7.2 |            3   |             5.8 |            1.6 | Iris-virginica  |
| 130 |  131 |             7.4 |            2.8 |             6.1 |            1.9 | Iris-virginica  |
| 131 |  132 |             7.9 |            3.8 |             6.4 |            2   | Iris-virginica  |
| 132 |  133 |             6.4 |            2.8 |             5.6 |            2.2 | Iris-virginica  |
| 133 |  134 |             6.3 |            2.8 |             5.1 |            1.5 | Iris-virginica  |
| 134 |  135 |             6.1 |            2.6 |             5.6 |            1.4 | Iris-virginica  |
| 135 |  136 |             7.7 |            3   |             6.1 |            2.3 | Iris-virginica  |
| 136 |  137 |             6.3 |            3.4 |             5.6 |            2.4 | Iris-virginica  |
| 137 |  138 |             6.4 |            3.1 |             5.5 |            1.8 | Iris-virginica  |
| 138 |  139 |             6   |            3   |             4.8 |            1.8 | Iris-virginica  |
| 139 |  140 |             6.9 |            3.1 |             5.4 |            2.1 | Iris-virginica  |
| 140 |  141 |             6.7 |            3.1 |             5.6 |            2.4 | Iris-virginica  |
| 141 |  142 |             6.9 |            3.1 |             5.1 |            2.3 | Iris-virginica  |
| 142 |  143 |             5.8 |            2.7 |             5.1 |            1.9 | Iris-virginica  |
| 143 |  144 |             6.8 |            3.2 |             5.9 |            2.3 | Iris-virginica  |
| 144 |  145 |             6.7 |            3.3 |             5.7 |            2.5 | Iris-virginica  |
| 145 |  146 |             6.7 |            3   |             5.2 |            2.3 | Iris-virginica  |
| 146 |  147 |             6.3 |            2.5 |             5   |            1.9 | Iris-virginica  |
| 147 |  148 |             6.5 |            3   |             5.2 |            2   | Iris-virginica  |
| 148 |  149 |             6.2 |            3.4 |             5.4 |            2.3 | Iris-virginica  |
| 149 |  150 |             5.9 |            3   |             5.1 |            1.8 | Iris-virginica  |
+-----+------+-----------------+----------------+-----------------+----------------+-----------------+
</pre></div>
</div>
</div>
</div>
</section>
<section id="menghilangkan-species-labelnya">
<h2><strong>3. Menghilangkan species / labelnya</strong><a class="headerlink" href="#menghilangkan-species-labelnya" title="Link to this heading">#</a></h2>
<p>Kode ini bertujuan untuk mengambil data dari database MySQL, namun hanya kolom fitur (seperti <code class="docutils literal notranslate"><span class="pre">sepalLengthCm</span></code>, <code class="docutils literal notranslate"><span class="pre">sepalWidthCm</span></code>, <code class="docutils literal notranslate"><span class="pre">petalLengthCm</span></code>, dan <code class="docutils literal notranslate"><span class="pre">petalWidthCm</span></code>) tanpa kolom label atau kelas (<code class="docutils literal notranslate"><span class="pre">species</span></code>). Prosesnya dimulai dengan membuat koneksi ke database menggunakan <code class="docutils literal notranslate"><span class="pre">pymysql</span></code>, kemudian menjalankan query untuk mengambil data hanya dari kolom-kolom fitur tersebut. Data yang diambil lalu diubah menjadi format DataFrame dengan <code class="docutils literal notranslate"><span class="pre">pandas</span></code>, dan dikonversi menjadi array NumPy untuk keperluan analisis selanjutnya, seperti clustering. Terakhir, data tanpa kolom label ini ditampilkan dalam bentuk tabel yang rapi menggunakan <code class="docutils literal notranslate"><span class="pre">tabulate</span></code>, dan koneksi ke database ditutup dengan benar setelah proses selesai atau jika terjadi error.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Selanjutnya Hilangkan species/labelnya</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">pymysql</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tabulate</span><span class="w"> </span><span class="kn">import</span> <span class="n">tabulate</span>

<span class="n">MYSQL_HOST</span> <span class="o">=</span> <span class="s2">&quot;mysql-ce646e0-matakuliah.i.aivencloud.com&quot;</span>
<span class="n">MYSQL_PORT</span> <span class="o">=</span> <span class="mi">18376</span>  <span class="c1"># Aiven MySQL biasanya menggunakan port 25060</span>
<span class="n">MYSQL_DB</span> <span class="o">=</span> <span class="s2">&quot;defaultdb&quot;</span>  <span class="c1"># Ganti dengan nama database Anda</span>
<span class="n">MYSQL_USER</span> <span class="o">=</span> <span class="s2">&quot;avnadmin&quot;</span>  <span class="c1"># Username dari Aiven.io</span>
<span class="n">MYSQL_PASS</span> <span class="o">=</span> <span class="s2">&quot;AVNS_ttJDVCcji3xAatQ6zvd&quot;</span>  <span class="c1"># Ganti dengan password dari Aiven.io</span>

<span class="k">try</span><span class="p">:</span>
    <span class="c1"># Membuat koneksi ke MySQL</span>
    <span class="n">conn</span> <span class="o">=</span> <span class="n">pymysql</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span>
        <span class="n">host</span><span class="o">=</span><span class="n">MYSQL_HOST</span><span class="p">,</span>
        <span class="n">port</span><span class="o">=</span><span class="n">MYSQL_PORT</span><span class="p">,</span>
        <span class="n">user</span><span class="o">=</span><span class="n">MYSQL_USER</span><span class="p">,</span>
        <span class="n">password</span><span class="o">=</span><span class="n">MYSQL_PASS</span><span class="p">,</span>
        <span class="n">database</span><span class="o">=</span><span class="n">MYSQL_DB</span><span class="p">,</span>
        <span class="n">ssl</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;ssl&#39;</span><span class="p">:</span> <span class="p">{}},</span>  <span class="c1"># Aiven.io membutuhkan koneksi SSL</span>
    <span class="p">)</span>
    <span class="n">cur</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">cursor</span><span class="p">()</span>

    <span class="c1"># Menjalankan query untuk mengambil data tanpa kolom &#39;species&#39;</span>
    <span class="n">cur</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;SELECT sepalLengthCm, sepalWidthCm, petalLengthCm, petalWidthCm FROM defaultdb.irissql;&quot;</span><span class="p">)</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="n">cur</span><span class="o">.</span><span class="n">fetchall</span><span class="p">()</span>

    <span class="c1"># Mengambil nama kolom</span>
    <span class="n">col_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">desc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">desc</span> <span class="ow">in</span> <span class="n">cur</span><span class="o">.</span><span class="n">description</span><span class="p">]</span>

    <span class="c1"># Menampilkan hasil dalam bentuk tabel</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">col_names</span><span class="p">)</span>
    <span class="n">data_remove_class</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>  <span class="c1"># atau df.values</span>

    <span class="c1"># Menampilkan DataFrame tanpa kolom species (kalau ada)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Data tanpa kolom &#39;species&#39;:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tabulate</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="s2">&quot;keys&quot;</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="s2">&quot;psql&quot;</span><span class="p">))</span>

<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Error:&quot;</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>

<span class="k">finally</span><span class="p">:</span>
    <span class="c1"># Menutup koneksi</span>
    <span class="k">if</span> <span class="n">cur</span><span class="p">:</span>
        <span class="n">cur</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">conn</span><span class="p">:</span>
        <span class="n">conn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data tanpa kolom &#39;species&#39;:
+-----+-----------------+----------------+-----------------+----------------+
|     |   sepalLengthCm |   sepalWidthCm |   petalLengthCm |   petalWidthCm |
|-----+-----------------+----------------+-----------------+----------------|
|   0 |             5.1 |            3.5 |             1.4 |            0.2 |
|   1 |             4.9 |            3   |             1.4 |            0.2 |
|   2 |             4.7 |            3.2 |             1.3 |            0.2 |
|   3 |             4.6 |            3.1 |             1.5 |            0.2 |
|   4 |             5   |            3.6 |             1.4 |            0.2 |
|   5 |             5.4 |            3.9 |             1.7 |            0.4 |
|   6 |             4.6 |            3.4 |             1.4 |            0.3 |
|   7 |             5   |            3.4 |             1.5 |            0.2 |
|   8 |             4.4 |            2.9 |             1.4 |            0.2 |
|   9 |             4.9 |            3.1 |             1.5 |            0.1 |
|  10 |             5.4 |            3.7 |             1.5 |            0.2 |
|  11 |             4.8 |            3.4 |             1.6 |            0.2 |
|  12 |             4.8 |            3   |             1.4 |            0.1 |
|  13 |             4.3 |            3   |             1.1 |            0.1 |
|  14 |             5.8 |            4   |             1.2 |            0.2 |
|  15 |             5.7 |            4.4 |             1.5 |            0.4 |
|  16 |             5.4 |            3.9 |             1.3 |            0.4 |
|  17 |             5.1 |            3.5 |             1.4 |            0.3 |
|  18 |             5.7 |            3.8 |             1.7 |            0.3 |
|  19 |             5.1 |            3.8 |             1.5 |            0.3 |
|  20 |             5.4 |            3.4 |             1.7 |            0.2 |
|  21 |             5.1 |            3.7 |             1.5 |            0.4 |
|  22 |             4.6 |            3.6 |             1   |            0.2 |
|  23 |             5.1 |            3.3 |             1.7 |            0.5 |
|  24 |             4.8 |            3.4 |             1.9 |            0.2 |
|  25 |             5   |            3   |             1.6 |            0.2 |
|  26 |             5   |            3.4 |             1.6 |            0.4 |
|  27 |             5.2 |            3.5 |             1.5 |            0.2 |
|  28 |             5.2 |            3.4 |             1.4 |            0.2 |
|  29 |             4.7 |            3.2 |             1.6 |            0.2 |
|  30 |             4.8 |            3.1 |             1.6 |            0.2 |
|  31 |             5.4 |            3.4 |             1.5 |            0.4 |
|  32 |             5.2 |            4.1 |             1.5 |            0.1 |
|  33 |             5.5 |            4.2 |             1.4 |            0.2 |
|  34 |             4.9 |            3.1 |             1.5 |            0.1 |
|  35 |             5   |            3.2 |             1.2 |            0.2 |
|  36 |             5.5 |            3.5 |             1.3 |            0.2 |
|  37 |             4.9 |            3.1 |             1.5 |            0.1 |
|  38 |             4.4 |            3   |             1.3 |            0.2 |
|  39 |             5.1 |            3.4 |             1.5 |            0.2 |
|  40 |             5   |            3.5 |             1.3 |            0.3 |
|  41 |             4.5 |            2.3 |             1.3 |            0.3 |
|  42 |             4.4 |            3.2 |             1.3 |            0.2 |
|  43 |             5   |            3.5 |             1.6 |            0.6 |
|  44 |             5.1 |            3.8 |             1.9 |            0.4 |
|  45 |             4.8 |            3   |             1.4 |            0.3 |
|  46 |             5.1 |            3.8 |             1.6 |            0.2 |
|  47 |             4.6 |            3.2 |             1.4 |            0.2 |
|  48 |             5.3 |            3.7 |             1.5 |            0.2 |
|  49 |             5   |            3.3 |             1.4 |            0.2 |
|  50 |             7   |            3.2 |             4.7 |            1.4 |
|  51 |             6.4 |            3.2 |             4.5 |            1.5 |
|  52 |             6.9 |            3.1 |             4.9 |            1.5 |
|  53 |             5.5 |            2.3 |             4   |            1.3 |
|  54 |             6.5 |            2.8 |             4.6 |            1.5 |
|  55 |             5.7 |            2.8 |             4.5 |            1.3 |
|  56 |             6.3 |            3.3 |             4.7 |            1.6 |
|  57 |             4.9 |            2.4 |             3.3 |            1   |
|  58 |             6.6 |            2.9 |             4.6 |            1.3 |
|  59 |             5.2 |            2.7 |             3.9 |            1.4 |
|  60 |             5   |            2   |             3.5 |            1   |
|  61 |             5.9 |            3   |             4.2 |            1.5 |
|  62 |             6   |            2.2 |             4   |            1   |
|  63 |             6.1 |            2.9 |             4.7 |            1.4 |
|  64 |             5.6 |            2.9 |             3.6 |            1.3 |
|  65 |             6.7 |            3.1 |             4.4 |            1.4 |
|  66 |             5.6 |            3   |             4.5 |            1.5 |
|  67 |             5.8 |            2.7 |             4.1 |            1   |
|  68 |             6.2 |            2.2 |             4.5 |            1.5 |
|  69 |             5.6 |            2.5 |             3.9 |            1.1 |
|  70 |             5.9 |            3.2 |             4.8 |            1.8 |
|  71 |             6.1 |            2.8 |             4   |            1.3 |
|  72 |             6.3 |            2.5 |             4.9 |            1.5 |
|  73 |             6.1 |            2.8 |             4.7 |            1.2 |
|  74 |             6.4 |            2.9 |             4.3 |            1.3 |
|  75 |             6.6 |            3   |             4.4 |            1.4 |
|  76 |             6.8 |            2.8 |             4.8 |            1.4 |
|  77 |             6.7 |            3   |             5   |            1.7 |
|  78 |             6   |            2.9 |             4.5 |            1.5 |
|  79 |             5.7 |            2.6 |             3.5 |            1   |
|  80 |             5.5 |            2.4 |             3.8 |            1.1 |
|  81 |             5.5 |            2.4 |             3.7 |            1   |
|  82 |             5.8 |            2.7 |             3.9 |            1.2 |
|  83 |             6   |            2.7 |             5.1 |            1.6 |
|  84 |             5.4 |            3   |             4.5 |            1.5 |
|  85 |             6   |            3.4 |             4.5 |            1.6 |
|  86 |             6.7 |            3.1 |             4.7 |            1.5 |
|  87 |             6.3 |            2.3 |             4.4 |            1.3 |
|  88 |             5.6 |            3   |             4.1 |            1.3 |
|  89 |             5.5 |            2.5 |             4   |            1.3 |
|  90 |             5.5 |            2.6 |             4.4 |            1.2 |
|  91 |             6.1 |            3   |             4.6 |            1.4 |
|  92 |             5.8 |            2.6 |             4   |            1.2 |
|  93 |             5   |            2.3 |             3.3 |            1   |
|  94 |             5.6 |            2.7 |             4.2 |            1.3 |
|  95 |             5.7 |            3   |             4.2 |            1.2 |
|  96 |             5.7 |            2.9 |             4.2 |            1.3 |
|  97 |             6.2 |            2.9 |             4.3 |            1.3 |
|  98 |             5.1 |            2.5 |             3   |            1.1 |
|  99 |             5.7 |            2.8 |             4.1 |            1.3 |
| 100 |             6.3 |            3.3 |             6   |            2.5 |
| 101 |             5.8 |            2.7 |             5.1 |            1.9 |
| 102 |             7.1 |            3   |             5.9 |            2.1 |
| 103 |             6.3 |            2.9 |             5.6 |            1.8 |
| 104 |             6.5 |            3   |             5.8 |            2.2 |
| 105 |             7.6 |            3   |             6.6 |            2.1 |
| 106 |             4.9 |            2.5 |             4.5 |            1.7 |
| 107 |             7.3 |            2.9 |             6.3 |            1.8 |
| 108 |             6.7 |            2.5 |             5.8 |            1.8 |
| 109 |             7.2 |            3.6 |             6.1 |            2.5 |
| 110 |             6.5 |            3.2 |             5.1 |            2   |
| 111 |             6.4 |            2.7 |             5.3 |            1.9 |
| 112 |             6.8 |            3   |             5.5 |            2.1 |
| 113 |             5.7 |            2.5 |             5   |            2   |
| 114 |             5.8 |            2.8 |             5.1 |            2.4 |
| 115 |             6.4 |            3.2 |             5.3 |            2.3 |
| 116 |             6.5 |            3   |             5.5 |            1.8 |
| 117 |             7.7 |            3.8 |             6.7 |            2.2 |
| 118 |             7.7 |            2.6 |             6.9 |            2.3 |
| 119 |             6   |            2.2 |             5   |            1.5 |
| 120 |             6.9 |            3.2 |             5.7 |            2.3 |
| 121 |             5.6 |            2.8 |             4.9 |            2   |
| 122 |             7.7 |            2.8 |             6.7 |            2   |
| 123 |             6.3 |            2.7 |             4.9 |            1.8 |
| 124 |             6.7 |            3.3 |             5.7 |            2.1 |
| 125 |             7.2 |            3.2 |             6   |            1.8 |
| 126 |             6.2 |            2.8 |             4.8 |            1.8 |
| 127 |             6.1 |            3   |             4.9 |            1.8 |
| 128 |             6.4 |            2.8 |             5.6 |            2.1 |
| 129 |             7.2 |            3   |             5.8 |            1.6 |
| 130 |             7.4 |            2.8 |             6.1 |            1.9 |
| 131 |             7.9 |            3.8 |             6.4 |            2   |
| 132 |             6.4 |            2.8 |             5.6 |            2.2 |
| 133 |             6.3 |            2.8 |             5.1 |            1.5 |
| 134 |             6.1 |            2.6 |             5.6 |            1.4 |
| 135 |             7.7 |            3   |             6.1 |            2.3 |
| 136 |             6.3 |            3.4 |             5.6 |            2.4 |
| 137 |             6.4 |            3.1 |             5.5 |            1.8 |
| 138 |             6   |            3   |             4.8 |            1.8 |
| 139 |             6.9 |            3.1 |             5.4 |            2.1 |
| 140 |             6.7 |            3.1 |             5.6 |            2.4 |
| 141 |             6.9 |            3.1 |             5.1 |            2.3 |
| 142 |             5.8 |            2.7 |             5.1 |            1.9 |
| 143 |             6.8 |            3.2 |             5.9 |            2.3 |
| 144 |             6.7 |            3.3 |             5.7 |            2.5 |
| 145 |             6.7 |            3   |             5.2 |            2.3 |
| 146 |             6.3 |            2.5 |             5   |            1.9 |
| 147 |             6.5 |            3   |             5.2 |            2   |
| 148 |             6.2 |            3.4 |             5.4 |            2.3 |
| 149 |             5.9 |            3   |             5.1 |            1.8 |
+-----+-----------------+----------------+-----------------+----------------+
</pre></div>
</div>
</div>
</div>
</section>
<section id="clustering-pada-data-iris-menggunakan-k-means-dengan-jumlah-cluster-2">
<h2><strong>4. Clustering pada data Iris menggunakan K-Means dengan jumlah cluster 2</strong><a class="headerlink" href="#clustering-pada-data-iris-menggunakan-k-means-dengan-jumlah-cluster-2" title="Link to this heading">#</a></h2>
<p>Kode di atas bertujuan untuk melakukan pengelompokan (clustering) pada dataset iris menggunakan algoritma KMeans. Pertama, data fitur dari iris diambil dan kemudian dinormalisasi agar semua nilai fitur berada dalam rentang yang sama, sehingga proses clustering menjadi lebih efektif dan adil antar fitur. Selanjutnya, algoritma KMeans dijalankan untuk membagi data menjadi sejumlah cluster yang telah ditentukan (dalam contoh ini, 2 cluster). Setelah clustering selesai, kode ini mengevaluasi kualitas hasil cluster menggunakan metrik seperti inertia dan silhouette score, yang mengukur seberapa baik data terkelompok secara internal. Kemudian, untuk mengetahui seberapa sesuai hasil clustering dengan label kelas asli, setiap cluster dipetakan ke kelas mayoritas yang paling sering muncul di cluster tersebut, sehingga bisa dilakukan perbandingan dan perhitungan akurasi terhadap label asli. Terakhir, hasil pengelompokan, evaluasi, dan pemetaan kelas disimpan dan ditampilkan agar pengguna dapat melihat distribusi cluster per kelas serta performa clustering secara keseluruhan. Pendekatan ini membantu memahami apakah metode clustering mampu mengelompokkan data dengan pola yang mirip dengan klasifikasi asli yang sudah ada.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">google.colab</span><span class="w"> </span><span class="kn">import</span> <span class="n">files</span>
<span class="n">uploaded</span> <span class="o">=</span> <span class="n">files</span><span class="o">.</span><span class="n">upload</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
     <input type="file" id="files-f98af1b7-cfec-4764-b693-5d0622f2e942" name="files[]" multiple disabled
        style="border:none" />
     <output id="result-f98af1b7-cfec-4764-b693-5d0622f2e942">
      Upload widget is only available when the cell has been executed in the
      current browser session. Please rerun this cell to enable.
      </output>
      <script>// Copyright 2017 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

/**
 * @fileoverview Helpers for google.colab Python module.
 */
(function(scope) {
function span(text, styleAttributes = {}) {
  const element = document.createElement('span');
  element.textContent = text;
  for (const key of Object.keys(styleAttributes)) {
    element.style[key] = styleAttributes[key];
  }
  return element;
}

// Max number of bytes which will be uploaded at a time.
const MAX_PAYLOAD_SIZE = 100 * 1024;

function _uploadFiles(inputId, outputId) {
  const steps = uploadFilesStep(inputId, outputId);
  const outputElement = document.getElementById(outputId);
  // Cache steps on the outputElement to make it available for the next call
  // to uploadFilesContinue from Python.
  outputElement.steps = steps;

  return _uploadFilesContinue(outputId);
}

// This is roughly an async generator (not supported in the browser yet),
// where there are multiple asynchronous steps and the Python side is going
// to poll for completion of each step.
// This uses a Promise to block the python side on completion of each step,
// then passes the result of the previous step as the input to the next step.
function _uploadFilesContinue(outputId) {
  const outputElement = document.getElementById(outputId);
  const steps = outputElement.steps;

  const next = steps.next(outputElement.lastPromiseValue);
  return Promise.resolve(next.value.promise).then((value) => {
    // Cache the last promise value to make it available to the next
    // step of the generator.
    outputElement.lastPromiseValue = value;
    return next.value.response;
  });
}

/**
 * Generator function which is called between each async step of the upload
 * process.
 * @param {string} inputId Element ID of the input file picker element.
 * @param {string} outputId Element ID of the output display.
 * @return {!Iterable<!Object>} Iterable of next steps.
 */
function* uploadFilesStep(inputId, outputId) {
  const inputElement = document.getElementById(inputId);
  inputElement.disabled = false;

  const outputElement = document.getElementById(outputId);
  outputElement.innerHTML = '';

  const pickedPromise = new Promise((resolve) => {
    inputElement.addEventListener('change', (e) => {
      resolve(e.target.files);
    });
  });

  const cancel = document.createElement('button');
  inputElement.parentElement.appendChild(cancel);
  cancel.textContent = 'Cancel upload';
  const cancelPromise = new Promise((resolve) => {
    cancel.onclick = () => {
      resolve(null);
    };
  });

  // Wait for the user to pick the files.
  const files = yield {
    promise: Promise.race([pickedPromise, cancelPromise]),
    response: {
      action: 'starting',
    }
  };

  cancel.remove();

  // Disable the input element since further picks are not allowed.
  inputElement.disabled = true;

  if (!files) {
    return {
      response: {
        action: 'complete',
      }
    };
  }

  for (const file of files) {
    const li = document.createElement('li');
    li.append(span(file.name, {fontWeight: 'bold'}));
    li.append(span(
        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +
        `last modified: ${
            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :
                                    'n/a'} - `));
    const percent = span('0% done');
    li.appendChild(percent);

    outputElement.appendChild(li);

    const fileDataPromise = new Promise((resolve) => {
      const reader = new FileReader();
      reader.onload = (e) => {
        resolve(e.target.result);
      };
      reader.readAsArrayBuffer(file);
    });
    // Wait for the data to be ready.
    let fileData = yield {
      promise: fileDataPromise,
      response: {
        action: 'continue',
      }
    };

    // Use a chunked sending to avoid message size limits. See b/62115660.
    let position = 0;
    do {
      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);
      const chunk = new Uint8Array(fileData, position, length);
      position += length;

      const base64 = btoa(String.fromCharCode.apply(null, chunk));
      yield {
        response: {
          action: 'append',
          file: file.name,
          data: base64,
        },
      };

      let percentDone = fileData.byteLength === 0 ?
          100 :
          Math.round((position / fileData.byteLength) * 100);
      percent.textContent = `${percentDone}% done`;

    } while (position < fileData.byteLength);
  }

  // All done.
  yield {
    response: {
      action: 'complete',
    }
  };
}

scope.google = scope.google || {};
scope.google.colab = scope.google.colab || {};
scope.google.colab._files = {
  _uploadFiles,
  _uploadFilesContinue,
};
})(self);
</script> </div><div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="nn">&lt;ipython-input-4-21dc3c638f66&gt;</span> in <span class="ni">&lt;cell line: 0&gt;</span><span class="nt">()</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="kn">from</span><span class="w"> </span><span class="nn">google.colab</span><span class="w"> </span><span class="kn">import</span> <span class="n">files</span>
<span class="ne">----&gt; </span><span class="mi">2</span> <span class="n">uploaded</span> <span class="o">=</span> <span class="n">files</span><span class="o">.</span><span class="n">upload</span><span class="p">()</span>

<span class="nn">/usr/local/lib/python3.11/dist-packages/google/colab/files.py</span> in <span class="ni">upload</span><span class="nt">(target_dir)</span>
<span class="g g-Whitespace">     </span><span class="mi">70</span>   <span class="s2">&quot;&quot;&quot;</span>
<span class="g g-Whitespace">     </span><span class="mi">71</span><span class="s2"> </span>
<span class="ne">---&gt; </span><span class="mi">72</span><span class="s2">   uploaded_files = _upload_files(multiple=True)</span>
<span class="g g-Whitespace">     </span><span class="mi">73</span><span class="s2">   # Mapping from original filename to filename as saved locally.</span>
<span class="g g-Whitespace">     </span><span class="mi">74</span><span class="s2">   local_filenames = dict()</span>

<span class="nn">/usr/local/lib/python3.11/dist-packages/google/colab/files.py</span> in <span class="ni">_upload_files</span><span class="nt">(multiple)</span>
<span class="g g-Whitespace">    </span><span class="mi">162</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">163</span><span class="s2">   # First result is always an indication that the file picker has completed.</span>
<span class="ne">--&gt; </span><span class="mi">164</span><span class="s2">   result = _output.eval_js(</span>
<span class="g g-Whitespace">    </span><span class="mi">165</span><span class="s2">       &#39;google.colab._files._uploadFiles(&quot;</span><span class="si">{input_id}</span><span class="s2">&quot;, &quot;</span><span class="si">{output_id}</span><span class="s2">&quot;)&#39;.format(</span>
<span class="g g-Whitespace">    </span><span class="mi">166</span><span class="s2">           input_id=input_id, output_id=output_id</span>

<span class="nn">/usr/local/lib/python3.11/dist-packages/google/colab/output/_js.py</span> in <span class="ni">eval_js</span><span class="nt">(script, ignore_result, timeout_sec)</span>
<span class="g g-Whitespace">     </span><span class="mi">38</span><span class="s2">   if ignore_result:</span>
<span class="g g-Whitespace">     </span><span class="mi">39</span><span class="s2">     return</span>
<span class="ne">---&gt; </span><span class="mi">40</span><span class="s2">   return _message.read_reply_from_input(request_id, timeout_sec)</span>
<span class="g g-Whitespace">     </span><span class="mi">41</span><span class="s2"> </span>
<span class="g g-Whitespace">     </span><span class="mi">42</span><span class="s2"> </span>

<span class="nn">/usr/local/lib/python3.11/dist-packages/google/colab/_message.py</span> in <span class="ni">read_reply_from_input</span><span class="nt">(message_id, timeout_sec)</span>
<span class="g g-Whitespace">     </span><span class="mi">94</span><span class="s2">     reply = _read_next_input_message()</span>
<span class="g g-Whitespace">     </span><span class="mi">95</span><span class="s2">     if reply == _NOT_READY or not isinstance(reply, dict):</span>
<span class="ne">---&gt; </span><span class="mi">96</span><span class="s2">       time.sleep(0.025)</span>
<span class="g g-Whitespace">     </span><span class="mi">97</span><span class="s2">       continue</span>
<span class="g g-Whitespace">     </span><span class="mi">98</span><span class="s2">     if (</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.cluster</span><span class="w"> </span><span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">silhouette_score</span><span class="p">,</span> <span class="n">accuracy_score</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># Memuat data dari file Excel yang berisi fitur dan label kelas</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s2">&quot;data_iris.xlsx&quot;</span><span class="p">)</span>

<span class="c1"># Memilih kolom fitur yang akan digunakan untuk clustering</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;sepal length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal width&#39;</span><span class="p">,</span> <span class="s1">&#39;petal length&#39;</span><span class="p">,</span> <span class="s1">&#39;petal width&#39;</span><span class="p">]]</span>
<span class="c1"># Mengambil kolom label asli untuk evaluasi nanti</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span>

<span class="c1"># Melakukan skala fitur agar nilainya berada di rentang 0 sampai 1</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">scaled_features</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

<span class="c1"># Menjalankan algoritma KMeans untuk membagi data menjadi K cluster</span>
<span class="n">K</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># Menentukan jumlah cluster yang diinginkan</span>
<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">K</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>
<span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">scaled_features</span><span class="p">)</span>

<span class="c1"># Menambahkan kolom cluster hasil prediksi ke dataframe asli</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;cluster&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span>

<span class="c1"># Menampilkan jumlah iterasi yang diperlukan hingga algoritma berhenti</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Jumlah iterasi sampai konvergen: </span><span class="si">{</span><span class="n">kmeans</span><span class="o">.</span><span class="n">n_iter_</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="c1"># Menampilkan nilai inertia sebagai ukuran kualitas cluster (semakin kecil semakin baik)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Inertia (SSE): </span><span class="si">{</span><span class="n">kmeans</span><span class="o">.</span><span class="n">inertia_</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="c1"># Menghitung dan menampilkan skor silhouette untuk menilai seberapa baik cluster terbentuk</span>
<span class="n">sil_score</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">scaled_features</span><span class="p">,</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Silhouette Score: </span><span class="si">{</span><span class="n">sil_score</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Mengasosiasikan setiap cluster dengan kelas mayoritas dari data asli untuk penilaian akurasi</span>
<span class="n">mapping</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;cluster&#39;</span><span class="p">)[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span>
    <span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">mode</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>
    <span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
<span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;predicted_class&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;cluster&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">mapping</span><span class="p">)</span>

<span class="c1"># Membandingkan label asli dengan hasil prediksi berdasarkan cluster untuk menghitung akurasi</span>
<span class="n">y_true</span> <span class="o">=</span> <span class="n">labels</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;predicted_class&#39;</span><span class="p">]</span>

<span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Akurasi keseluruhan clustering terhadap label asli: </span><span class="si">{</span><span class="n">acc</span><span class="si">:</span><span class="s2">.4%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Menampilkan tabel frekuensi untuk melihat distribusi cluster di tiap kelas asli</span>
<span class="n">dist</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">crosstab</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;cluster&#39;</span><span class="p">],</span> <span class="n">rownames</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">],</span> <span class="n">colnames</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Cluster&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Distribusi cluster per kelas:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dist</span><span class="p">)</span>

<span class="c1"># Menyimpan hasil data yang sudah termasuk cluster dan prediksi kelas ke file Excel baru</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s2">&quot;hasilnya.xlsx&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Menampilkan tabel lengkap yang memuat label asli, hasil cluster, dan kelas prediksi</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_rows&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;Class&#39;</span><span class="p">,</span> <span class="s1">&#39;cluster&#39;</span><span class="p">,</span> <span class="s1">&#39;predicted_class&#39;</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Jumlah iterasi sampai konvergen: 4
Inertia (SSE): 12.1437
Silhouette Score: 0.6295

Akurasi keseluruhan clustering terhadap label asli: 66.6667%

Distribusi cluster per kelas:
Cluster           0   1
Class                  
Iris-setosa       0  50
Iris-versicolor  50   0
Iris-virginica   50   0
               Class  cluster  predicted_class
0        Iris-setosa        1      Iris-setosa
1        Iris-setosa        1      Iris-setosa
2        Iris-setosa        1      Iris-setosa
3        Iris-setosa        1      Iris-setosa
4        Iris-setosa        1      Iris-setosa
5        Iris-setosa        1      Iris-setosa
6        Iris-setosa        1      Iris-setosa
7        Iris-setosa        1      Iris-setosa
8        Iris-setosa        1      Iris-setosa
9        Iris-setosa        1      Iris-setosa
10       Iris-setosa        1      Iris-setosa
11       Iris-setosa        1      Iris-setosa
12       Iris-setosa        1      Iris-setosa
13       Iris-setosa        1      Iris-setosa
14       Iris-setosa        1      Iris-setosa
15       Iris-setosa        1      Iris-setosa
16       Iris-setosa        1      Iris-setosa
17       Iris-setosa        1      Iris-setosa
18       Iris-setosa        1      Iris-setosa
19       Iris-setosa        1      Iris-setosa
20       Iris-setosa        1      Iris-setosa
21       Iris-setosa        1      Iris-setosa
22       Iris-setosa        1      Iris-setosa
23       Iris-setosa        1      Iris-setosa
24       Iris-setosa        1      Iris-setosa
25       Iris-setosa        1      Iris-setosa
26       Iris-setosa        1      Iris-setosa
27       Iris-setosa        1      Iris-setosa
28       Iris-setosa        1      Iris-setosa
29       Iris-setosa        1      Iris-setosa
30       Iris-setosa        1      Iris-setosa
31       Iris-setosa        1      Iris-setosa
32       Iris-setosa        1      Iris-setosa
33       Iris-setosa        1      Iris-setosa
34       Iris-setosa        1      Iris-setosa
35       Iris-setosa        1      Iris-setosa
36       Iris-setosa        1      Iris-setosa
37       Iris-setosa        1      Iris-setosa
38       Iris-setosa        1      Iris-setosa
39       Iris-setosa        1      Iris-setosa
40       Iris-setosa        1      Iris-setosa
41       Iris-setosa        1      Iris-setosa
42       Iris-setosa        1      Iris-setosa
43       Iris-setosa        1      Iris-setosa
44       Iris-setosa        1      Iris-setosa
45       Iris-setosa        1      Iris-setosa
46       Iris-setosa        1      Iris-setosa
47       Iris-setosa        1      Iris-setosa
48       Iris-setosa        1      Iris-setosa
49       Iris-setosa        1      Iris-setosa
50   Iris-versicolor        0  Iris-versicolor
51   Iris-versicolor        0  Iris-versicolor
52   Iris-versicolor        0  Iris-versicolor
53   Iris-versicolor        0  Iris-versicolor
54   Iris-versicolor        0  Iris-versicolor
55   Iris-versicolor        0  Iris-versicolor
56   Iris-versicolor        0  Iris-versicolor
57   Iris-versicolor        0  Iris-versicolor
58   Iris-versicolor        0  Iris-versicolor
59   Iris-versicolor        0  Iris-versicolor
60   Iris-versicolor        0  Iris-versicolor
61   Iris-versicolor        0  Iris-versicolor
62   Iris-versicolor        0  Iris-versicolor
63   Iris-versicolor        0  Iris-versicolor
64   Iris-versicolor        0  Iris-versicolor
65   Iris-versicolor        0  Iris-versicolor
66   Iris-versicolor        0  Iris-versicolor
67   Iris-versicolor        0  Iris-versicolor
68   Iris-versicolor        0  Iris-versicolor
69   Iris-versicolor        0  Iris-versicolor
70   Iris-versicolor        0  Iris-versicolor
71   Iris-versicolor        0  Iris-versicolor
72   Iris-versicolor        0  Iris-versicolor
73   Iris-versicolor        0  Iris-versicolor
74   Iris-versicolor        0  Iris-versicolor
75   Iris-versicolor        0  Iris-versicolor
76   Iris-versicolor        0  Iris-versicolor
77   Iris-versicolor        0  Iris-versicolor
78   Iris-versicolor        0  Iris-versicolor
79   Iris-versicolor        0  Iris-versicolor
80   Iris-versicolor        0  Iris-versicolor
81   Iris-versicolor        0  Iris-versicolor
82   Iris-versicolor        0  Iris-versicolor
83   Iris-versicolor        0  Iris-versicolor
84   Iris-versicolor        0  Iris-versicolor
85   Iris-versicolor        0  Iris-versicolor
86   Iris-versicolor        0  Iris-versicolor
87   Iris-versicolor        0  Iris-versicolor
88   Iris-versicolor        0  Iris-versicolor
89   Iris-versicolor        0  Iris-versicolor
90   Iris-versicolor        0  Iris-versicolor
91   Iris-versicolor        0  Iris-versicolor
92   Iris-versicolor        0  Iris-versicolor
93   Iris-versicolor        0  Iris-versicolor
94   Iris-versicolor        0  Iris-versicolor
95   Iris-versicolor        0  Iris-versicolor
96   Iris-versicolor        0  Iris-versicolor
97   Iris-versicolor        0  Iris-versicolor
98   Iris-versicolor        0  Iris-versicolor
99   Iris-versicolor        0  Iris-versicolor
100   Iris-virginica        0  Iris-versicolor
101   Iris-virginica        0  Iris-versicolor
102   Iris-virginica        0  Iris-versicolor
103   Iris-virginica        0  Iris-versicolor
104   Iris-virginica        0  Iris-versicolor
105   Iris-virginica        0  Iris-versicolor
106   Iris-virginica        0  Iris-versicolor
107   Iris-virginica        0  Iris-versicolor
108   Iris-virginica        0  Iris-versicolor
109   Iris-virginica        0  Iris-versicolor
110   Iris-virginica        0  Iris-versicolor
111   Iris-virginica        0  Iris-versicolor
112   Iris-virginica        0  Iris-versicolor
113   Iris-virginica        0  Iris-versicolor
114   Iris-virginica        0  Iris-versicolor
115   Iris-virginica        0  Iris-versicolor
116   Iris-virginica        0  Iris-versicolor
117   Iris-virginica        0  Iris-versicolor
118   Iris-virginica        0  Iris-versicolor
119   Iris-virginica        0  Iris-versicolor
120   Iris-virginica        0  Iris-versicolor
121   Iris-virginica        0  Iris-versicolor
122   Iris-virginica        0  Iris-versicolor
123   Iris-virginica        0  Iris-versicolor
124   Iris-virginica        0  Iris-versicolor
125   Iris-virginica        0  Iris-versicolor
126   Iris-virginica        0  Iris-versicolor
127   Iris-virginica        0  Iris-versicolor
128   Iris-virginica        0  Iris-versicolor
129   Iris-virginica        0  Iris-versicolor
130   Iris-virginica        0  Iris-versicolor
131   Iris-virginica        0  Iris-versicolor
132   Iris-virginica        0  Iris-versicolor
133   Iris-virginica        0  Iris-versicolor
134   Iris-virginica        0  Iris-versicolor
135   Iris-virginica        0  Iris-versicolor
136   Iris-virginica        0  Iris-versicolor
137   Iris-virginica        0  Iris-versicolor
138   Iris-virginica        0  Iris-versicolor
139   Iris-virginica        0  Iris-versicolor
140   Iris-virginica        0  Iris-versicolor
141   Iris-virginica        0  Iris-versicolor
142   Iris-virginica        0  Iris-versicolor
143   Iris-virginica        0  Iris-versicolor
144   Iris-virginica        0  Iris-versicolor
145   Iris-virginica        0  Iris-versicolor
146   Iris-virginica        0  Iris-versicolor
147   Iris-virginica        0  Iris-versicolor
148   Iris-virginica        0  Iris-versicolor
149   Iris-virginica        0  Iris-versicolor
</pre></div>
</div>
</div>
</div>
</section>
<section id="clustering-pada-data-iris-menggunakan-k-means-dengan-jumlah-cluster-3">
<h2><strong>5. Clustering pada data Iris menggunakan K-Means dengan jumlah cluster 3</strong><a class="headerlink" href="#clustering-pada-data-iris-menggunakan-k-means-dengan-jumlah-cluster-3" title="Link to this heading">#</a></h2>
<p>Kode ini bertujuan untuk mengelompokkan data iris menggunakan algoritma K-Means dan mengevaluasi hasilnya terhadap label kelas yang sebenarnya. Data fitur dinormalisasi terlebih dahulu, kemudian dilakukan <em>clustering</em> dengan 3 klaster sesuai jumlah kelas. Setelah itu, setiap klaster dipetakan ke kelas berdasarkan mayoritas anggotanya. Evaluasi dilakukan dengan menghitung akurasi, kesalahan per kelas, <em>Silhouette Score</em>, dan distribusi klaster. Hasil akhir disimpan dalam file Excel dan ditampilkan perbandingan antara kelas asli, klaster, dan kelas hasil prediksi.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.cluster</span><span class="w"> </span><span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">silhouette_score</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># Membaca file Excel yang mencakup data fitur serta label kelas</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s2">&quot;data_iris.xlsx&quot;</span><span class="p">)</span>

<span class="c1"># Membersihkan dan menyesuaikan format nama kolom agar seragam</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="s1">&#39;_&#39;</span><span class="p">)</span>

<span class="c1"># Menentukan kolom-kolom numerik yang akan digunakan dalam proses klasterisasi</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;sepal_length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal_width&#39;</span><span class="p">,</span> <span class="s1">&#39;petal_length&#39;</span><span class="p">,</span> <span class="s1">&#39;petal_width&#39;</span><span class="p">]]</span>

<span class="c1"># Mengubah nilai fitur ke dalam skala 0-1 untuk menghindari dominasi oleh fitur tertentu</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">scaled_features</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

<span class="c1"># Inisialisasi dan pelatihan model KMeans dengan 3 klaster</span>
<span class="n">K</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span>
    <span class="n">n_clusters</span><span class="o">=</span><span class="n">K</span><span class="p">,</span>
    <span class="n">max_iter</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
    <span class="n">tol</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
    <span class="n">n_init</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span>  <span class="c1"># Ganti ke 10 jika menggunakan versi scikit-learn &lt; 1.4</span>
<span class="p">)</span>
<span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">scaled_features</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;cluster&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span>  <span class="c1"># Menyimpan hasil klasterisasi ke dalam dataframe</span>

<span class="c1"># Menampilkan informasi dasar tentang hasil proses KMeans</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Jumlah iterasi hingga model berhenti: </span><span class="si">{</span><span class="n">kmeans</span><span class="o">.</span><span class="n">n_iter_</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Nilai inertia (total SSE): </span><span class="si">{</span><span class="n">kmeans</span><span class="o">.</span><span class="n">inertia_</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">sil_score</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">scaled_features</span><span class="p">,</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Skor Silhouette: </span><span class="si">{</span><span class="n">sil_score</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Mengaitkan setiap cluster dengan label kelas yang paling sering muncul dalam cluster tersebut</span>
<span class="n">mapping</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;cluster&#39;</span><span class="p">)[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span>
      <span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">mode</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>
      <span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
<span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;predicted_class&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;cluster&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">mapping</span><span class="p">)</span>

<span class="c1"># Menyiapkan data asli dan hasil prediksi untuk keperluan evaluasi</span>
<span class="n">y_true</span>   <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span>
<span class="n">y_pred</span>   <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;predicted_class&#39;</span><span class="p">]</span>
<span class="n">classes</span>  <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
<span class="n">cm</span>       <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">classes</span><span class="p">)</span>

<span class="c1"># Mengukur akurasi umum dari hasil clustering terhadap label asli</span>
<span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Tingkat akurasi secara keseluruhan: </span><span class="si">{</span><span class="n">acc</span><span class="si">:</span><span class="s2">.4%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Menghitung tingkat kesalahan pada masing-masing kelas</span>
<span class="n">error_per_class</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">classes</span><span class="p">):</span>
    <span class="n">total</span>   <span class="o">=</span> <span class="n">cm</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="n">cm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
    <span class="n">error</span>   <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">correct</span><span class="o">/</span><span class="n">total</span> <span class="k">if</span> <span class="n">total</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
    <span class="n">error_per_class</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">error</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Rasio kesalahan berdasarkan kelas:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">c</span><span class="p">,</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">error_per_class</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; - </span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Menyusun tabulasi frekuensi hubungan antara label asli dengan klaster hasil</span>
<span class="n">dist</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">crosstab</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;cluster&#39;</span><span class="p">],</span>
                   <span class="n">rownames</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">],</span> <span class="n">colnames</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Cluster&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Tabel distribusi cluster untuk setiap kelas:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dist</span><span class="p">)</span>

<span class="c1"># Menyimpan hasil analisis lengkap ke file Excel</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s2">&quot;hasil_clustering_dengan_class_lengkap.xlsx&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Menampilkan perbandingan antara label asli, hasil klasterisasi, dan prediksi kelas</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_rows&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Tabel perbandingan class, cluster, dan predicted_class:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;class&#39;</span><span class="p">,</span> <span class="s1">&#39;cluster&#39;</span><span class="p">,</span> <span class="s1">&#39;predicted_class&#39;</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Jumlah iterasi hingga model berhenti: 3
Nilai inertia (total SSE): 7.1386
Skor Silhouette: 0.4825

Tingkat akurasi secara keseluruhan: 88.0000%

Rasio kesalahan berdasarkan kelas:
 - Iris-setosa: 0.00%
 - Iris-versicolor: 20.00%
 - Iris-virginica: 16.00%

Tabel distribusi cluster untuk setiap kelas:
Cluster           0   1   2
Class                      
Iris-setosa       0  50   0
Iris-versicolor  10   0  40
Iris-virginica   42   0   8

Tabel perbandingan class, cluster, dan predicted_class:
               class  cluster  predicted_class
0        Iris-setosa        1      Iris-setosa
1        Iris-setosa        1      Iris-setosa
2        Iris-setosa        1      Iris-setosa
3        Iris-setosa        1      Iris-setosa
4        Iris-setosa        1      Iris-setosa
5        Iris-setosa        1      Iris-setosa
6        Iris-setosa        1      Iris-setosa
7        Iris-setosa        1      Iris-setosa
8        Iris-setosa        1      Iris-setosa
9        Iris-setosa        1      Iris-setosa
10       Iris-setosa        1      Iris-setosa
11       Iris-setosa        1      Iris-setosa
12       Iris-setosa        1      Iris-setosa
13       Iris-setosa        1      Iris-setosa
14       Iris-setosa        1      Iris-setosa
15       Iris-setosa        1      Iris-setosa
16       Iris-setosa        1      Iris-setosa
17       Iris-setosa        1      Iris-setosa
18       Iris-setosa        1      Iris-setosa
19       Iris-setosa        1      Iris-setosa
20       Iris-setosa        1      Iris-setosa
21       Iris-setosa        1      Iris-setosa
22       Iris-setosa        1      Iris-setosa
23       Iris-setosa        1      Iris-setosa
24       Iris-setosa        1      Iris-setosa
25       Iris-setosa        1      Iris-setosa
26       Iris-setosa        1      Iris-setosa
27       Iris-setosa        1      Iris-setosa
28       Iris-setosa        1      Iris-setosa
29       Iris-setosa        1      Iris-setosa
30       Iris-setosa        1      Iris-setosa
31       Iris-setosa        1      Iris-setosa
32       Iris-setosa        1      Iris-setosa
33       Iris-setosa        1      Iris-setosa
34       Iris-setosa        1      Iris-setosa
35       Iris-setosa        1      Iris-setosa
36       Iris-setosa        1      Iris-setosa
37       Iris-setosa        1      Iris-setosa
38       Iris-setosa        1      Iris-setosa
39       Iris-setosa        1      Iris-setosa
40       Iris-setosa        1      Iris-setosa
41       Iris-setosa        1      Iris-setosa
42       Iris-setosa        1      Iris-setosa
43       Iris-setosa        1      Iris-setosa
44       Iris-setosa        1      Iris-setosa
45       Iris-setosa        1      Iris-setosa
46       Iris-setosa        1      Iris-setosa
47       Iris-setosa        1      Iris-setosa
48       Iris-setosa        1      Iris-setosa
49       Iris-setosa        1      Iris-setosa
50   Iris-versicolor        0   Iris-virginica
51   Iris-versicolor        0   Iris-virginica
52   Iris-versicolor        0   Iris-virginica
53   Iris-versicolor        2  Iris-versicolor
54   Iris-versicolor        2  Iris-versicolor
55   Iris-versicolor        2  Iris-versicolor
56   Iris-versicolor        0   Iris-virginica
57   Iris-versicolor        2  Iris-versicolor
58   Iris-versicolor        2  Iris-versicolor
59   Iris-versicolor        2  Iris-versicolor
60   Iris-versicolor        2  Iris-versicolor
61   Iris-versicolor        2  Iris-versicolor
62   Iris-versicolor        2  Iris-versicolor
63   Iris-versicolor        2  Iris-versicolor
64   Iris-versicolor        2  Iris-versicolor
65   Iris-versicolor        0   Iris-virginica
66   Iris-versicolor        2  Iris-versicolor
67   Iris-versicolor        2  Iris-versicolor
68   Iris-versicolor        2  Iris-versicolor
69   Iris-versicolor        2  Iris-versicolor
70   Iris-versicolor        0   Iris-virginica
71   Iris-versicolor        2  Iris-versicolor
72   Iris-versicolor        2  Iris-versicolor
73   Iris-versicolor        2  Iris-versicolor
74   Iris-versicolor        2  Iris-versicolor
75   Iris-versicolor        2  Iris-versicolor
76   Iris-versicolor        0   Iris-virginica
77   Iris-versicolor        0   Iris-virginica
78   Iris-versicolor        2  Iris-versicolor
79   Iris-versicolor        2  Iris-versicolor
80   Iris-versicolor        2  Iris-versicolor
81   Iris-versicolor        2  Iris-versicolor
82   Iris-versicolor        2  Iris-versicolor
83   Iris-versicolor        2  Iris-versicolor
84   Iris-versicolor        2  Iris-versicolor
85   Iris-versicolor        0   Iris-virginica
86   Iris-versicolor        0   Iris-virginica
87   Iris-versicolor        2  Iris-versicolor
88   Iris-versicolor        2  Iris-versicolor
89   Iris-versicolor        2  Iris-versicolor
90   Iris-versicolor        2  Iris-versicolor
91   Iris-versicolor        2  Iris-versicolor
92   Iris-versicolor        2  Iris-versicolor
93   Iris-versicolor        2  Iris-versicolor
94   Iris-versicolor        2  Iris-versicolor
95   Iris-versicolor        2  Iris-versicolor
96   Iris-versicolor        2  Iris-versicolor
97   Iris-versicolor        2  Iris-versicolor
98   Iris-versicolor        2  Iris-versicolor
99   Iris-versicolor        2  Iris-versicolor
100   Iris-virginica        0   Iris-virginica
101   Iris-virginica        2  Iris-versicolor
102   Iris-virginica        0   Iris-virginica
103   Iris-virginica        0   Iris-virginica
104   Iris-virginica        0   Iris-virginica
105   Iris-virginica        0   Iris-virginica
106   Iris-virginica        2  Iris-versicolor
107   Iris-virginica        0   Iris-virginica
108   Iris-virginica        0   Iris-virginica
109   Iris-virginica        0   Iris-virginica
110   Iris-virginica        0   Iris-virginica
111   Iris-virginica        0   Iris-virginica
112   Iris-virginica        0   Iris-virginica
113   Iris-virginica        2  Iris-versicolor
114   Iris-virginica        0   Iris-virginica
115   Iris-virginica        0   Iris-virginica
116   Iris-virginica        0   Iris-virginica
117   Iris-virginica        0   Iris-virginica
118   Iris-virginica        0   Iris-virginica
119   Iris-virginica        2  Iris-versicolor
120   Iris-virginica        0   Iris-virginica
121   Iris-virginica        2  Iris-versicolor
122   Iris-virginica        0   Iris-virginica
123   Iris-virginica        0   Iris-virginica
124   Iris-virginica        0   Iris-virginica
125   Iris-virginica        0   Iris-virginica
126   Iris-virginica        0   Iris-virginica
127   Iris-virginica        0   Iris-virginica
128   Iris-virginica        0   Iris-virginica
129   Iris-virginica        0   Iris-virginica
130   Iris-virginica        0   Iris-virginica
131   Iris-virginica        0   Iris-virginica
132   Iris-virginica        0   Iris-virginica
133   Iris-virginica        2  Iris-versicolor
134   Iris-virginica        2  Iris-versicolor
135   Iris-virginica        0   Iris-virginica
136   Iris-virginica        0   Iris-virginica
137   Iris-virginica        0   Iris-virginica
138   Iris-virginica        0   Iris-virginica
139   Iris-virginica        0   Iris-virginica
140   Iris-virginica        0   Iris-virginica
141   Iris-virginica        0   Iris-virginica
142   Iris-virginica        2  Iris-versicolor
143   Iris-virginica        0   Iris-virginica
144   Iris-virginica        0   Iris-virginica
145   Iris-virginica        0   Iris-virginica
146   Iris-virginica        0   Iris-virginica
147   Iris-virginica        0   Iris-virginica
148   Iris-virginica        0   Iris-virginica
149   Iris-virginica        0   Iris-virginica
</pre></div>
</div>
</div>
</div>
</section>
<section id="clustering-pada-data-iris-menggunakan-k-means-dengan-jumlah-cluster-4">
<h2><strong>6. Clustering pada data Iris menggunakan K-Means dengan jumlah cluster 4</strong><a class="headerlink" href="#clustering-pada-data-iris-menggunakan-k-means-dengan-jumlah-cluster-4" title="Link to this heading">#</a></h2>
<p>Kode di atas bertujuan untuk mengelompokkan data iris ke dalam empat kelompok (cluster) menggunakan algoritma KMeans. Proses dimulai dengan membaca data fitur iris dari file Excel, kemudian data tersebut dinormalisasi agar setiap fitur memiliki skala yang sama sehingga hasil clustering menjadi lebih akurat. Setelah itu, model KMeans dijalankan dengan jumlah cluster sebanyak empat untuk menemukan pola pengelompokan dalam data tanpa menggunakan label asli. Selanjutnya, hasil cluster yang diperoleh dipetakan ke kelas asli berdasarkan dominasi kelas dalam masing-masing cluster, sehingga memungkinkan evaluasi akurasi clustering terhadap label sebenarnya. Kode ini juga menghitung dan menampilkan beberapa metrik penting seperti jumlah iterasi hingga konvergensi, inertia sebagai ukuran seberapa rapat cluster, serta silhouette score yang mengukur kualitas pemisahan cluster. Akhirnya, hasil clustering beserta prediksi kelas disimpan ke file Excel dan juga ditampilkan distribusi data dari tiap kelas asli dalam cluster yang terbentuk, sehingga dapat dianalisis lebih lanjut efektivitas metode clustering tersebut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.cluster</span><span class="w"> </span><span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">silhouette_score</span><span class="p">,</span> <span class="n">accuracy_score</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># Membaca dataset iris dari file Excel</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s2">&quot;data_iris.xlsx&quot;</span><span class="p">)</span>

<span class="c1"># Memilih kolom fitur yang akan digunakan untuk proses clustering</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;sepal length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal width&#39;</span><span class="p">,</span> <span class="s1">&#39;petal length&#39;</span><span class="p">,</span> <span class="s1">&#39;petal width&#39;</span><span class="p">]]</span>

<span class="c1"># Melakukan skala fitur agar berada dalam rentang 0 sampai 1</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">scaled_features</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

<span class="c1"># Menginisialisasi model KMeans dengan jumlah cluster 4 sesuai permintaan</span>
<span class="n">K</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">K</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>
<span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">scaled_features</span><span class="p">)</span>

<span class="c1"># Menyimpan label cluster hasil clustering ke dalam dataframe</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;cluster&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span>

<span class="c1"># Menampilkan jumlah iterasi yang dibutuhkan sampai model mencapai konvergensi</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Jumlah iterasi hingga stabil: </span><span class="si">{</span><span class="n">kmeans</span><span class="o">.</span><span class="n">n_iter_</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="c1"># Menampilkan nilai inertia, ukuran total jarak dalam cluster yang ingin diminimalkan</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Inertia (jumlah kuadrat jarak dalam cluster): </span><span class="si">{</span><span class="n">kmeans</span><span class="o">.</span><span class="n">inertia_</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="c1"># Menghitung skor silhouette yang mengukur seberapa baik cluster terbentuk</span>
<span class="n">sil_score</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">scaled_features</span><span class="p">,</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Skor Silhouette: </span><span class="si">{</span><span class="n">sil_score</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Membuat pemetaan cluster ke kelas dominan berdasarkan label asli</span>
<span class="n">mapping</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;cluster&#39;</span><span class="p">)[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span>
    <span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">mode</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># Kelas paling sering muncul dalam cluster</span>
    <span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
<span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;predicted_class&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;cluster&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">mapping</span><span class="p">)</span>

<span class="c1"># Membandingkan hasil prediksi cluster dengan label asli menggunakan akurasi</span>
<span class="n">y_true</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;predicted_class&#39;</span><span class="p">]</span>

<span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Akurasi hasil clustering terhadap label sebenarnya: </span><span class="si">{</span><span class="n">acc</span><span class="si">:</span><span class="s2">.4%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Menampilkan tabel distribusi jumlah data tiap kelas asli di setiap cluster</span>
<span class="n">dist</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">crosstab</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;cluster&#39;</span><span class="p">],</span> <span class="n">rownames</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Kelas&#39;</span><span class="p">],</span> <span class="n">colnames</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Cluster&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Distribusi data tiap kelas pada cluster:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dist</span><span class="p">)</span>

<span class="c1"># Menyimpan hasil clustering dan prediksi ke file Excel baru</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s2">&quot;hasil_iris_kmeans_k4.xlsx&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Menampilkan seluruh data dengan kolom kelas asli, cluster, dan prediksi</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_rows&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;Class&#39;</span><span class="p">,</span> <span class="s1">&#39;cluster&#39;</span><span class="p">,</span> <span class="s1">&#39;predicted_class&#39;</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Jumlah iterasi hingga stabil: 6
Inertia (jumlah kuadrat jarak dalam cluster): 5.5417
Skor Silhouette: 0.4435

Akurasi hasil clustering terhadap label sebenarnya: 84.6667%

Distribusi data tiap kelas pada cluster:
Cluster           0   1   2   3
Kelas                          
Iris-setosa       0  50   0   0
Iris-versicolor  21   0  29   0
Iris-virginica   21   0   2  27
               Class  cluster  predicted_class
0        Iris-setosa        1      Iris-setosa
1        Iris-setosa        1      Iris-setosa
2        Iris-setosa        1      Iris-setosa
3        Iris-setosa        1      Iris-setosa
4        Iris-setosa        1      Iris-setosa
5        Iris-setosa        1      Iris-setosa
6        Iris-setosa        1      Iris-setosa
7        Iris-setosa        1      Iris-setosa
8        Iris-setosa        1      Iris-setosa
9        Iris-setosa        1      Iris-setosa
10       Iris-setosa        1      Iris-setosa
11       Iris-setosa        1      Iris-setosa
12       Iris-setosa        1      Iris-setosa
13       Iris-setosa        1      Iris-setosa
14       Iris-setosa        1      Iris-setosa
15       Iris-setosa        1      Iris-setosa
16       Iris-setosa        1      Iris-setosa
17       Iris-setosa        1      Iris-setosa
18       Iris-setosa        1      Iris-setosa
19       Iris-setosa        1      Iris-setosa
20       Iris-setosa        1      Iris-setosa
21       Iris-setosa        1      Iris-setosa
22       Iris-setosa        1      Iris-setosa
23       Iris-setosa        1      Iris-setosa
24       Iris-setosa        1      Iris-setosa
25       Iris-setosa        1      Iris-setosa
26       Iris-setosa        1      Iris-setosa
27       Iris-setosa        1      Iris-setosa
28       Iris-setosa        1      Iris-setosa
29       Iris-setosa        1      Iris-setosa
30       Iris-setosa        1      Iris-setosa
31       Iris-setosa        1      Iris-setosa
32       Iris-setosa        1      Iris-setosa
33       Iris-setosa        1      Iris-setosa
34       Iris-setosa        1      Iris-setosa
35       Iris-setosa        1      Iris-setosa
36       Iris-setosa        1      Iris-setosa
37       Iris-setosa        1      Iris-setosa
38       Iris-setosa        1      Iris-setosa
39       Iris-setosa        1      Iris-setosa
40       Iris-setosa        1      Iris-setosa
41       Iris-setosa        1      Iris-setosa
42       Iris-setosa        1      Iris-setosa
43       Iris-setosa        1      Iris-setosa
44       Iris-setosa        1      Iris-setosa
45       Iris-setosa        1      Iris-setosa
46       Iris-setosa        1      Iris-setosa
47       Iris-setosa        1      Iris-setosa
48       Iris-setosa        1      Iris-setosa
49       Iris-setosa        1      Iris-setosa
50   Iris-versicolor        0  Iris-versicolor
51   Iris-versicolor        0  Iris-versicolor
52   Iris-versicolor        0  Iris-versicolor
53   Iris-versicolor        2  Iris-versicolor
54   Iris-versicolor        0  Iris-versicolor
55   Iris-versicolor        2  Iris-versicolor
56   Iris-versicolor        0  Iris-versicolor
57   Iris-versicolor        2  Iris-versicolor
58   Iris-versicolor        0  Iris-versicolor
59   Iris-versicolor        2  Iris-versicolor
60   Iris-versicolor        2  Iris-versicolor
61   Iris-versicolor        0  Iris-versicolor
62   Iris-versicolor        2  Iris-versicolor
63   Iris-versicolor        0  Iris-versicolor
64   Iris-versicolor        2  Iris-versicolor
65   Iris-versicolor        0  Iris-versicolor
66   Iris-versicolor        2  Iris-versicolor
67   Iris-versicolor        2  Iris-versicolor
68   Iris-versicolor        2  Iris-versicolor
69   Iris-versicolor        2  Iris-versicolor
70   Iris-versicolor        0  Iris-versicolor
71   Iris-versicolor        2  Iris-versicolor
72   Iris-versicolor        0  Iris-versicolor
73   Iris-versicolor        2  Iris-versicolor
74   Iris-versicolor        0  Iris-versicolor
75   Iris-versicolor        0  Iris-versicolor
76   Iris-versicolor        0  Iris-versicolor
77   Iris-versicolor        0  Iris-versicolor
78   Iris-versicolor        0  Iris-versicolor
79   Iris-versicolor        2  Iris-versicolor
80   Iris-versicolor        2  Iris-versicolor
81   Iris-versicolor        2  Iris-versicolor
82   Iris-versicolor        2  Iris-versicolor
83   Iris-versicolor        0  Iris-versicolor
84   Iris-versicolor        2  Iris-versicolor
85   Iris-versicolor        0  Iris-versicolor
86   Iris-versicolor        0  Iris-versicolor
87   Iris-versicolor        2  Iris-versicolor
88   Iris-versicolor        2  Iris-versicolor
89   Iris-versicolor        2  Iris-versicolor
90   Iris-versicolor        2  Iris-versicolor
91   Iris-versicolor        0  Iris-versicolor
92   Iris-versicolor        2  Iris-versicolor
93   Iris-versicolor        2  Iris-versicolor
94   Iris-versicolor        2  Iris-versicolor
95   Iris-versicolor        2  Iris-versicolor
96   Iris-versicolor        2  Iris-versicolor
97   Iris-versicolor        0  Iris-versicolor
98   Iris-versicolor        2  Iris-versicolor
99   Iris-versicolor        2  Iris-versicolor
100   Iris-virginica        3   Iris-virginica
101   Iris-virginica        0  Iris-versicolor
102   Iris-virginica        3   Iris-virginica
103   Iris-virginica        0  Iris-versicolor
104   Iris-virginica        3   Iris-virginica
105   Iris-virginica        3   Iris-virginica
106   Iris-virginica        2  Iris-versicolor
107   Iris-virginica        3   Iris-virginica
108   Iris-virginica        0  Iris-versicolor
109   Iris-virginica        3   Iris-virginica
110   Iris-virginica        0  Iris-versicolor
111   Iris-virginica        0  Iris-versicolor
112   Iris-virginica        3   Iris-virginica
113   Iris-virginica        0  Iris-versicolor
114   Iris-virginica        0  Iris-versicolor
115   Iris-virginica        3   Iris-virginica
116   Iris-virginica        0  Iris-versicolor
117   Iris-virginica        3   Iris-virginica
118   Iris-virginica        3   Iris-virginica
119   Iris-virginica        2  Iris-versicolor
120   Iris-virginica        3   Iris-virginica
121   Iris-virginica        0  Iris-versicolor
122   Iris-virginica        3   Iris-virginica
123   Iris-virginica        0  Iris-versicolor
124   Iris-virginica        3   Iris-virginica
125   Iris-virginica        3   Iris-virginica
126   Iris-virginica        0  Iris-versicolor
127   Iris-virginica        0  Iris-versicolor
128   Iris-virginica        0  Iris-versicolor
129   Iris-virginica        3   Iris-virginica
130   Iris-virginica        3   Iris-virginica
131   Iris-virginica        3   Iris-virginica
132   Iris-virginica        3   Iris-virginica
133   Iris-virginica        0  Iris-versicolor
134   Iris-virginica        0  Iris-versicolor
135   Iris-virginica        3   Iris-virginica
136   Iris-virginica        3   Iris-virginica
137   Iris-virginica        0  Iris-versicolor
138   Iris-virginica        0  Iris-versicolor
139   Iris-virginica        3   Iris-virginica
140   Iris-virginica        3   Iris-virginica
141   Iris-virginica        3   Iris-virginica
142   Iris-virginica        0  Iris-versicolor
143   Iris-virginica        3   Iris-virginica
144   Iris-virginica        3   Iris-virginica
145   Iris-virginica        3   Iris-virginica
146   Iris-virginica        0  Iris-versicolor
147   Iris-virginica        0  Iris-versicolor
148   Iris-virginica        3   Iris-virginica
149   Iris-virginica        0  Iris-versicolor
</pre></div>
</div>
</div>
</div>
</section>
<section id="kesimpulan">
<h2><strong>7. Kesimpulan</strong><a class="headerlink" href="#kesimpulan" title="Link to this heading">#</a></h2>
<p>Pada analisis clustering menggunakan metode K-Means dengan variasi jumlah cluster (K), ditemukan hasil evaluasi yang berbeda-beda untuk masing-masing nilai K yang diuji, yaitu K = 2, K = 3, dan K = 4. Evaluasi dilakukan dengan menggunakan dua metrik utama, yaitu nilai inertia (sum of squared errors/SSE) dan silhouette score, yang masing-masing menggambarkan kualitas cluster dari sisi internal dan eksternal.</p>
<p>Untuk <strong>K = 2</strong>, nilai inertia sebesar 12.1437 menunjukkan bahwa rata-rata jarak titik data terhadap pusat cluster masih cukup besar, yang mengindikasikan cluster masih agak longgar. Namun, nilai silhouette score sebesar 0.6295 menunjukkan bahwa cluster yang terbentuk cukup baik, karena nilai ini cukup mendekati 1 yang merupakan nilai ideal. Silhouette score yang tinggi berarti bahwa tiap data lebih dekat dengan pusat cluster sendiri dibandingkan pusat cluster lain, sehingga cluster relatif terpisah dan memiliki struktur yang jelas. Hal ini mengindikasikan bahwa K = 2 menghasilkan pembagian cluster yang cukup natural dan representatif untuk data yang dianalisis.</p>
<p>Pada pengujian dengan <strong>K = 3</strong>, nilai inertia menurun menjadi 7.1386, yang berarti titik-titik data secara keseluruhan berada lebih dekat dengan pusat cluster masing-masing. Secara matematis, penurunan inertia mengindikasikan cluster menjadi lebih rapat. Namun, nilai silhouette score juga mengalami penurunan cukup signifikan menjadi 0.4825. Penurunan ini menunjukkan bahwa meskipun cluster menjadi lebih rapat, kualitas pemisahan antar cluster menurun, dengan beberapa titik data yang mulai berada pada batas antara cluster. Hal ini dapat mengindikasikan adanya tumpang tindih antar cluster, atau cluster yang kurang jelas batasnya.</p>
<p>Selanjutnya, pada <strong>K = 4</strong>, nilai inertia kembali turun menjadi 5.5417, yang menunjukkan cluster semakin kompak dan titik-titik data lebih dekat ke pusatnya masing-masing. Namun demikian, nilai silhouette score mengalami penurunan lebih jauh menjadi 0.4435, yang menunjukkan semakin memburuknya kualitas pemisahan cluster. Penurunan silhouette score ini dapat disebabkan oleh terlalu banyak cluster yang memecah data secara berlebihan sehingga ada overlap antar cluster atau cluster yang tidak bermakna secara struktural.</p>
<p>Berdasarkan analisis kedua metrik tersebut, dapat disimpulkan bahwa meskipun nilai inertia cenderung menurun seiring bertambahnya jumlah cluster (yang memang diharapkan karena cluster lebih kecil dan rapat), nilai silhouette score yang menjadi indikator utama kualitas pemisahan cluster menunjukkan penurunan setelah K = 2. Oleh karena itu, <strong>K = 2 merupakan jumlah cluster yang paling optimal</strong> karena memberikan keseimbangan terbaik antara kepadatan cluster (internal cohesion) dan keterpisahan antar cluster (separation). Nilai silhouette score yang paling tinggi pada K = 2 memperkuat keputusan ini, menandakan cluster yang dihasilkan lebih jelas, terpisah, dan bermakna secara statistik dibandingkan dengan K lainnya.</p>
<p>Dengan demikian, untuk dataset yang digunakan, penggunaan dua cluster cukup untuk merepresentasikan pola utama dalam data secara efektif tanpa menimbulkan kompleksitas berlebih atau penurunan kualitas clustering.</p>
</section>
<section id="metode-elbow">
<h2><strong>8. Metode Elbow</strong><a class="headerlink" href="#metode-elbow" title="Link to this heading">#</a></h2>
<p><strong>Metode Elbow dalam Penentuan Jumlah Klaster Optimal</strong></p>
<p>Dalam analisis klaster, salah satu tantangan utama adalah menentukan jumlah klaster (ùëò) yang paling sesuai untuk memetakan data secara efektif. Jika jumlah klaster terlalu sedikit, pengelompokan akan terlalu kasar dan tidak mampu menangkap pola yang berbeda di dalam data. Sebaliknya, jika jumlah klaster terlalu banyak, model akan terlalu kompleks dan bisa menyebabkan overfitting, yaitu pengelompokan yang terlalu spesifik dan kurang generalisasi.</p>
<p>Metode Elbow adalah salah satu teknik populer yang digunakan untuk membantu menentukan nilai ùëò yang optimal. Prinsip utamanya adalah dengan memantau perubahan nilai <em>inertia</em> atau <em>Within-Cluster Sum of Squares</em> (WCSS) saat jumlah klaster bertambah. WCSS adalah ukuran seberapa baik data dalam setiap klaster terkelompok dengan menghitung total jarak kuadrat antara titik data dan pusat klasternya. Semakin kecil nilai WCSS, semakin rapat klaster tersebut.</p>
<p>Langkahnya sebagai berikut:</p>
<ol class="arabic simple">
<li><p>Jalankan algoritma klaster (misalnya K-Means) untuk beberapa nilai ùëò yang berbeda, misalnya dari 1 hingga 10.</p></li>
<li><p>Hitung WCSS untuk setiap ùëò.</p></li>
<li><p>Plot grafik WCSS terhadap ùëò.</p></li>
</ol>
<p>Grafik ini biasanya menunjukkan penurunan WCSS yang tajam saat ùëò meningkat dari 1, karena klaster yang lebih banyak membuat data lebih tersegmentasi dan jarak dalam klaster mengecil. Namun, setelah mencapai suatu titik tertentu, penurunan WCSS mulai melambat dan grafik cenderung mendatar. Titik di mana perubahan penurunan ini berkurang drastis dan membentuk sudut yang menyerupai siku (elbow) disebut titik <em>elbow</em>.</p>
<p>Titik <em>elbow</em> ini penting karena menunjukkan nilai ùëò di mana penambahan klaster baru tidak lagi memberikan perbaikan signifikan dalam pengelompokan data. Dengan kata lain, klaster tersebut sudah cukup untuk mewakili struktur data secara efisien tanpa menambah kompleksitas yang tidak perlu.</p>
<p>Sebagai contoh dari hasil metode Elbow yang umum pada dataset Iris, nilai optimal ùëò sering kali berada pada 3. Pada titik ini, WCSS mengalami penurunan cukup besar dibandingkan nilai ùëò sebelumnya, menandakan klasterisasi yang efektif. Setelah ùëò = 3, penurunan WCSS semakin kecil sehingga menandakan pembagian data ke dalam lebih banyak klaster tidak memberikan manfaat signifikan.</p>
<p>Kesimpulannya, metode Elbow memudahkan pemilihan jumlah klaster optimal secara visual dan empiris dengan mempertimbangkan keseimbangan antara kompleksitas model dan kualitas pengelompokan.</p>
<p>Berikut Adalah Contoh Elbow Method :</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.cluster</span><span class="w"> </span><span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">MinMaxScaler</span>

<span class="c1"># Load dataset</span>
<span class="n">iris</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;data_iris.xlsx&#39;</span><span class="p">)</span>

<span class="c1"># Pilih kolom fitur: petal length, petal width, sepal length, sepal width</span>
<span class="n">iris_x</span> <span class="o">=</span> <span class="n">iris</span><span class="p">[[</span><span class="s1">&#39;petal length&#39;</span><span class="p">,</span> <span class="s1">&#39;petal width&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal width&#39;</span><span class="p">]]</span>

<span class="c1"># Konversi ke numpy array</span>
<span class="n">x_iris</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">iris_x</span><span class="p">)</span>

<span class="c1"># Scaling fitur ke rentang 0-1</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">x_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_iris</span><span class="p">)</span>

<span class="c1"># Hitung WCSS untuk berbagai jumlah cluster (1 sampai 10)</span>
<span class="n">wcss</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">):</span>
    <span class="n">km</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">km</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_scaled</span><span class="p">)</span>   <span class="c1"># gunakan data yang sudah di-scaling</span>
    <span class="n">wcss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">km</span><span class="o">.</span><span class="n">inertia_</span><span class="p">)</span>

<span class="c1"># Visualisasi Elbow Method</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">7</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">),</span> <span class="n">wcss</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;8&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;WCSS&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Clusters (k)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Elbow Method for Optimal k&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/61c673b30feb5b7ea15b1c21bd8b3d73cdda6b59ae627a3694fb0f0f6814c8b0.png" src="_images/61c673b30feb5b7ea15b1c21bd8b3d73cdda6b59ae627a3694fb0f0f6814c8b0.png" />
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="pengenalan-fuzzy-c-means">
<h1><strong>Pengenalan Fuzzy C-Means</strong><a class="headerlink" href="#pengenalan-fuzzy-c-means" title="Link to this heading">#</a></h1>
<section id="konsep-fuzzy-c-means">
<h2><strong>Konsep Fuzzy C-Means</strong><a class="headerlink" href="#konsep-fuzzy-c-means" title="Link to this heading">#</a></h2>
<p>Fuzzy C-Means adalah adalah sebuah metode <em>clustering</em> atau pengelompokan data yang menggunakan pendekatan logika fuzzy, di mana setiap data dapat menjadi anggota dari lebih dari satu cluster dengan tingkat keanggotaan tertentu. Berbeda dengan metode <em>hard clustering</em> seperti K-Means yang menetapkan tiap data hanya pada satu cluster secara mutlak, FCM memberikan nilai keanggotaan (membership) antara 0 dan 1 untuk setiap data terhadap semua cluster, sehingga menggambarkan ketidakpastian atau ambiguitas yang mungkin ada dalam proses pengelompokan. Nilai keanggotaan ini menunjukkan seberapa kuat suatu data termasuk ke dalam suatu cluster. FCM bekerja dengan meminimalkan fungsi objektif yang mempertimbangkan jarak antara data dan pusat cluster, yang diperhitungkan secara berbobot menggunakan derajat keanggotaan fuzzy. Metode ini sangat berguna dalam kasus-kasus di mana batas antar kelompok data tidak tegas atau tumpang tindih, seperti dalam pengolahan citra, data medis, dan analisis spasial.</p>
</section>
<section id="langkah-algoritma">
<h2><strong>Langkah Algoritma</strong><a class="headerlink" href="#langkah-algoritma" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Inisialisasi jumlah cluster c, nilai m, dan matriks keanggotaan U</p></li>
<li><p>Iterasi sampai konvergen:</p></li>
</ol>
<ul class="simple">
<li><p>Hitung pusat cluster c ij</p></li>
<li><p>Update matriks keanggotaan U ij</p></li>
<li><p>Hitung fungsi objektif j</p></li>
</ul>
<p>Berikut adalah <strong>rumus update derajat keanggotaan</strong> dalam algoritma <strong>Fuzzy C-Means (FCM)</strong>:</p>
<div class="math notranslate nohighlight">
\[
u_{ij} = \left( \sum_{k=1}^{c} \left( \frac{\|x_i - v_j\|}{\|x_i - v_k\|} \right)^{\frac{2}{m - 1}} \right)^{-1}
\]</div>
<p>Keterangan:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(u_{ij}\)</span> = derajat keanggotaan data ke-<strong>i</strong> terhadap cluster ke-<strong>j</strong></p></li>
<li><p><span class="math notranslate nohighlight">\(c\)</span> = jumlah total cluster</p></li>
<li><p><span class="math notranslate nohighlight">\(x_i\)</span> = data ke-<strong>i</strong></p></li>
<li><p><span class="math notranslate nohighlight">\(v_j\)</span> = pusat cluster ke-<strong>j</strong></p></li>
<li><p><span class="math notranslate nohighlight">\(m\)</span> = parameter fuzzy (biasanya <span class="math notranslate nohighlight">\(m = 2\)</span>) yang mengontrol tingkat kekaburan (<em>fuzziness</em>)</p></li>
<li><p><span class="math notranslate nohighlight">\(\|x_i - v_j\|\)</span> = jarak (biasanya Euclidean) antara data <span class="math notranslate nohighlight">\(x_i\)</span> dan pusat cluster <span class="math notranslate nohighlight">\(v_j\)</span></p></li>
</ul>
<p>Inti dari rumus:</p>
<p>Rumus ini membandingkan jarak antara data <span class="math notranslate nohighlight">\(x_i\)</span> dengan pusat cluster <span class="math notranslate nohighlight">\(v_j\)</span>, relatif terhadap semua pusat cluster yang ada. Jika <span class="math notranslate nohighlight">\(x_i\)</span> lebih dekat ke <span class="math notranslate nohighlight">\(v_j\)</span>, maka nilai <span class="math notranslate nohighlight">\(u_{ij}\)</span> akan lebih besar. Sebaliknya, jika lebih jauh, nilai <span class="math notranslate nohighlight">\(u_{ij}\)</span> akan kecil. Nilai ini mencerminkan <strong>seberapa besar kemungkinan data tersebut menjadi anggota suatu cluster</strong>, dan hasil akhirnya akan memiliki nilai keanggotaan yang totalnya 1 untuk setiap data.</p>
<p>Berikut adalah <strong>rumus update pusat cluster</strong> dalam algoritma <strong>Fuzzy C-Means (FCM)</strong>:</p>
<div class="math notranslate nohighlight">
\[
v_j = \frac{\sum_{i=1}^n u_{ij}^m \cdot x_i}{\sum_{i=1}^n u_{ij}^m}
\]</div>
<p>Keterangan:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(v_j\)</span> = pusat (centroid) dari cluster ke-<strong>j</strong></p></li>
<li><p><span class="math notranslate nohighlight">\(n\)</span> = jumlah total data</p></li>
<li><p><span class="math notranslate nohighlight">\(u_{ij}\)</span> = derajat keanggotaan data ke-<strong>i</strong> terhadap cluster ke-<strong>j</strong></p></li>
<li><p><span class="math notranslate nohighlight">\(m\)</span> = parameter <em>fuzziness</em> (biasanya <span class="math notranslate nohighlight">\(m = 2\)</span>)</p></li>
<li><p><span class="math notranslate nohighlight">\(x_i\)</span> = data ke-<strong>i</strong></p></li>
</ul>
<p>Inti dari rumus:</p>
<p>Rumus ini menghitung pusat cluster <span class="math notranslate nohighlight">\(v_j\)</span> sebagai <strong>rata-rata tertimbang</strong> dari semua data, di mana bobotnya adalah derajat keanggotaan fuzzy yang sudah dipangkatkan oleh <span class="math notranslate nohighlight">\(m\)</span>. Artinya, data yang memiliki keanggotaan tinggi terhadap cluster <span class="math notranslate nohighlight">\(j\)</span> akan memberi pengaruh lebih besar dalam menentukan posisi pusat cluster tersebut.</p>
<p>Setelah pusat cluster diperbarui, algoritma FCM akan melanjutkan ke proses <strong>update derajat keanggotaan</strong> lagi, dan begitu seterusnya hingga hasilnya konvergen (tidak banyak berubah).</p>
<p>Gunakan matriks keanggotaan terbaru untuk menghitung pusat baru.</p>
</section>
<section id="contoh-penerapan-dalam-bentuk-code">
<h2><strong>Contoh penerapan dalam bentuk code</strong><a class="headerlink" href="#contoh-penerapan-dalam-bentuk-code" title="Link to this heading">#</a></h2>
<p>Buatkan nilai keanggotaan acak dengan data</p>
<p>Data untuk dianalisis
Data (xi) | x1 | x2</p>
<p>1  |  1  | 2</p>
<p>2  |  2  | 3</p>
<p>3  |  3  | 4</p>
<p>4  |  6  | 7</p>
<p>5  |  7  | 8</p>
<p>Data  | Dc1 | Dc2</p>
<p>1  |  0,5  | 0,5</p>
<p>2  |  0,7  | 0,3</p>
<p>3  |  0,8  | 0,2</p>
<p>4  |  0,7  | 0,3</p>
<p>5  |  0,6  | 0,4</p>
<p>Buatkan program tahapan tahapan yaitu U11, U12, U21, U22, U31, U32, U41, U42, U51, U52 pakai library keanggotaan cukup 2 iterasi dan setiap iterasi mendapatkan keanggotaan dan pusat cluster dan output hasil cluster</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># Data xi</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="p">])</span>

<span class="c1"># Derajat keanggotaan awal (u_ij) untuk 2 cluster</span>
<span class="n">U</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
    <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]</span>
<span class="p">])</span>

<span class="c1"># Parameter fuzziness</span>
<span class="n">m</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c1"># Fungsi menghitung pusat cluster dan menghasilkan titik pusat (centroid) masing-masing cluste</span>
<span class="k">def</span><span class="w"> </span><span class="nf">compute_centroids</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">m</span><span class="p">):</span>
    <span class="n">um</span> <span class="o">=</span> <span class="n">U</span> <span class="o">**</span> <span class="n">m</span>
    <span class="n">centroids</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">):</span>
        <span class="n">numerator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">um</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="n">data</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">denominator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">um</span><span class="p">[:,</span> <span class="n">j</span><span class="p">])</span>
        <span class="n">centroids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">numerator</span> <span class="o">/</span> <span class="n">denominator</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">centroids</span><span class="p">)</span>

<span class="c1"># Fungsi update keanggotaan</span>
<span class="k">def</span><span class="w"> </span><span class="nf">update_membership</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">centroids</span><span class="p">,</span> <span class="n">m</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">U_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">):</span>
            <span class="n">denom</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">):</span>
                <span class="n">dist_ratio</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">centroids</span><span class="p">[</span><span class="n">j</span><span class="p">])</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">centroids</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
                <span class="n">denom</span> <span class="o">+=</span> <span class="n">dist_ratio</span> <span class="o">**</span> <span class="p">(</span><span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="n">m</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
            <span class="n">U_new</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">denom</span>
    <span class="k">return</span> <span class="n">U_new</span>

<span class="c1"># Iterasi FCM</span>
<span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== Iterasi </span><span class="si">{</span><span class="n">iteration</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2"> ===&quot;</span><span class="p">)</span>
    <span class="n">centroids</span> <span class="o">=</span> <span class="n">compute_centroids</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Pusat Cluster (Cj):&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">centroids</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;C</span><span class="si">{</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2"> = </span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">U</span> <span class="o">=</span> <span class="n">update_membership</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">centroids</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Derajat Keanggotaan (Uij):&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Data </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">: U1 = </span><span class="si">{</span><span class="n">U</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, U2 = </span><span class="si">{</span><span class="n">U</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Output hasil cluster</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== Hasil Cluster (berdasarkan nilai keanggotaan tertinggi) ===&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">cluster</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">U</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Data </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2">): Cluster </span><span class="si">{</span><span class="n">cluster</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=== Iterasi 1 ===
Pusat Cluster (Cj):
C1 = [3.86098655 4.86098655]
C2 = [3.50793651 4.50793651]

Derajat Keanggotaan (Uij):
Data 1: U1 = 0.4345, U2 = 0.5655
Data 2: U1 = 0.3963, U2 = 0.6037
Data 3: U1 = 0.2582, U2 = 0.7418
Data 4: U1 = 0.5758, U2 = 0.4242
Data 5: U1 = 0.5531, U2 = 0.4469

=== Iterasi 2 ===
Pusat Cluster (Cj):
C1 = [4.60336854 5.60336854]
C2 = [3.20743845 4.20743845]

Derajat Keanggotaan (Uij):
Data 1: U1 = 0.2729, U2 = 0.7271
Data 2: U1 = 0.1770, U2 = 0.8230
Data 3: U1 = 0.0165, U2 = 0.9835
Data 4: U1 = 0.7999, U2 = 0.2001
Data 5: U1 = 0.7146, U2 = 0.2854

=== Hasil Cluster (berdasarkan nilai keanggotaan tertinggi) ===
Data 1 ([1 2]): Cluster 2
Data 2 ([2 3]): Cluster 2
Data 3 ([3 4]): Cluster 2
Data 4 ([6 7]): Cluster 1
Data 5 ([7 8]): Cluster 1
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># Data xi</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="p">])</span>

<span class="c1"># Derajat keanggotaan awal (u_ij)</span>
<span class="n">U</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
    <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]</span>
<span class="p">])</span>

<span class="c1"># Parameter</span>
<span class="n">m</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">max_iter</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">tolerance</span> <span class="o">=</span> <span class="mf">1e-5</span>

<span class="k">def</span><span class="w"> </span><span class="nf">compute_centroids</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">m</span><span class="p">):</span>
    <span class="n">um</span> <span class="o">=</span> <span class="n">U</span> <span class="o">**</span> <span class="n">m</span>
    <span class="n">centroids</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">):</span>
        <span class="n">numerator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">um</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="n">data</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">denominator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">um</span><span class="p">[:,</span> <span class="n">j</span><span class="p">])</span>
        <span class="n">centroids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">numerator</span> <span class="o">/</span> <span class="n">denominator</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">centroids</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">update_membership</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">centroids</span><span class="p">,</span> <span class="n">m</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">U_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">):</span>
            <span class="n">denom</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">):</span>
                <span class="n">dist_j</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">centroids</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
                <span class="n">dist_k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">centroids</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
                <span class="n">ratio</span> <span class="o">=</span> <span class="p">(</span><span class="n">dist_j</span> <span class="o">/</span> <span class="n">dist_k</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="n">m</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span> <span class="k">if</span> <span class="n">dist_k</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">1e-10</span>
                <span class="n">denom</span> <span class="o">+=</span> <span class="n">ratio</span>
            <span class="n">U_new</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">denom</span>
    <span class="k">return</span> <span class="n">U_new</span>

<span class="k">def</span><span class="w"> </span><span class="nf">compute_objective</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">centroids</span><span class="p">,</span> <span class="n">m</span><span class="p">):</span>
    <span class="n">J</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">):</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">centroids</span><span class="p">[</span><span class="n">j</span><span class="p">])</span> <span class="o">**</span> <span class="mi">2</span>
            <span class="n">J</span> <span class="o">+=</span> <span class="p">(</span><span class="n">U</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">**</span> <span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">dist</span>
    <span class="k">return</span> <span class="n">J</span>

<span class="n">prev_J</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== Iterasi </span><span class="si">{</span><span class="n">iteration</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2"> ===&quot;</span><span class="p">)</span>
    <span class="n">centroids</span> <span class="o">=</span> <span class="n">compute_centroids</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Pusat Cluster (Cj):&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">centroids</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;C</span><span class="si">{</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2"> = </span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">J</span> <span class="o">=</span> <span class="n">compute_objective</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">centroids</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Fungsi Objektif (Jm) = </span><span class="si">{</span><span class="n">J</span><span class="si">:</span><span class="s2">.5f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">prev_J</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">abs</span><span class="p">(</span><span class="n">J</span> <span class="o">-</span> <span class="n">prev_J</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">tolerance</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Konvergen: Fungsi objektif tidak berubah signifikan.&quot;</span><span class="p">)</span>
        <span class="k">break</span>
    <span class="n">prev_J</span> <span class="o">=</span> <span class="n">J</span>

    <span class="n">U</span> <span class="o">=</span> <span class="n">update_membership</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">centroids</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Derajat Keanggotaan (Uij):&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Data </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">: U1 = </span><span class="si">{</span><span class="n">U</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, U2 = </span><span class="si">{</span><span class="n">U</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== Hasil Akhir Cluster ===&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">cluster</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">U</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Data </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2">): Cluster </span><span class="si">{</span><span class="n">cluster</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=== Iterasi 1 ===
Pusat Cluster (Cj):
C1 = [3.86098655 4.86098655]
C2 = [3.50793651 4.50793651]
Fungsi Objektif (Jm) = 28.60873

Derajat Keanggotaan (Uij):
Data 1: U1 = 0.4345, U2 = 0.5655
Data 2: U1 = 0.3963, U2 = 0.6037
Data 3: U1 = 0.2582, U2 = 0.7418
Data 4: U1 = 0.5758, U2 = 0.4242
Data 5: U1 = 0.5531, U2 = 0.4469

=== Iterasi 2 ===
Pusat Cluster (Cj):
C1 = [4.60336854 5.60336854]
C2 = [3.20743845 4.20743845]
Fungsi Objektif (Jm) = 24.96117

Derajat Keanggotaan (Uij):
Data 1: U1 = 0.2729, U2 = 0.7271
Data 2: U1 = 0.1770, U2 = 0.8230
Data 3: U1 = 0.0165, U2 = 0.9835
Data 4: U1 = 0.7999, U2 = 0.2001
Data 5: U1 = 0.7146, U2 = 0.2854

=== Iterasi 3 ===
Pusat Cluster (Cj):
C1 = [6.00971594 7.00971594]
C2 = [2.43836418 3.43836418]
Fungsi Objektif (Jm) = 13.21509

Derajat Keanggotaan (Uij):
Data 1: U1 = 0.0762, U2 = 0.9238
Data 2: U1 = 0.0118, U2 = 0.9882
Data 3: U1 = 0.0337, U2 = 0.9663
Data 4: U1 = 1.0000, U2 = 0.0000
Data 5: U1 = 0.9550, U2 = 0.0450

=== Iterasi 4 ===
Pusat Cluster (Cj):
C1 = [6.45806457 7.45806457]
C2 = [2.03271073 3.03271073]
Fungsi Objektif (Jm) = 5.00353

Derajat Keanggotaan (Uij):
Data 1: U1 = 0.0346, U2 = 0.9654
Data 2: U1 = 0.0001, U2 = 0.9999
Data 3: U1 = 0.0726, U2 = 0.9274
Data 4: U1 = 0.9868, U2 = 0.0132
Data 5: U1 = 0.9882, U2 = 0.0118

=== Iterasi 5 ===
Pusat Cluster (Cj):
C1 = [6.48792764 7.48792764]
C2 = [1.97473482 2.97473482]
Fungsi Objektif (Jm) = 4.76925

Derajat Keanggotaan (Uij):
Data 1: U1 = 0.0306, U2 = 0.9694
Data 2: U1 = 0.0000, U2 = 1.0000
Data 3: U1 = 0.0795, U2 = 0.9205
Data 4: U1 = 0.9855, U2 = 0.0145
Data 5: U1 = 0.9897, U2 = 0.0103

=== Iterasi 6 ===
Pusat Cluster (Cj):
C1 = [6.48818664 7.48818664]
C2 = [1.96729997 2.96729997]
Fungsi Objektif (Jm) = 4.76650

Derajat Keanggotaan (Uij):
Data 1: U1 = 0.0301, U2 = 0.9699
Data 2: U1 = 0.0001, U2 = 0.9999
Data 3: U1 = 0.0806, U2 = 0.9194
Data 4: U1 = 0.9856, U2 = 0.0144
Data 5: U1 = 0.9898, U2 = 0.0102

=== Iterasi 7 ===
Pusat Cluster (Cj):
C1 = [6.4879658 7.4879658]
C2 = [1.96627272 2.96627272]
Fungsi Objektif (Jm) = 4.76645

Derajat Keanggotaan (Uij):
Data 1: U1 = 0.0301, U2 = 0.9699
Data 2: U1 = 0.0001, U2 = 0.9999
Data 3: U1 = 0.0807, U2 = 0.9193
Data 4: U1 = 0.9856, U2 = 0.0144
Data 5: U1 = 0.9898, U2 = 0.0102

=== Iterasi 8 ===
Pusat Cluster (Cj):
C1 = [6.48791854 7.48791854]
C2 = [1.96612481 2.96612481]
Fungsi Objektif (Jm) = 4.76645

Konvergen: Fungsi objektif tidak berubah signifikan.

=== Hasil Akhir Cluster ===
Data 1 ([1 2]): Cluster 2
Data 2 ([2 3]): Cluster 2
Data 3 ([3 4]): Cluster 2
Data 4 ([6 7]): Cluster 1
Data 5 ([7 8]): Cluster 1
</pre></div>
</div>
</div>
</div>
</section>
<section id="implementasi-kedalam-data-iris">
<h2><strong>Implementasi Kedalam Data Iris</strong><a class="headerlink" href="#implementasi-kedalam-data-iris" title="Link to this heading">#</a></h2>
<p>Kalau sudah paham implementasikan ke data riel data iris</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">google.colab</span><span class="w"> </span><span class="kn">import</span> <span class="n">files</span>
<span class="n">uploaded</span> <span class="o">=</span> <span class="n">files</span><span class="o">.</span><span class="n">upload</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
     <input type="file" id="files-8351e219-285e-408a-8ab2-3c1776387837" name="files[]" multiple disabled
        style="border:none" />
     <output id="result-8351e219-285e-408a-8ab2-3c1776387837">
      Upload widget is only available when the cell has been executed in the
      current browser session. Please rerun this cell to enable.
      </output>
      <script>// Copyright 2017 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

/**
 * @fileoverview Helpers for google.colab Python module.
 */
(function(scope) {
function span(text, styleAttributes = {}) {
  const element = document.createElement('span');
  element.textContent = text;
  for (const key of Object.keys(styleAttributes)) {
    element.style[key] = styleAttributes[key];
  }
  return element;
}

// Max number of bytes which will be uploaded at a time.
const MAX_PAYLOAD_SIZE = 100 * 1024;

function _uploadFiles(inputId, outputId) {
  const steps = uploadFilesStep(inputId, outputId);
  const outputElement = document.getElementById(outputId);
  // Cache steps on the outputElement to make it available for the next call
  // to uploadFilesContinue from Python.
  outputElement.steps = steps;

  return _uploadFilesContinue(outputId);
}

// This is roughly an async generator (not supported in the browser yet),
// where there are multiple asynchronous steps and the Python side is going
// to poll for completion of each step.
// This uses a Promise to block the python side on completion of each step,
// then passes the result of the previous step as the input to the next step.
function _uploadFilesContinue(outputId) {
  const outputElement = document.getElementById(outputId);
  const steps = outputElement.steps;

  const next = steps.next(outputElement.lastPromiseValue);
  return Promise.resolve(next.value.promise).then((value) => {
    // Cache the last promise value to make it available to the next
    // step of the generator.
    outputElement.lastPromiseValue = value;
    return next.value.response;
  });
}

/**
 * Generator function which is called between each async step of the upload
 * process.
 * @param {string} inputId Element ID of the input file picker element.
 * @param {string} outputId Element ID of the output display.
 * @return {!Iterable<!Object>} Iterable of next steps.
 */
function* uploadFilesStep(inputId, outputId) {
  const inputElement = document.getElementById(inputId);
  inputElement.disabled = false;

  const outputElement = document.getElementById(outputId);
  outputElement.innerHTML = '';

  const pickedPromise = new Promise((resolve) => {
    inputElement.addEventListener('change', (e) => {
      resolve(e.target.files);
    });
  });

  const cancel = document.createElement('button');
  inputElement.parentElement.appendChild(cancel);
  cancel.textContent = 'Cancel upload';
  const cancelPromise = new Promise((resolve) => {
    cancel.onclick = () => {
      resolve(null);
    };
  });

  // Wait for the user to pick the files.
  const files = yield {
    promise: Promise.race([pickedPromise, cancelPromise]),
    response: {
      action: 'starting',
    }
  };

  cancel.remove();

  // Disable the input element since further picks are not allowed.
  inputElement.disabled = true;

  if (!files) {
    return {
      response: {
        action: 'complete',
      }
    };
  }

  for (const file of files) {
    const li = document.createElement('li');
    li.append(span(file.name, {fontWeight: 'bold'}));
    li.append(span(
        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +
        `last modified: ${
            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :
                                    'n/a'} - `));
    const percent = span('0% done');
    li.appendChild(percent);

    outputElement.appendChild(li);

    const fileDataPromise = new Promise((resolve) => {
      const reader = new FileReader();
      reader.onload = (e) => {
        resolve(e.target.result);
      };
      reader.readAsArrayBuffer(file);
    });
    // Wait for the data to be ready.
    let fileData = yield {
      promise: fileDataPromise,
      response: {
        action: 'continue',
      }
    };

    // Use a chunked sending to avoid message size limits. See b/62115660.
    let position = 0;
    do {
      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);
      const chunk = new Uint8Array(fileData, position, length);
      position += length;

      const base64 = btoa(String.fromCharCode.apply(null, chunk));
      yield {
        response: {
          action: 'append',
          file: file.name,
          data: base64,
        },
      };

      let percentDone = fileData.byteLength === 0 ?
          100 :
          Math.round((position / fileData.byteLength) * 100);
      percent.textContent = `${percentDone}% done`;

    } while (position < fileData.byteLength);
  }

  // All done.
  yield {
    response: {
      action: 'complete',
    }
  };
}

scope.google = scope.google || {};
scope.google.colab = scope.google.colab || {};
scope.google.colab._files = {
  _uploadFiles,
  _uploadFilesContinue,
};
})(self);
</script> </div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving data_iris.xlsx to data_iris.xlsx
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># Membaca file Excel yang berisi data iris</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;data_iris.xlsx&#39;</span><span class="p">)</span>

<span class="c1"># Mengambil dua fitur numerik: sepal length dan sepal width</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;sepal length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal width&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># Parameter Fuzzy C-Means</span>
<span class="n">m</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># parameter fuzziness (biasanya &gt; 1)</span>
<span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># jumlah cluster yang diinginkan</span>
<span class="n">max_iter</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># jumlah iterasi maksimum</span>
<span class="n">tolerance</span> <span class="o">=</span> <span class="mf">1e-5</span>  <span class="c1"># toleransi perubahan fungsi objektif</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>  <span class="c1"># agar hasil random konsisten</span>

<span class="c1"># Inisialisasi matriks derajat keanggotaan U secara acak</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">U</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">)</span>

<span class="c1"># Normalisasi U sehingga setiap baris menjumlahkan ke 1</span>
<span class="n">U</span> <span class="o">=</span> <span class="n">U</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Fungsi untuk menghitung pusat cluster berdasarkan U</span>
<span class="k">def</span><span class="w"> </span><span class="nf">compute_centroids</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">m</span><span class="p">):</span>
    <span class="n">um</span> <span class="o">=</span> <span class="n">U</span> <span class="o">**</span> <span class="n">m</span>  <span class="c1"># Derajat keanggotaan dipangkatkan m (fuzziness)</span>
    <span class="n">centroids</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">):</span>
        <span class="c1"># Perhitungan pembilang: jumlah (Œº_ij^m * x_i)</span>
        <span class="n">numerator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">um</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="n">data</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="c1"># Penyebut: jumlah (Œº_ij^m)</span>
        <span class="n">denominator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">um</span><span class="p">[:,</span> <span class="n">j</span><span class="p">])</span>
        <span class="c1"># Centroid j</span>
        <span class="n">centroids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">numerator</span> <span class="o">/</span> <span class="n">denominator</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">centroids</span><span class="p">)</span>

<span class="c1"># Fungsi untuk memperbarui derajat keanggotaan</span>
<span class="k">def</span><span class="w"> </span><span class="nf">update_membership</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">centroids</span><span class="p">,</span> <span class="n">m</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">U_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">))</span>  <span class="c1"># Matriks U baru</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">):</span>
            <span class="n">denom</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">):</span>
                <span class="c1"># Hitung jarak dari data ke pusat cluster j dan k</span>
                <span class="n">dist_j</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">centroids</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
                <span class="n">dist_k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">centroids</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
                <span class="c1"># Rasio jarak dipangkatkan (2 / (m - 1))</span>
                <span class="n">ratio</span> <span class="o">=</span> <span class="p">(</span><span class="n">dist_j</span> <span class="o">/</span> <span class="n">dist_k</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="n">m</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span> <span class="k">if</span> <span class="n">dist_k</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">1e-10</span>
                <span class="n">denom</span> <span class="o">+=</span> <span class="n">ratio</span>
            <span class="c1"># Nilai Œº_ij baru</span>
            <span class="n">U_new</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">denom</span>
    <span class="k">return</span> <span class="n">U_new</span>

<span class="c1"># Fungsi untuk menghitung nilai fungsi objektif (Jm)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">compute_objective</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">centroids</span><span class="p">,</span> <span class="n">m</span><span class="p">):</span>
    <span class="n">J</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">):</span>
            <span class="c1"># Hitung kuadrat jarak dari data ke pusat cluster j</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">centroids</span><span class="p">[</span><span class="n">j</span><span class="p">])</span> <span class="o">**</span> <span class="mi">2</span>
            <span class="c1"># Akumulasi fungsi objektif</span>
            <span class="n">J</span> <span class="o">+=</span> <span class="p">(</span><span class="n">U</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">**</span> <span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">dist</span>
    <span class="k">return</span> <span class="n">J</span>

<span class="n">prev_J</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Menyimpan nilai fungsi objektif sebelumnya</span>

<span class="c1"># Iterasi utama algoritma FCM</span>
<span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== Iterasi </span><span class="si">{</span><span class="n">iteration</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2"> ===&quot;</span><span class="p">)</span>

    <span class="c1"># Hitung pusat cluster berdasarkan U</span>
    <span class="n">centroids</span> <span class="o">=</span> <span class="n">compute_centroids</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>

    <span class="c1"># Tampilkan pusat cluster saat ini</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Pusat Cluster (Cj):&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">centroids</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;C</span><span class="si">{</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2"> = </span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Hitung fungsi objektif saat ini</span>
    <span class="n">J</span> <span class="o">=</span> <span class="n">compute_objective</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">centroids</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Fungsi Objektif (Jm) = </span><span class="si">{</span><span class="n">J</span><span class="si">:</span><span class="s2">.5f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Cek konvergensi: apakah perubahan J sangat kecil</span>
    <span class="k">if</span> <span class="n">prev_J</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">abs</span><span class="p">(</span><span class="n">J</span> <span class="o">-</span> <span class="n">prev_J</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">tolerance</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Konvergen: Fungsi objektif tidak berubah signifikan.&quot;</span><span class="p">)</span>
        <span class="k">break</span>  <span class="c1"># hentikan iterasi jika sudah konvergen</span>

    <span class="c1"># Simpan J untuk iterasi berikutnya</span>
    <span class="n">prev_J</span> <span class="o">=</span> <span class="n">J</span>

    <span class="c1"># Update derajat keanggotaan U</span>
    <span class="n">U</span> <span class="o">=</span> <span class="n">update_membership</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">centroids</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>

<span class="c1"># Menampilkan hasil akhir cluster setiap data</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== Hasil Akhir Cluster ===&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="c1"># Ambil cluster dengan keanggotaan terbesar</span>
    <span class="n">cluster</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">U</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Data </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2">): Cluster </span><span class="si">{</span><span class="n">cluster</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=== Iterasi 1 ===
Pusat Cluster (Cj):
C1 = [5.89403029 3.0294488 ]
C2 = [5.81210471 3.09925375]
Fungsi Objektif (Jm) = 81.83906

=== Iterasi 2 ===
Pusat Cluster (Cj):
C1 = [5.95250529 3.00484022]
C2 = [5.72143523 3.10783588]
Fungsi Objektif (Jm) = 64.35674

=== Iterasi 3 ===
Pusat Cluster (Cj):
C1 = [6.10591896 2.97915017]
C2 = [5.54056348 3.13819684]
Fungsi Objektif (Jm) = 60.91251

=== Iterasi 4 ===
Pusat Cluster (Cj):
C1 = [6.32038399 2.95634844]
C2 = [5.29544562 3.17681835]
Fungsi Objektif (Jm) = 51.60044

=== Iterasi 5 ===
Pusat Cluster (Cj):
C1 = [6.45249834 2.9555753 ]
C2 = [5.1568329  3.19832737]
Fungsi Objektif (Jm) = 45.37001

=== Iterasi 6 ===
Pusat Cluster (Cj):
C1 = [6.49469519 2.96106125]
C2 = [5.12202255 3.19931251]
Fungsi Objektif (Jm) = 44.51397

=== Iterasi 7 ===
Pusat Cluster (Cj):
C1 = [6.5073077  2.96435391]
C2 = [5.11760385 3.19599371]
Fungsi Objektif (Jm) = 44.45881

=== Iterasi 8 ===
Pusat Cluster (Cj):
C1 = [6.51225833 2.96603197]
C2 = [5.1185113  3.19336261]
Fungsi Objektif (Jm) = 44.45230

=== Iterasi 9 ===
Pusat Cluster (Cj):
C1 = [6.5147452  2.96693074]
C2 = [5.11976642 3.19172518]
Fungsi Objektif (Jm) = 44.45050

=== Iterasi 10 ===
Pusat Cluster (Cj):
C1 = [6.51614858 2.96743807]
C2 = [5.12066273 3.19075098]
Fungsi Objektif (Jm) = 44.44987

=== Iterasi 11 ===
Pusat Cluster (Cj):
C1 = [6.51697341 2.96773314]
C2 = [5.12123005 3.19017412]
Fungsi Objektif (Jm) = 44.44965

=== Iterasi 12 ===
Pusat Cluster (Cj):
C1 = [6.51746436 2.96790733]
C2 = [5.12157655 3.18983155]
Fungsi Objektif (Jm) = 44.44957

=== Iterasi 13 ===
Pusat Cluster (Cj):
C1 = [6.51775768 2.96801087]
C2 = [5.1217856 3.1896275]
Fungsi Objektif (Jm) = 44.44954

=== Iterasi 14 ===
Pusat Cluster (Cj):
C1 = [6.5179331  2.96807264]
C2 = [5.12191114 3.1895057 ]
Fungsi Objektif (Jm) = 44.44953

=== Iterasi 15 ===
Pusat Cluster (Cj):
C1 = [6.51803806 2.96810954]
C2 = [5.12198638 3.18943291]
Fungsi Objektif (Jm) = 44.44953

Konvergen: Fungsi objektif tidak berubah signifikan.

=== Hasil Akhir Cluster ===
Data 1 ([5.1 3.5]): Cluster 2
Data 2 ([4.9 3. ]): Cluster 2
Data 3 ([4.7 3.2]): Cluster 2
Data 4 ([4.6 3.1]): Cluster 2
Data 5 ([5.  3.6]): Cluster 2
Data 6 ([5.4 3.9]): Cluster 2
Data 7 ([4.6 3.4]): Cluster 2
Data 8 ([5.  3.4]): Cluster 2
Data 9 ([4.4 2.9]): Cluster 2
Data 10 ([4.9 3.1]): Cluster 2
Data 11 ([5.4 3.7]): Cluster 2
Data 12 ([4.8 3.4]): Cluster 2
Data 13 ([4.8 3. ]): Cluster 2
Data 14 ([4.3 3. ]): Cluster 2
Data 15 ([5.8 4. ]): Cluster 2
Data 16 ([5.7 4.4]): Cluster 2
Data 17 ([5.4 3.9]): Cluster 2
Data 18 ([5.1 3.5]): Cluster 2
Data 19 ([5.7 3.8]): Cluster 2
Data 20 ([5.1 3.8]): Cluster 2
Data 21 ([5.4 3.4]): Cluster 2
Data 22 ([5.1 3.7]): Cluster 2
Data 23 ([4.6 3.6]): Cluster 2
Data 24 ([5.1 3.3]): Cluster 2
Data 25 ([4.8 3.4]): Cluster 2
Data 26 ([5. 3.]): Cluster 2
Data 27 ([5.  3.4]): Cluster 2
Data 28 ([5.2 3.5]): Cluster 2
Data 29 ([5.2 3.4]): Cluster 2
Data 30 ([4.7 3.2]): Cluster 2
Data 31 ([4.8 3.1]): Cluster 2
Data 32 ([5.4 3.4]): Cluster 2
Data 33 ([5.2 4.1]): Cluster 2
Data 34 ([5.5 4.2]): Cluster 2
Data 35 ([4.9 3.1]): Cluster 2
Data 36 ([5.  3.2]): Cluster 2
Data 37 ([5.5 3.5]): Cluster 2
Data 38 ([4.9 3.1]): Cluster 2
Data 39 ([4.4 3. ]): Cluster 2
Data 40 ([5.1 3.4]): Cluster 2
Data 41 ([5.  3.5]): Cluster 2
Data 42 ([4.5 2.3]): Cluster 2
Data 43 ([4.4 3.2]): Cluster 2
Data 44 ([5.  3.5]): Cluster 2
Data 45 ([5.1 3.8]): Cluster 2
Data 46 ([4.8 3. ]): Cluster 2
Data 47 ([5.1 3.8]): Cluster 2
Data 48 ([4.6 3.2]): Cluster 2
Data 49 ([5.3 3.7]): Cluster 2
Data 50 ([5.  3.3]): Cluster 2
Data 51 ([7.  3.2]): Cluster 1
Data 52 ([6.4 3.2]): Cluster 1
Data 53 ([6.9 3.1]): Cluster 1
Data 54 ([5.5 2.3]): Cluster 2
Data 55 ([6.5 2.8]): Cluster 1
Data 56 ([5.7 2.8]): Cluster 2
Data 57 ([6.3 3.3]): Cluster 1
Data 58 ([4.9 2.4]): Cluster 2
Data 59 ([6.6 2.9]): Cluster 1
Data 60 ([5.2 2.7]): Cluster 2
Data 61 ([5. 2.]): Cluster 2
Data 62 ([5.9 3. ]): Cluster 1
Data 63 ([6.  2.2]): Cluster 1
Data 64 ([6.1 2.9]): Cluster 1
Data 65 ([5.6 2.9]): Cluster 2
Data 66 ([6.7 3.1]): Cluster 1
Data 67 ([5.6 3. ]): Cluster 2
Data 68 ([5.8 2.7]): Cluster 1
Data 69 ([6.2 2.2]): Cluster 1
Data 70 ([5.6 2.5]): Cluster 2
Data 71 ([5.9 3.2]): Cluster 1
Data 72 ([6.1 2.8]): Cluster 1
Data 73 ([6.3 2.5]): Cluster 1
Data 74 ([6.1 2.8]): Cluster 1
Data 75 ([6.4 2.9]): Cluster 1
Data 76 ([6.6 3. ]): Cluster 1
Data 77 ([6.8 2.8]): Cluster 1
Data 78 ([6.7 3. ]): Cluster 1
Data 79 ([6.  2.9]): Cluster 1
Data 80 ([5.7 2.6]): Cluster 2
Data 81 ([5.5 2.4]): Cluster 2
Data 82 ([5.5 2.4]): Cluster 2
Data 83 ([5.8 2.7]): Cluster 1
Data 84 ([6.  2.7]): Cluster 1
Data 85 ([5.4 3. ]): Cluster 2
Data 86 ([6.  3.4]): Cluster 1
Data 87 ([6.7 3.1]): Cluster 1
Data 88 ([6.3 2.3]): Cluster 1
Data 89 ([5.6 3. ]): Cluster 2
Data 90 ([5.5 2.5]): Cluster 2
Data 91 ([5.5 2.6]): Cluster 2
Data 92 ([6.1 3. ]): Cluster 1
Data 93 ([5.8 2.6]): Cluster 1
Data 94 ([5.  2.3]): Cluster 2
Data 95 ([5.6 2.7]): Cluster 2
Data 96 ([5.7 3. ]): Cluster 2
Data 97 ([5.7 2.9]): Cluster 2
Data 98 ([6.2 2.9]): Cluster 1
Data 99 ([5.1 2.5]): Cluster 2
Data 100 ([5.7 2.8]): Cluster 2
Data 101 ([6.3 3.3]): Cluster 1
Data 102 ([5.8 2.7]): Cluster 1
Data 103 ([7.1 3. ]): Cluster 1
Data 104 ([6.3 2.9]): Cluster 1
Data 105 ([6.5 3. ]): Cluster 1
Data 106 ([7.6 3. ]): Cluster 1
Data 107 ([4.9 2.5]): Cluster 2
Data 108 ([7.3 2.9]): Cluster 1
Data 109 ([6.7 2.5]): Cluster 1
Data 110 ([7.2 3.6]): Cluster 1
Data 111 ([6.5 3.2]): Cluster 1
Data 112 ([6.4 2.7]): Cluster 1
Data 113 ([6.8 3. ]): Cluster 1
Data 114 ([5.7 2.5]): Cluster 2
Data 115 ([5.8 2.8]): Cluster 1
Data 116 ([6.4 3.2]): Cluster 1
Data 117 ([6.5 3. ]): Cluster 1
Data 118 ([7.7 3.8]): Cluster 1
Data 119 ([7.7 2.6]): Cluster 1
Data 120 ([6.  2.2]): Cluster 1
Data 121 ([6.9 3.2]): Cluster 1
Data 122 ([5.6 2.8]): Cluster 2
Data 123 ([7.7 2.8]): Cluster 1
Data 124 ([6.3 2.7]): Cluster 1
Data 125 ([6.7 3.3]): Cluster 1
Data 126 ([7.2 3.2]): Cluster 1
Data 127 ([6.2 2.8]): Cluster 1
Data 128 ([6.1 3. ]): Cluster 1
Data 129 ([6.4 2.8]): Cluster 1
Data 130 ([7.2 3. ]): Cluster 1
Data 131 ([7.4 2.8]): Cluster 1
Data 132 ([7.9 3.8]): Cluster 1
Data 133 ([6.4 2.8]): Cluster 1
Data 134 ([6.3 2.8]): Cluster 1
Data 135 ([6.1 2.6]): Cluster 1
Data 136 ([7.7 3. ]): Cluster 1
Data 137 ([6.3 3.4]): Cluster 1
Data 138 ([6.4 3.1]): Cluster 1
Data 139 ([6. 3.]): Cluster 1
Data 140 ([6.9 3.1]): Cluster 1
Data 141 ([6.7 3.1]): Cluster 1
Data 142 ([6.9 3.1]): Cluster 1
Data 143 ([5.8 2.7]): Cluster 1
Data 144 ([6.8 3.2]): Cluster 1
Data 145 ([6.7 3.3]): Cluster 1
Data 146 ([6.7 3. ]): Cluster 1
Data 147 ([6.3 2.5]): Cluster 1
Data 148 ([6.5 3. ]): Cluster 1
Data 149 ([6.2 3.4]): Cluster 1
Data 150 ([5.9 3. ]): Cluster 1
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="proyek_ujiantengahsemester.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><strong>üìù UTS Penambangan Data - Klasifikasi Prediksi Survival Pasien Sirosis</strong></p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#"><strong>Pengenalan Clustering dan K-Means</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#apa-itu-clustering"><strong>Apa Itu Clustering‚Ä¶?</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#algoritma-k-means"><strong>Algoritma K-Means</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluasi-kualitas-clustering"><strong>Evaluasi Kualitas Clustering</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#implementasi-algoritma-k-means-menggunakan-python"><strong>Implementasi Algoritma K-Means Menggunakan Python</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#install-library-yang-dibutuhkan"><strong>1. Install Library yang dibutuhkan</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mengambil-database-dari-dbever"><strong>2. Mengambil Database dari DBever</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#menghilangkan-species-labelnya"><strong>3. Menghilangkan species / labelnya</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#clustering-pada-data-iris-menggunakan-k-means-dengan-jumlah-cluster-2"><strong>4. Clustering pada data Iris menggunakan K-Means dengan jumlah cluster 2</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#clustering-pada-data-iris-menggunakan-k-means-dengan-jumlah-cluster-3"><strong>5. Clustering pada data Iris menggunakan K-Means dengan jumlah cluster 3</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#clustering-pada-data-iris-menggunakan-k-means-dengan-jumlah-cluster-4"><strong>6. Clustering pada data Iris menggunakan K-Means dengan jumlah cluster 4</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kesimpulan"><strong>7. Kesimpulan</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metode-elbow"><strong>8. Metode Elbow</strong></a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#pengenalan-fuzzy-c-means"><strong>Pengenalan Fuzzy C-Means</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#konsep-fuzzy-c-means"><strong>Konsep Fuzzy C-Means</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-algoritma"><strong>Langkah Algoritma</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#contoh-penerapan-dalam-bentuk-code"><strong>Contoh penerapan dalam bentuk code</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementasi-kedalam-data-iris"><strong>Implementasi Kedalam Data Iris</strong></a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Muhammad Hanif
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      ¬© Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>