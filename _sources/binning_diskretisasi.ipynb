{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO/RjMsXjMuyuGbrAri7zxx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Binning (Diskritisasi menggunakan K-Means Clustering)**"],"metadata":{"id":"XNE4mPppAQ1_"}},{"cell_type":"markdown","source":["# **Penerapan K-Means dalam Pengelompokan Data Sepal Length**\n","\n","Algoritma K-Means Clustering merupakan salah satu metode unsupervised learning yang digunakan untuk mengelompokkan data berdasarkan kemiripan nilai fitur tertentu. Dalam kasus ini, fitur yang digunakan adalah panjang sepal (Sepal Length). Tujuan dari proses ini adalah untuk membagi data ke dalam lima kelompok (klaster) yang diberi label 0, 1, 2, 3, dan 4.\n","\n","Proses clusterisasi dilakukan dengan menghitung jarak antar nilai panjang sepal, lalu mengelompokkan data yang memiliki nilai-nilai yang berdekatan ke dalam klaster yang sama. Setiap klaster akan mencerminkan rentang nilai tertentu dari panjang sepal, sehingga data dalam satu klaster memiliki karakteristik yang mirip.\n","\n","Langkah-langkah umum dalam penerapan K-Means pada fitur Sepal Length meliputi:\n","\n","Menentukan jumlah klaster (dalam hal ini 5).\n","\n","Menginisialisasi centroid awal secara acak atau berdasarkan metode tertentu.\n","\n","Menghitung jarak antara setiap data dengan centroid, lalu mengelompokkannya ke klaster terdekat.\n","\n","Memperbarui posisi centroid berdasarkan rata-rata nilai dalam masing-masing klaster.\n","\n","Mengulangi proses hingga tidak terjadi perubahan signifikan dalam pembagian klaster.\n","\n","Dengan demikian, hasil akhir dari proses K-Means ini adalah lima kelompok data berdasarkan panjang sepal, yang masing-masing merepresentasikan satu interval nilai dan pola persebaran data yang lebih terstruktur."],"metadata":{"id":"cDGkYBHwBeu5"}},{"cell_type":"markdown","source":["## **Penjelasan Kode**\n","Kode di Bawah ini merupakan implementasi algoritma *K-Means clustering* untuk mengelompokkan data bunga Iris berdasarkan hanya satu fitur yaitu **`sepal length`**. Langkah pertama dalam kode ini adalah membaca dataset dari file Excel (`data_iris.xlsx`) yang berisi data fitur serta label kelas asli pada kolom `Class`. Kemudian, fitur `sepal length` dipilih sebagai satu-satunya input untuk proses clustering.\n","\n","Selanjutnya, fitur ini dinormalisasi menggunakan **MinMaxScaler** agar berada dalam rentang nilai 0 hingga 1, yang penting untuk memastikan bahwa perbedaan skala tidak memengaruhi hasil clustering. Setelah proses normalisasi, model **KMeans** dijalankan untuk membentuk **4 klaster**. Parameter seperti `n_init=10`, `max_iter=300`, dan `tol=1e-4` digunakan untuk memastikan hasil yang stabil dan optimal.\n","\n","Setelah model KMeans selesai dilatih, label klaster yang dihasilkan (`kmeans.labels_`) ditambahkan ke dalam dataframe sebagai kolom `cluster`. Kemudian dilakukan evaluasi terhadap kualitas cluster menggunakan dua metrik utama, yaitu **jumlah iterasi hingga konvergensi**, **inertia (SSE)** yang menunjukkan total jarak kuadrat dalam tiap klaster, dan **Silhouette Score**, yang mengukur seberapa baik data cocok dengan klaster masing-masing.\n","\n","Untuk mengetahui seberapa sesuai hasil clustering dengan label sebenarnya, dilakukan pemetaan setiap klaster ke **kelas mayoritas** berdasarkan kolom `Class`. Hasil prediksi ini disimpan dalam kolom `predicted_class`. Selanjutnya, dilakukan perhitungan **akurasi** dengan membandingkan `predicted_class` terhadap label asli `Class`, serta ditampilkan **tabel distribusi** untuk melihat sebaran kelas dalam tiap klaster.\n","\n","Akhirnya, seluruh hasil clustering dan prediksi disimpan ke file baru `clus_dis_sepal_length.xlsx`, dan isi kolom `Class`, `cluster`, dan `predicted_class` ditampilkan sebagai output. Kode ini menunjukkan bagaimana algoritma unsupervised seperti KMeans dapat dimanfaatkan untuk menemukan struktur atau pola dalam data, bahkan hanya dengan menggunakan satu fitur saja.\n"],"metadata":{"id":"QSTazF48FKUr"}},{"cell_type":"code","source":["from sklearn.cluster import KMeans\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import silhouette_score, accuracy_score\n","import pandas as pd\n","\n","# Membaca data dari file Excel\n","df = pd.read_excel(\"data_iris.xlsx\")  # File ini harus sudah memiliki kolom 'sepal length' dan 'Class'\n","\n","# Ambil hanya fitur sepal length\n","features = df[['sepal length']]\n","\n","# Normalisasi fitur\n","scaler = MinMaxScaler()\n","scaled_features = scaler.fit_transform(features)\n","\n","# Clustering KMeans dengan 4 klaster\n","kmeans = KMeans(n_clusters=4, random_state=42, n_init=10, max_iter=300, tol=1e-4)\n","kmeans.fit(scaled_features)\n","\n","# Simpan hasil cluster ke dataframe\n","df['cluster'] = kmeans.labels_\n","\n","# Evaluasi\n","print(f\"Jumlah iterasi sampai konvergen: {kmeans.n_iter_}\")\n","print(f\"Inertia (SSE): {kmeans.inertia_:.4f}\")\n","sil_score = silhouette_score(scaled_features, kmeans.labels_)\n","print(f\"Silhouette Score: {sil_score:.4f}\")\n","\n","# Pemetaan cluster ke class mayoritas\n","mapping = (\n","    df.groupby('cluster')['Class']\n","    .agg(lambda x: x.mode()[0])\n","    .to_dict()\n",")\n","df['predicted_class'] = df['cluster'].map(mapping)\n","\n","# Hitung akurasi prediksi clustering terhadap label asli\n","y_true = df['Class']\n","y_pred = df['predicted_class']\n","acc = accuracy_score(y_true, y_pred)\n","print(f\"\\nAkurasi keseluruhan clustering terhadap label asli: {acc:.4%}\")\n","\n","# Tampilkan distribusi cluster per kelas\n","dist = pd.crosstab(df['Class'], df['cluster'], rownames=['Class'], colnames=['Cluster'])\n","print(\"\\nDistribusi cluster per kelas:\")\n","print(dist)\n","\n","# Simpan hasil ke Excel\n","df.to_excel(\"clus_dis_sepal_length.xlsx\", index=False)\n","\n","# Tampilkan hasil akhir\n","pd.set_option('display.max_rows', None)\n","print(df[['Class', 'cluster', 'predicted_class']])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gamA2xNOBqSo","executionInfo":{"status":"ok","timestamp":1749780998926,"user_tz":-420,"elapsed":194,"user":{"displayName":"23-177 Muhammad Hanif","userId":"11387158830586806132"}},"outputId":"8ce11bb2-df35-47cb-9c5a-18840ded20cc"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Jumlah iterasi sampai konvergen: 2\n","Inertia (SSE): 0.6416\n","Silhouette Score: 0.5920\n","\n","Akurasi keseluruhan clustering terhadap label asli: 72.0000%\n","\n","Distribusi cluster per kelas:\n","Cluster           0   1   2   3\n","Class                          \n","Iris-setosa      10   0  40   0\n","Iris-versicolor  29   0   5  16\n","Iris-virginica   10  12   1  27\n","               Class  cluster  predicted_class\n","0        Iris-setosa        2      Iris-setosa\n","1        Iris-setosa        2      Iris-setosa\n","2        Iris-setosa        2      Iris-setosa\n","3        Iris-setosa        2      Iris-setosa\n","4        Iris-setosa        2      Iris-setosa\n","5        Iris-setosa        0  Iris-versicolor\n","6        Iris-setosa        2      Iris-setosa\n","7        Iris-setosa        2      Iris-setosa\n","8        Iris-setosa        2      Iris-setosa\n","9        Iris-setosa        2      Iris-setosa\n","10       Iris-setosa        0  Iris-versicolor\n","11       Iris-setosa        2      Iris-setosa\n","12       Iris-setosa        2      Iris-setosa\n","13       Iris-setosa        2      Iris-setosa\n","14       Iris-setosa        0  Iris-versicolor\n","15       Iris-setosa        0  Iris-versicolor\n","16       Iris-setosa        0  Iris-versicolor\n","17       Iris-setosa        2      Iris-setosa\n","18       Iris-setosa        0  Iris-versicolor\n","19       Iris-setosa        2      Iris-setosa\n","20       Iris-setosa        0  Iris-versicolor\n","21       Iris-setosa        2      Iris-setosa\n","22       Iris-setosa        2      Iris-setosa\n","23       Iris-setosa        2      Iris-setosa\n","24       Iris-setosa        2      Iris-setosa\n","25       Iris-setosa        2      Iris-setosa\n","26       Iris-setosa        2      Iris-setosa\n","27       Iris-setosa        2      Iris-setosa\n","28       Iris-setosa        2      Iris-setosa\n","29       Iris-setosa        2      Iris-setosa\n","30       Iris-setosa        2      Iris-setosa\n","31       Iris-setosa        0  Iris-versicolor\n","32       Iris-setosa        2      Iris-setosa\n","33       Iris-setosa        0  Iris-versicolor\n","34       Iris-setosa        2      Iris-setosa\n","35       Iris-setosa        2      Iris-setosa\n","36       Iris-setosa        0  Iris-versicolor\n","37       Iris-setosa        2      Iris-setosa\n","38       Iris-setosa        2      Iris-setosa\n","39       Iris-setosa        2      Iris-setosa\n","40       Iris-setosa        2      Iris-setosa\n","41       Iris-setosa        2      Iris-setosa\n","42       Iris-setosa        2      Iris-setosa\n","43       Iris-setosa        2      Iris-setosa\n","44       Iris-setosa        2      Iris-setosa\n","45       Iris-setosa        2      Iris-setosa\n","46       Iris-setosa        2      Iris-setosa\n","47       Iris-setosa        2      Iris-setosa\n","48       Iris-setosa        2      Iris-setosa\n","49       Iris-setosa        2      Iris-setosa\n","50   Iris-versicolor        3   Iris-virginica\n","51   Iris-versicolor        3   Iris-virginica\n","52   Iris-versicolor        3   Iris-virginica\n","53   Iris-versicolor        0  Iris-versicolor\n","54   Iris-versicolor        3   Iris-virginica\n","55   Iris-versicolor        0  Iris-versicolor\n","56   Iris-versicolor        3   Iris-virginica\n","57   Iris-versicolor        2      Iris-setosa\n","58   Iris-versicolor        3   Iris-virginica\n","59   Iris-versicolor        2      Iris-setosa\n","60   Iris-versicolor        2      Iris-setosa\n","61   Iris-versicolor        0  Iris-versicolor\n","62   Iris-versicolor        0  Iris-versicolor\n","63   Iris-versicolor        0  Iris-versicolor\n","64   Iris-versicolor        0  Iris-versicolor\n","65   Iris-versicolor        3   Iris-virginica\n","66   Iris-versicolor        0  Iris-versicolor\n","67   Iris-versicolor        0  Iris-versicolor\n","68   Iris-versicolor        3   Iris-virginica\n","69   Iris-versicolor        0  Iris-versicolor\n","70   Iris-versicolor        0  Iris-versicolor\n","71   Iris-versicolor        0  Iris-versicolor\n","72   Iris-versicolor        3   Iris-virginica\n","73   Iris-versicolor        0  Iris-versicolor\n","74   Iris-versicolor        3   Iris-virginica\n","75   Iris-versicolor        3   Iris-virginica\n","76   Iris-versicolor        3   Iris-virginica\n","77   Iris-versicolor        3   Iris-virginica\n","78   Iris-versicolor        0  Iris-versicolor\n","79   Iris-versicolor        0  Iris-versicolor\n","80   Iris-versicolor        0  Iris-versicolor\n","81   Iris-versicolor        0  Iris-versicolor\n","82   Iris-versicolor        0  Iris-versicolor\n","83   Iris-versicolor        0  Iris-versicolor\n","84   Iris-versicolor        0  Iris-versicolor\n","85   Iris-versicolor        0  Iris-versicolor\n","86   Iris-versicolor        3   Iris-virginica\n","87   Iris-versicolor        3   Iris-virginica\n","88   Iris-versicolor        0  Iris-versicolor\n","89   Iris-versicolor        0  Iris-versicolor\n","90   Iris-versicolor        0  Iris-versicolor\n","91   Iris-versicolor        0  Iris-versicolor\n","92   Iris-versicolor        0  Iris-versicolor\n","93   Iris-versicolor        2      Iris-setosa\n","94   Iris-versicolor        0  Iris-versicolor\n","95   Iris-versicolor        0  Iris-versicolor\n","96   Iris-versicolor        0  Iris-versicolor\n","97   Iris-versicolor        3   Iris-virginica\n","98   Iris-versicolor        2      Iris-setosa\n","99   Iris-versicolor        0  Iris-versicolor\n","100   Iris-virginica        3   Iris-virginica\n","101   Iris-virginica        0  Iris-versicolor\n","102   Iris-virginica        1   Iris-virginica\n","103   Iris-virginica        3   Iris-virginica\n","104   Iris-virginica        3   Iris-virginica\n","105   Iris-virginica        1   Iris-virginica\n","106   Iris-virginica        2      Iris-setosa\n","107   Iris-virginica        1   Iris-virginica\n","108   Iris-virginica        3   Iris-virginica\n","109   Iris-virginica        1   Iris-virginica\n","110   Iris-virginica        3   Iris-virginica\n","111   Iris-virginica        3   Iris-virginica\n","112   Iris-virginica        3   Iris-virginica\n","113   Iris-virginica        0  Iris-versicolor\n","114   Iris-virginica        0  Iris-versicolor\n","115   Iris-virginica        3   Iris-virginica\n","116   Iris-virginica        3   Iris-virginica\n","117   Iris-virginica        1   Iris-virginica\n","118   Iris-virginica        1   Iris-virginica\n","119   Iris-virginica        0  Iris-versicolor\n","120   Iris-virginica        3   Iris-virginica\n","121   Iris-virginica        0  Iris-versicolor\n","122   Iris-virginica        1   Iris-virginica\n","123   Iris-virginica        3   Iris-virginica\n","124   Iris-virginica        3   Iris-virginica\n","125   Iris-virginica        1   Iris-virginica\n","126   Iris-virginica        3   Iris-virginica\n","127   Iris-virginica        0  Iris-versicolor\n","128   Iris-virginica        3   Iris-virginica\n","129   Iris-virginica        1   Iris-virginica\n","130   Iris-virginica        1   Iris-virginica\n","131   Iris-virginica        1   Iris-virginica\n","132   Iris-virginica        3   Iris-virginica\n","133   Iris-virginica        3   Iris-virginica\n","134   Iris-virginica        0  Iris-versicolor\n","135   Iris-virginica        1   Iris-virginica\n","136   Iris-virginica        3   Iris-virginica\n","137   Iris-virginica        3   Iris-virginica\n","138   Iris-virginica        0  Iris-versicolor\n","139   Iris-virginica        3   Iris-virginica\n","140   Iris-virginica        3   Iris-virginica\n","141   Iris-virginica        3   Iris-virginica\n","142   Iris-virginica        0  Iris-versicolor\n","143   Iris-virginica        3   Iris-virginica\n","144   Iris-virginica        3   Iris-virginica\n","145   Iris-virginica        3   Iris-virginica\n","146   Iris-virginica        3   Iris-virginica\n","147   Iris-virginica        3   Iris-virginica\n","148   Iris-virginica        3   Iris-virginica\n","149   Iris-virginica        0  Iris-versicolor\n"]}]},{"cell_type":"markdown","source":["## **Analisis Statistik Cluster: Nilai Minimum, Maksimum, dan Centroid pada Fitur Sepal Length**\n","\n","Setelah data panjang sepal (Sepal Length) dikelompokkan menggunakan algoritma K-Means, langkah selanjutnya adalah melakukan analisis statistik terhadap hasil klasterisasi. Analisis ini mencakup pencarian nilai minimum (min), maksimum (max), dan centroid (nilai rata-rata) untuk masing-masing klaster yang terbentuk.\n","\n","Nilai minimum dan maksimum di setiap klaster digunakan untuk menentukan batas bawah dan batas atas dari rentang nilai di dalam klaster tersebut. Rentang ini menjadi dasar dalam proses diskretisasi data, yaitu mengubah nilai kontinu menjadi kategori berdasarkan interval.\n","\n","Centroid atau titik tengah dari tiap klaster dihitung sebagai rata-rata dari seluruh nilai Sepal Length yang termasuk dalam klaster tersebut. Nilai ini berfungsi sebagai representasi khas dari klaster tersebut dan dapat digunakan sebagai label numerik dalam proses transformasi data.\n","\n","Dengan pendekatan ini, fitur Sepal Length yang semula berupa nilai kontinu (angka desimal) dapat diubah menjadi bentuk kategori diskret, seperti:\n","\n","Klaster 0 → kategori A\n","\n","Klaster 1 → kategori B\n","\n","dst.\n","\n","Setiap data akan dikategorikan berdasarkan interval min–max dari klaster tempatnya berada. Hasilnya, data menjadi lebih mudah dianalisis dalam konteks klasifikasi atau pemodelan yang membutuhkan data dalam bentuk diskrit.\n"],"metadata":{"id":"l2EX7PfQFhVi"}},{"cell_type":"code","source":["from sklearn.cluster import KMeans\n","from sklearn.preprocessing import MinMaxScaler\n","import pandas as pd\n","\n","from google.colab import files\n","uploaded = files.upload()\n","\n","\n","# Contoh Data\n","df = pd.read_excel(\"clus_dis.xlsx\")\n","features = df[['sepal_length']]\n","\n","# Normalisasi\n","scaler = MinMaxScaler()\n","scaled_features = scaler.fit_transform(features)\n","\n","# KMeans Clustering\n","kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\n","kmeans.fit(scaled_features)\n","\n","# Tambahkan hasil cluster ke data\n","df['cluster'] = kmeans.labels_\n","\n","# Ambil centroid dari hasil clustering (dalam skala normalisasi)\n","centroids_scaled = kmeans.cluster_centers_\n","\n","# Konversi centroid ke skala asli\n","centroids_original = scaler.inverse_transform(centroids_scaled)\n","\n","# Hitung min, max, dan centroid per klaster\n","cluster_stats = df.groupby('cluster')['sepal_length'].agg(['min', 'max']).copy()\n","cluster_stats['centroid'] = centroids_original.flatten()\n","\n","# Tampilkan hasil\n","print(\"\\nStatistik Sepal Length per Cluster:\")\n","print(cluster_stats)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":212},"id":"J2QSe7j0EZRV","executionInfo":{"status":"ok","timestamp":1749782552120,"user_tz":-420,"elapsed":22235,"user":{"displayName":"23-177 Muhammad Hanif","userId":"11387158830586806132"}},"outputId":"cc1f0a7d-5479-4b53-e104-c78f839cb21b"},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-19eed944-8d24-485f-82c0-aaadf27d1c2b\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-19eed944-8d24-485f-82c0-aaadf27d1c2b\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving clus_dis.xlsx to clus_dis (1).xlsx\n","\n","Statistik Sepal Length per Cluster:\n","         min  max  centroid\n","cluster                    \n","0        4.3  5.4  4.933333\n","1        7.2  7.9  7.550000\n","2        5.6  6.3  5.985714\n","3        6.5  7.1  6.833333\n"]}]},{"cell_type":"markdown","source":["Interpretasi Output Statistik Klasterisasi Fitur Sepal Length\n","\n","Hasil yang ditampilkan merupakan ringkasan statistik dari fitur Sepal Length setelah dilakukan proses pengelompokan menggunakan metode K-Means Clustering menjadi empat klaster (label: 0, 1, 2, 3). Setiap klaster berisi sekumpulan data dengan nilai panjang sepal yang memiliki kemiripan dan berada dalam rentang tertentu.\n","\n","Untuk masing-masing klaster, ditampilkan tiga komponen statistik penting:\n","\n","Minimum (min): Merupakan nilai terendah dari Sepal Length di dalam suatu klaster. Nilai ini berfungsi sebagai batas bawah dari rentang nilai dalam klaster tersebut.\n","\n","Maksimum (max): Merupakan nilai tertinggi dari Sepal Length dalam klaster, dan digunakan sebagai batas atas interval nilai dalam klaster tersebut.\n","\n","Centroid: Nilai rata-rata dari semua Sepal Length dalam satu klaster. Ini menunjukkan pusat atau representasi dari klaster, yang juga dikenal sebagai titik tengah (hasil dari cluster_centers_ pada KMeans).\n","\n","Nilai min dan max dari setiap klaster dapat dimanfaatkan untuk membentuk interval diskrit, yaitu rentang-rentang nilai yang digunakan dalam proses diskretisasi fitur Sepal Length. Proses ini mengubah nilai kontinu menjadi bentuk kategori berdasarkan interval yang telah didefinisikan. Sementara itu, centroid bisa digunakan sebagai nilai representatif (label numerik) dari masing-masing kategori hasil diskretisasi.\n","\n","Dengan demikian, fitur Sepal Length yang sebelumnya berupa angka kontinu bisa dikonversi menjadi fitur kategori yang lebih sederhana dan terstruktur, siap digunakan untuk proses data mining atau klasifikasi selanjutnya.\n"],"metadata":{"id":"dceXHrHzHKKa"}},{"cell_type":"markdown","source":["# **Transformasi Sepal Length Menjadi Data Kategorikal Melalui Proses Diskretisasi**\n","\n","Tahapan ini merupakan lanjutan dari proses klasterisasi, yaitu melakukan diskretisasi terhadap fitur numerik Sepal Length berdasarkan hasil pengelompokan yang diperoleh dari algoritma K-Means. Tujuannya adalah mengubah fitur numerik menjadi bentuk kategori agar lebih sesuai untuk analisis tertentu, seperti klasifikasi atau pembuatan aturan dalam data mining.\n","\n","Setelah proses klasterisasi dilakukan, setiap nilai Sepal Length dari dataset telah terasosiasi dengan satu klaster (contoh: klaster 0, 1, 2, atau 3). Berdasarkan nilai minimum dan maksimum dari setiap klaster, ditentukan rentang yang merepresentasikan masing-masing kelompok data. Setiap nilai panjang sepal kemudian dicocokkan ke dalam rentang tersebut untuk menentukan label kategori diskrit.\n","\n","Sebagai contoh:\n","\n","Jika nilai Sepal Length pada baris pertama adalah 5.1, dan nilai tersebut berada dalam rentang klaster 2, maka data tersebut akan diberi label diskrit berupa ‘C’ (dengan asumsi label klaster ditransformasikan menjadi huruf A, B, C, D, dst. secara berurutan).\n","\n","Proses ini mengakibatkan fitur sepal_length yang awalnya merupakan data kontinu (angka desimal) diubah menjadi data kategorikal, yaitu label yang mewakili masing-masing klaster atau interval. Hal ini mempermudah pemrosesan lebih lanjut pada algoritma yang tidak mendukung data numerik kontinu, atau saat ingin menyederhanakan pemodelan dengan pendekatan berbasis kategori."],"metadata":{"id":"4TUtM89FHOfe"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.cluster import KMeans\n","\n","# Baca file\n","df = pd.read_excel(\"data_iris.xlsx\")\n","\n","# Klasterisasi dengan KMeans pada kolom sepal length\n","kmeans = KMeans(n_clusters=4, random_state=42)\n","df['cluster'] = kmeans.fit_predict(df[['sepal length']])\n","\n","# Pemetaan angka klaster ke huruf\n","cluster_to_label = {0: 'A', 1: 'B', 2: 'C', 3: 'D'}\n","df['sepal_length_original'] = df['sepal length']\n","df['sepal length'] = df['cluster'].map(cluster_to_label)\n","\n","# Simpan ke Excel\n","df.to_excel(\"data_iris_terklaster_huruf.xlsx\", index=False)"],"metadata":{"id":"0EWE5jwnLTnW","executionInfo":{"status":"ok","timestamp":1749782711993,"user_tz":-420,"elapsed":201,"user":{"displayName":"23-177 Muhammad Hanif","userId":"11387158830586806132"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Pemetaan cluster ke label huruf\n","cluster_to_label = {\n","    0: 'A',\n","    1: 'B',\n","    2: 'C',\n","    3: 'D'\n","}\n","\n","# Salin kolom sepal length asli ke kolom baru (SALIN DULU SEBELUM DIUBAH)\n","df['sepal_length_original'] = df['sepal length']\n","\n","# Gantikan nilai sepal length dengan huruf berdasarkan klaster\n","df['sepal length'] = df['cluster'].map(cluster_to_label)\n","\n","# Tampilkan hasil\n","print(df[['cluster', 'sepal length', 'sepal_length_original']])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-VISAK1aHm6-","executionInfo":{"status":"ok","timestamp":1749783033357,"user_tz":-420,"elapsed":360,"user":{"displayName":"23-177 Muhammad Hanif","userId":"11387158830586806132"}},"outputId":"3fd5979d-9bbf-45fc-bd31-545a07fee697"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["     cluster sepal length sepal_length_original\n","0          2            C                     C\n","1          2            C                     C\n","2          2            C                     C\n","3          2            C                     C\n","4          2            C                     C\n","5          1            B                     B\n","6          2            C                     C\n","7          2            C                     C\n","8          2            C                     C\n","9          2            C                     C\n","10         1            B                     B\n","11         2            C                     C\n","12         2            C                     C\n","13         2            C                     C\n","14         1            B                     B\n","15         1            B                     B\n","16         1            B                     B\n","17         2            C                     C\n","18         1            B                     B\n","19         2            C                     C\n","20         1            B                     B\n","21         2            C                     C\n","22         2            C                     C\n","23         2            C                     C\n","24         2            C                     C\n","25         2            C                     C\n","26         2            C                     C\n","27         2            C                     C\n","28         2            C                     C\n","29         2            C                     C\n","30         2            C                     C\n","31         1            B                     B\n","32         2            C                     C\n","33         1            B                     B\n","34         2            C                     C\n","35         2            C                     C\n","36         1            B                     B\n","37         2            C                     C\n","38         2            C                     C\n","39         2            C                     C\n","40         2            C                     C\n","41         2            C                     C\n","42         2            C                     C\n","43         2            C                     C\n","44         2            C                     C\n","45         2            C                     C\n","46         2            C                     C\n","47         2            C                     C\n","48         1            B                     B\n","49         2            C                     C\n","50         3            D                     D\n","51         0            A                     A\n","52         3            D                     D\n","53         1            B                     B\n","54         0            A                     A\n","55         1            B                     B\n","56         0            A                     A\n","57         2            C                     C\n","58         0            A                     A\n","59         2            C                     C\n","60         2            C                     C\n","61         1            B                     B\n","62         0            A                     A\n","63         0            A                     A\n","64         1            B                     B\n","65         0            A                     A\n","66         1            B                     B\n","67         1            B                     B\n","68         0            A                     A\n","69         1            B                     B\n","70         1            B                     B\n","71         0            A                     A\n","72         0            A                     A\n","73         0            A                     A\n","74         0            A                     A\n","75         0            A                     A\n","76         3            D                     D\n","77         0            A                     A\n","78         0            A                     A\n","79         1            B                     B\n","80         1            B                     B\n","81         1            B                     B\n","82         1            B                     B\n","83         0            A                     A\n","84         1            B                     B\n","85         0            A                     A\n","86         0            A                     A\n","87         0            A                     A\n","88         1            B                     B\n","89         1            B                     B\n","90         1            B                     B\n","91         0            A                     A\n","92         1            B                     B\n","93         2            C                     C\n","94         1            B                     B\n","95         1            B                     B\n","96         1            B                     B\n","97         0            A                     A\n","98         2            C                     C\n","99         1            B                     B\n","100        0            A                     A\n","101        1            B                     B\n","102        3            D                     D\n","103        0            A                     A\n","104        0            A                     A\n","105        3            D                     D\n","106        2            C                     C\n","107        3            D                     D\n","108        0            A                     A\n","109        3            D                     D\n","110        0            A                     A\n","111        0            A                     A\n","112        3            D                     D\n","113        1            B                     B\n","114        1            B                     B\n","115        0            A                     A\n","116        0            A                     A\n","117        3            D                     D\n","118        3            D                     D\n","119        0            A                     A\n","120        3            D                     D\n","121        1            B                     B\n","122        3            D                     D\n","123        0            A                     A\n","124        0            A                     A\n","125        3            D                     D\n","126        0            A                     A\n","127        0            A                     A\n","128        0            A                     A\n","129        3            D                     D\n","130        3            D                     D\n","131        3            D                     D\n","132        0            A                     A\n","133        0            A                     A\n","134        0            A                     A\n","135        3            D                     D\n","136        0            A                     A\n","137        0            A                     A\n","138        0            A                     A\n","139        3            D                     D\n","140        0            A                     A\n","141        3            D                     D\n","142        1            B                     B\n","143        3            D                     D\n","144        0            A                     A\n","145        0            A                     A\n","146        0            A                     A\n","147        0            A                     A\n","148        0            A                     A\n","149        1            B                     B\n"]}]},{"cell_type":"markdown","source":["# **Transformasi Fitur Sepal Length: Dari Nilai Numerik ke Bentuk Kategorikal**\n","\n","Pada tahapan ini, dilakukan proses konversi terhadap fitur Sepal Length yang semula berupa data numerik menjadi data kategorikal (diskrit). Tujuan dari proses ini adalah untuk menyederhanakan representasi data, sekaligus menyesuaikan format fitur dengan kebutuhan algoritma atau analisis tertentu yang lebih optimal dengan data bertipe kategori.\n","\n","Langkah-langkah yang dilakukan meliputi:\n","\n","Membaca Data Asli dan Label Kelas\n","Pertama-tama, data asli dari dataset Iris dan data kelas (label spesies) dibaca ulang. Kedua data ini kemudian digabungkan agar fitur Sepal Length dapat dianalisis secara bersamaan dengan label kelasnya.\n","\n","Normalisasi Fitur Sepal Length\n","Sebelum dilakukan klasterisasi, nilai Sepal Length dinormalisasi menggunakan metode Min-Max Scaling, yang mengubah seluruh nilai ke dalam rentang antara 0 hingga 1. Langkah ini sangat penting karena algoritma K-Means Clustering bersifat sensitif terhadap perbedaan skala pada fitur, sehingga normalisasi memastikan bahwa hasil klasterisasi tidak bias terhadap nilai-nilai besar.\n","\n","Klasterisasi Menggunakan K-Means\n","Dengan data yang telah dinormalisasi, algoritma K-Means dijalankan untuk membagi fitur Sepal Length ke dalam empat klaster berdasarkan pola kemiripan nilai. Setiap data kemudian diberi label klaster (misalnya 0, 1, 2, atau 3) yang disimpan dalam kolom baru bernama cluster.\n","\n","Pemetaan Klaster ke Label Kategorikal\n","Label numerik hasil klasterisasi (misal: 0–3) selanjutnya diubah menjadi bentuk label kategori yang lebih mudah dipahami, misalnya:\n","\n","Klaster 0 → 'A'\n","\n","Klaster 1 → 'B'\n","\n","Klaster 2 → 'C'\n","\n","Klaster 3 → 'D'\n","\n","Label tersebut menggantikan nilai asli pada fitur Sepal Length, sehingga fitur tersebut tidak lagi berisi angka desimal, melainkan simbol kategori yang mencerminkan interval nilai berdasarkan hasil klasterisasi.\n","\n","Dengan selesainya proses ini, fitur Sepal Length kini telah bertransformasi dari bentuk numerik kontinu menjadi kategori diskrit, yang dapat digunakan dalam berbagai model klasifikasi atau pemrosesan data berbasis simbol."],"metadata":{"id":"IlSsDfc8M7HS"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.cluster import KMeans\n","from sklearn.preprocessing import MinMaxScaler\n","\n","df_features = pd.read_excel(\"clus_dis.xlsx\")\n","df_class = pd.read_excel(\"class.xlsx\")\n","\n","# Gabungkan dengan class\n","df = df_features.copy()\n","df['class'] = df_class['class']\n","\n","# Clustering ulang fitur sepal_length\n","features = df[['sepal_length']]\n","scaler = MinMaxScaler()\n","scaled_features = scaler.fit_transform(features)\n","\n","kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\n","kmeans.fit(scaled_features)\n","df['cluster'] = kmeans.labels_\n","\n","# Map hasil cluster ke kategori\n","cluster_to_category = {\n","    0: 'A',\n","    2: 'B',\n","    3: 'C',\n","    1: 'D'\n","}\n","df['sepal_length'] = df['cluster'].map(cluster_to_category)\n","\n","# Hapus kolom yang tidak perlu\n","df_result = df.drop(columns=[col for col in ['cluster', 'class', 'predicted_class'] if col in df.columns])\n","\n","# Simpan\n","df_result.to_excel(\"data_iris_sepal_kategori.xlsx\", index=False)\n","\n","# Tampilkan sebagian hasil\n","pd.set_option('display.max_rows', None)\n","print(df_result)"],"metadata":{"id":"0y-I2eXCND_y","executionInfo":{"status":"ok","timestamp":1749783382187,"user_tz":-420,"elapsed":907,"user":{"displayName":"23-177 Muhammad Hanif","userId":"11387158830586806132"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["      id  petal_length  petal_width sepal_length  sepal_width\n","0      1           1.4          0.2            B          3.5\n","1      2           1.4          0.2            B          3.0\n","2      3           1.3          0.2            B          3.2\n","3      4           1.5          0.2            B          3.1\n","4      5           1.4          0.2            B          3.6\n","5      6           1.7          0.4            A          3.9\n","6      7           1.4          0.3            B          3.4\n","7      8           1.5          0.2            B          3.4\n","8      9           1.4          0.2            B          2.9\n","9     10           1.5          0.1            B          3.1\n","10    11           1.5          0.2            A          3.7\n","11    12           1.6          0.2            B          3.4\n","12    13           1.4          0.1            B          3.0\n","13    14           1.1          0.1            B          3.0\n","14    15           1.2          0.2            A          4.0\n","15    16           1.5          0.4            A          4.4\n","16    17           1.3          0.4            A          3.9\n","17    18           1.4          0.3            B          3.5\n","18    19           1.7          0.3            A          3.8\n","19    20           1.5          0.3            B          3.8\n","20    21           1.7          0.2            A          3.4\n","21    22           1.5          0.4            B          3.7\n","22    23           1.0          0.2            B          3.6\n","23    24           1.7          0.5            B          3.3\n","24    25           1.9          0.2            B          3.4\n","25    26           1.6          0.2            B          3.0\n","26    27           1.6          0.4            B          3.4\n","27    28           1.5          0.2            B          3.5\n","28    29           1.4          0.2            B          3.4\n","29    30           1.6          0.2            B          3.2\n","30    31           1.6          0.2            B          3.1\n","31    32           1.5          0.4            A          3.4\n","32    33           1.5          0.1            B          4.1\n","33    34           1.4          0.2            A          4.2\n","34    35           1.5          0.1            B          3.1\n","35    36           1.2          0.2            B          3.2\n","36    37           1.3          0.2            A          3.5\n","37    38           1.5          0.1            B          3.1\n","38    39           1.3          0.2            B          3.0\n","39    40           1.5          0.2            B          3.4\n","40    41           1.3          0.3            B          3.5\n","41    42           1.3          0.3            B          2.3\n","42    43           1.3          0.2            B          3.2\n","43    44           1.6          0.6            B          3.5\n","44    45           1.9          0.4            B          3.8\n","45    46           1.4          0.3            B          3.0\n","46    47           1.6          0.2            B          3.8\n","47    48           1.4          0.2            B          3.2\n","48    49           1.5          0.2            B          3.7\n","49    50           1.4          0.2            B          3.3\n","50    51           4.7          1.4            C          3.2\n","51    52           4.5          1.5            C          3.2\n","52    53           4.9          1.5            C          3.1\n","53    54           4.0          1.3            A          2.3\n","54    55           4.6          1.5            C          2.8\n","55    56           4.5          1.3            A          2.8\n","56    57           4.7          1.6            C          3.3\n","57    58           3.3          1.0            B          2.4\n","58    59           4.6          1.3            C          2.9\n","59    60           3.9          1.4            B          2.7\n","60    61           3.5          1.0            B          2.0\n","61    62           4.2          1.5            A          3.0\n","62    63           4.0          1.0            A          2.2\n","63    64           4.7          1.4            A          2.9\n","64    65           3.6          1.3            A          2.9\n","65    66           4.4          1.4            C          3.1\n","66    67           4.5          1.5            A          3.0\n","67    68           4.1          1.0            A          2.7\n","68    69           4.5          1.5            C          2.2\n","69    70           3.9          1.1            A          2.5\n","70    71           4.8          1.8            A          3.2\n","71    72           4.0          1.3            A          2.8\n","72    73           4.9          1.5            C          2.5\n","73    74           4.7          1.2            A          2.8\n","74    75           4.3          1.3            C          2.9\n","75    76           4.4          1.4            C          3.0\n","76    77           4.8          1.4            C          2.8\n","77    78           5.0          1.7            C          3.0\n","78    79           4.5          1.5            A          2.9\n","79    80           3.5          1.0            A          2.6\n","80    81           3.8          1.1            A          2.4\n","81    82           3.7          1.0            A          2.4\n","82    83           3.9          1.2            A          2.7\n","83    84           5.1          1.6            A          2.7\n","84    85           4.5          1.5            A          3.0\n","85    86           4.5          1.6            A          3.4\n","86    87           4.7          1.5            C          3.1\n","87    88           4.4          1.3            C          2.3\n","88    89           4.1          1.3            A          3.0\n","89    90           4.0          1.3            A          2.5\n","90    91           4.4          1.2            A          2.6\n","91    92           4.6          1.4            A          3.0\n","92    93           4.0          1.2            A          2.6\n","93    94           3.3          1.0            B          2.3\n","94    95           4.2          1.3            A          2.7\n","95    96           4.2          1.2            A          3.0\n","96    97           4.2          1.3            A          2.9\n","97    98           4.3          1.3            C          2.9\n","98    99           3.0          1.1            B          2.5\n","99   100           4.1          1.3            A          2.8\n","100  101           6.0          2.5            C          3.3\n","101  102           5.1          1.9            A          2.7\n","102  103           5.9          2.1            D          3.0\n","103  104           5.6          1.8            C          2.9\n","104  105           5.8          2.2            C          3.0\n","105  106           6.6          2.1            D          3.0\n","106  107           4.5          1.7            B          2.5\n","107  108           6.3          1.8            D          2.9\n","108  109           5.8          1.8            C          2.5\n","109  110           6.1          2.5            D          3.6\n","110  111           5.1          2.0            C          3.2\n","111  112           5.3          1.9            C          2.7\n","112  113           5.5          2.1            C          3.0\n","113  114           5.0          2.0            A          2.5\n","114  115           5.1          2.4            A          2.8\n","115  116           5.3          2.3            C          3.2\n","116  117           5.5          1.8            C          3.0\n","117  118           6.7          2.2            D          3.8\n","118  119           6.9          2.3            D          2.6\n","119  120           5.0          1.5            A          2.2\n","120  121           5.7          2.3            C          3.2\n","121  122           4.9          2.0            A          2.8\n","122  123           6.7          2.0            D          2.8\n","123  124           4.9          1.8            C          2.7\n","124  125           5.7          2.1            C          3.3\n","125  126           6.0          1.8            D          3.2\n","126  127           4.8          1.8            C          2.8\n","127  128           4.9          1.8            A          3.0\n","128  129           5.6          2.1            C          2.8\n","129  130           5.8          1.6            D          3.0\n","130  131           6.1          1.9            D          2.8\n","131  132           6.4          2.0            D          3.8\n","132  133           5.6          2.2            C          2.8\n","133  134           5.1          1.5            C          2.8\n","134  135           5.6          1.4            A          2.6\n","135  136           6.1          2.3            D          3.0\n","136  137           5.6          2.4            C          3.4\n","137  138           5.5          1.8            C          3.1\n","138  139           4.8          1.8            A          3.0\n","139  140           5.4          2.1            C          3.1\n","140  141           5.6          2.4            C          3.1\n","141  142           5.1          2.3            C          3.1\n","142  143           5.1          1.9            A          2.7\n","143  144           5.9          2.3            C          3.2\n","144  145           5.7          2.5            C          3.3\n","145  146           5.2          2.3            C          3.0\n","146  147           5.0          1.9            C          2.5\n","147  148           5.2          2.0            C          3.0\n","148  149           5.4          2.3            C          3.4\n","149  150           5.1          1.8            A          3.0"],"metadata":{"id":"T86YRS5mN6S7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Diskretisasi Fitur Sepal Width, Petal Length, dan Petal Width Menggunakan K-Means Clustering**\n","\n","Setelah berhasil mengonversi fitur Sepal Length ke bentuk kategorikal melalui proses klasterisasi, tahapan selanjutnya adalah menerapkan pendekatan serupa pada fitur numerik lainnya, yaitu:\n","\n","Sepal Width,\n","\n","Petal Length, dan\n","\n","Petal Width.\n","\n","Masing-masing fitur akan diproses secara terpisah menggunakan metode K-Means Clustering, dengan tujuan yang sama: mengubah data numerik kontinu menjadi kategori diskrit berdasarkan pola distribusi nilainya.\n","\n","Langkah-Langkah Proses:\n","Pembacaan Data\n","Data yang digunakan dalam proses ini adalah:\n","\n","Dataset Iris asli yang berisi fitur numerik lengkap.\n","\n","Versi data sebelumnya yang telah memuat kolom sepal_length dalam bentuk kategorikal.\n","\n","Kedua sumber ini digabungkan agar proses lanjutan tetap mempertahankan struktur dan label yang sudah dihasilkan sebelumnya.\n","\n","Pembuatan Fungsi cluster_kategori_stat()\n","Untuk menghindari duplikasi proses, dibuat sebuah fungsi bantu bernama cluster_kategori_stat(). Fungsi ini memiliki peran sebagai berikut:\n","\n","Melakukan normalisasi data menggunakan Min-Max Scaler, agar seluruh nilai berada dalam rentang 0 hingga 1.\n","\n","Menjalankan proses K-Means Clustering sesuai jumlah klaster yang ditentukan untuk fitur tertentu.\n","\n","Memberikan label kategori berbentuk huruf (seperti 'A', 'B', dst.) berdasarkan label klaster hasil clustering.\n","\n","Menghasilkan statistik min, max, dan centroid dari setiap klaster yang terbentuk.\n","\n","Penerapan Diskretisasi\n","Dengan fungsi tersebut, dilakukan diskretisasi pada masing-masing fitur berikut:\n","\n","Sepal Width\n","Dikelompokkan menjadi 3 klaster, yang dikonversi ke dalam label kategori: 'A', 'B', dan 'C'.\n","\n","Petal Length\n","Dibagi ke dalam 4 klaster, dan diberi label kategori: 'A', 'B', 'C', dan 'D'.\n","\n","Petal Width\n","Dikelompokkan ke dalam 3 klaster, dengan label: 'A', 'B', dan 'C'.\n","\n","Hasil Akhir\n","Dengan pendekatan ini, seluruh fitur numerik dalam dataset Iris telah berhasil didiskretisasi ke dalam bentuk kategori. Setiap nilai asli kini direpresentasikan oleh label huruf yang menunjukkan interval nilai berdasarkan hasil klasterisasi. Transformasi ini tidak hanya menyederhanakan data, tetapi juga memungkinkan penggunaan algoritma klasifikasi atau data mining lain yang bekerja lebih baik dengan data kategorikal."],"metadata":{"id":"E-JW_Yu6OFCR"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.preprocessing import KBinsDiscretizer\n","import numpy as np # Untuk np.nan jika perlu\n","\n","# --- 1. Baca data awal ---\n","# Menggunakan nama file yang telah Anda sediakan\n","try:\n","    df_numerik = pd.read_excel(\"data_iris_sepal_kategori.xlsx\")\n","    # Untuk df_kategori, kita akan memulainya dari df_numerik dan menambahkan kolom kategori.\n","    # Asumsi: sepal_length sudah ada di df_numerik.\n","    df_kategori = df_numerik[['id', 'sepal_length']].copy()\n","except FileNotFoundError as e:\n","    print(f\"Error loading file: {e}. Pastikan file berada di direktori yang sama.\")\n","    exit()\n","\n","# --- 2. Fungsi bantu diskritisasi + mapping + statistik ---\n","def discretize_kbins_stat(data_col, n_bins, label_map, strategy='kmeans'):\n","    \"\"\"\n","    Melakukan diskritisasi menggunakan KBinsDiscretizer dan menghitung statistik.\n","\n","    Args:\n","        data_col (pd.Series): Kolom data numerik yang akan didiskritisasi.\n","        n_bins (int): Jumlah bin/kategori yang diinginkan.\n","        label_map (dict): Kamus untuk memetakan label numerik (0, 1, ...) ke label kategori (A, B, ...).\n","        strategy (str): Strategi diskritisasi ('uniform', 'quantile', 'kmeans'). Default 'kmeans'.\n","\n","    Returns:\n","        tuple: (pd.Series kategori, pd.DataFrame statistik)\n","    \"\"\"\n","    # Inisialisasi KBinsDiscretizer\n","    # encode='ordinal' berarti outputnya adalah integer (0, 1, ...)\n","    # strategy='kmeans' akan mencoba membuat bin berdasarkan klaster KMeans\n","    discretizer = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy=strategy)\n","\n","    # Melakukan fitting dan transformasi\n","    # Reshape data_col agar sesuai dengan input yang diharapkan oleh scikit-learn (2D array)\n","    labels_numeric = discretizer.fit_transform(data_col.values.reshape(-1, 1)).flatten().astype(int)\n","\n","    # Membuat seri kategori huruf\n","    kategori_series = pd.Series(labels_numeric).map(label_map)\n","\n","    # Menghitung statistik min, max, centroid per cluster/bin\n","    df_temp = pd.DataFrame({\n","        'nilai_asli': data_col,\n","        'cluster_id': labels_numeric # Menggunakan ID cluster/bin numerik\n","    })\n","\n","    # Hitung statistik\n","    stat = df_temp.groupby('cluster_id')['nilai_asli'].agg(['min', 'max', 'mean'])\n","    stat = stat.rename(columns={'mean': 'centroid'}) # Mengganti nama 'mean' menjadi 'centroid'\n","\n","    # Tambahkan kolom kategori ke statistik\n","    stat['kategori'] = stat.index.map(label_map)\n","    stat = stat.set_index('kategori')\n","\n","    return kategori_series, stat\n","\n","# --- 3. Sepal Width (3 kategori) ---\n","map_sepal_width = {0: 'A', 1: 'B', 2: 'C'}\n","# Menggunakan 'kmeans' strategy untuk mendekati perilaku asli\n","df_kategori['sepal width'], stat_sepal_width = discretize_kbins_stat(\n","    df_numerik['sepal width'], 3, map_sepal_width, strategy='kmeans'\n",")\n","\n","# --- 4. Petal Length (4 kategori) ---\n","map_petal_length = {0: 'A', 1: 'B', 2: 'C', 3: 'D'}\n","df_kategori['petal_length'], stat_petal_length = discretize_kbins_stat(\n","    df_numerik['petal_length'], 4, map_petal_length, strategy='kmeans'\n",")\n","\n","# --- 5. Petal Width (3 kategori) ---\n","map_petal_width = {0: 'A', 1: 'B', 2: 'C'}\n","df_kategori['petal_width'], stat_petal_width = discretize_kbins_stat(\n","    df_numerik['petal_width'], 3, map_petal_width, strategy='kmeans'\n",")\n","\n","df_kategori.to_excel(\"data_iris_kategori_lengkap.xlsx\", index=False)\n","print(\"Hasil kategori disimpan ke 'data_iris_kategori_lengkap.xlsx'\")\n","\n","\n","# --- 7. Gabungkan semua statistik dan tampilkan ---\n","print(\"\\n=== Statistik Sepal Width (3 kategori) ===\")\n","print(stat_sepal_width[['min', 'max', 'centroid']])\n","\n","print(\"\\n=== Statistik Petal Length (4 kategori) ===\")\n","print(stat_petal_length[['min', 'max', 'centroid']])\n","\n","print(\"\\n=== Statistik Petal Width (3 kategori) ===\")\n","print(stat_petal_width[['min', 'max', 'centroid']])"],"metadata":{"id":"Iq1fgDwbOa83","executionInfo":{"status":"ok","timestamp":1749783616066,"user_tz":-420,"elapsed":83,"user":{"displayName":"23-177 Muhammad Hanif","userId":"11387158830586806132"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Hasil kategori disimpan ke 'data_iris_kategori_lengkap.xlsx'\n","\n","=== Statistik Sepal Width (3 kategori) ===\n","          min  max  centroid\n","kategori\n","A         2.0  2.8  2.585106\n","B         2.9  3.4  3.118987\n","C         3.5  4.4  3.758333\n","\n","=== Statistik Petal Length (4 kategori) ==="],"metadata":{"id":"8CRd4Z-ROzjS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["          min  max  centroid\n","kategori\n","A         1.0  1.9  1.464000\n","B         3.0  4.3  3.884000\n","C         4.4  5.3  4.808889\n","D         5.4  6.9  5.903333\n","\n","=== Statistik Petal Width (3 kategori) ===\n","          min  max  centroid\n","kategori\n","A         0.1  0.6  0.244000\n","B         1.0  1.7  1.337037\n","C         1.8  2.5  2.073913"],"metadata":{"id":"YD9_fyHVO5NF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Menampilkan semua data hasil diskritisasi setiap fitur import pandas as pd**"],"metadata":{"id":"WLY-wYYTO9KV"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# Baca file Excel yang sudah berisi kategori\n","df_kategori = pd.read_excel(\"data_iris_kategori_lengkap.xlsx\")\n","\n","# Tampilkan semua baris\n","pd.set_option('display.max_rows', None)\n","print(df_kategori)"],"metadata":{"id":"5_HFaj28PE19","executionInfo":{"status":"ok","timestamp":1749783712394,"user_tz":-420,"elapsed":262,"user":{"displayName":"23-177 Muhammad Hanif","userId":"11387158830586806132"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["      id sepal_length sepal_width petal_length petal_width\n","0      1            B           C            A           A\n","1      2            B           B            A           A\n","2      3            B           B            A           A\n","3      4            B           B            A           A\n","4      5            B           C            A           A\n","5      6            A           C            A           A\n","6      7            B           B            A           A\n","7      8            B           B            A           A\n","8      9            B           B            A           A\n","9     10            B           B            A           A\n","10    11            A           C            A           A\n","11    12            B           B            A           A\n","12    13            B           B            A           A\n","13    14            B           B            A           A\n","14    15            A           C            A           A\n","15    16            A           C            A           A\n","16    17            A           C            A           A\n","17    18            B           C            A           A\n","18    19            A           C            A           A\n","19    20            B           C            A           A\n","20    21            A           B            A           A\n","21    22            B           C            A           A\n","22    23            B           C            A           A\n","23    24            B           B            A           A\n","24    25            B           B            A           A\n","25    26            B           B            A           A\n","26    27            B           B            A           A\n","27    28            B           C            A           A\n","28    29            B           B            A           A\n","29    30            B           B            A           A\n","30    31            B           B            A           A\n","31    32            A           B            A           A\n","32    33            B           C            A           A\n","33    34            A           C            A           A\n","34    35            B           B            A           A\n","35    36            B           B            A           A\n","36    37            A           C            A           A\n","37    38            B           B            A           A\n","38    39            B           B            A           A\n","39    40            B           B            A           A\n","40    41            B           C            A           A\n","41    42            B           A            A           A\n","42    43            B           B            A           A\n","43    44            B           C            A           A\n","44    45            B           C            A           A\n","45    46            B           B            A           A\n","46    47            B           C            A           A\n","47    48            B           B            A           A\n","48    49            B           C            A           A\n","49    50            B           B            A           A\n","50    51            C           B            C           B\n","51    52            C           B            C           B\n","52    53            C           B            C           B\n","53    54            A           A            B           B\n","54    55            C           A            C           B\n","55    56            A           A            C           B\n","56    57            C           B            C           B\n","57    58            B           A            B           B\n","58    59            C           B            C           B\n","59    60            B           A            B           B\n","60    61            B           A            B           B\n","61    62            A           B            B           B\n","62    63            A           A            B           B\n","63    64            A           B            C           B\n","64    65            A           B            B           B\n","65    66            C           B            C           B\n","66    67            A           B            C           B\n","67    68            A           A            B           B\n","68    69            C           A            C           B\n","69    70            A           A            B           B\n","70    71            A           B            C           C\n","71    72            A           A            B           B\n","72    73            C           A            C           B\n","73    74            A           A            C           B\n","74    75            C           B            B           B\n","75    76            C           B            C           B\n","76    77            C           A            C           B\n","77    78            C           B            C           B\n","78    79            A           B            C           B\n","79    80            A           A            B           B\n","80    81            A           A            B           B\n","81    82            A           A            B           B\n","82    83            A           A            B           B\n","83    84            A           A            C           B\n","84    85            A           B            C           B\n","85    86            A           B            C           B\n","86    87            C           B            C           B\n","87    88            C           A            C           B\n","88    89            A           B            B           B\n","89    90            A           A            B           B\n","90    91            A           A            C           B\n","91    92            A           B            C           B\n","92    93            A           A            B           B\n","93    94            B           A            B           B\n","94    95            A           A            B           B\n","95    96            A           B            B           B\n","96    97            A           B            B           B\n","97    98            C           B            B           B\n","98    99            B           A            B           B\n","99   100            A           A            B           B\n","100  101            C           B            D           C\n","101  102            A           A            C           C\n","102  103            D           B            D           C\n","103  104            C           B            D           C\n","104  105            C           B            D           C\n","105  106            D           B            D           C\n","106  107            B           A            C           B\n","107  108            D           B            D           C\n","108  109            C           A            D           C\n","109  110            D           C            D           C\n","110  111            C           B            C           C\n","111  112            C           A            C           C\n","112  113            C           B            D           C\n","113  114            A           A            C           C\n","114  115            A           A            C           C\n","115  116            C           B            C           C\n","116  117            C           B            D           C\n","117  118            D           C            D           C\n","118  119            D           A            D           C\n","119  120            A           A            C           B\n","120  121            C           B            D           C\n","121  122            A           A            C           C\n","122  123            D           A            D           C\n","123  124            C           A            C           C\n","124  125            C           B            D           C\n","125  126            D           B            D           C\n","126  127            C           A            C           C\n","127  128            A           B            C           C\n","128  129            C           A            D           C\n","129  130            D           B            D           B\n","130  131            D           A            D           C\n","131  132            D           C            D           C\n","132  133            C           A            D           C\n","133  134            C           A            C           B\n","134  135            A           A            D           B\n","135  136            D           B            D           C\n","136  137            C           B            D           C\n","137  138            C           B            D           C\n","138  139            A           B            C           C\n","139  140            C           B            D           C\n","140  141            C           B            D           C\n","141  142            C           B            C           C\n","142  143            A           A            C           C\n","143  144            C           B            D           C\n","144  145            C           B            D           C\n","145  146            C           B            C           C\n","146  147            C           A            C           C\n","147  148            C           B            C           C\n","148  149            C           B            D           C\n","149  150            A           B            C           C"],"metadata":{"id":"h-dtXNIcPKyA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Klasifikasi Naive Bayes Data Diskrit**\n","\n","Kode ini merupakan implementasi algoritma **Naive Bayes (CategoricalNB)** untuk melakukan klasifikasi pada data **Iris yang telah didiskritisasi** (berupa kategori seperti A, B, C, dst.). Dataset yang digunakan terdiri dari dua file: `data_iris_kategori_lengkap.xlsx` yang berisi fitur-fitur dalam bentuk kategori, dan `class.xlsx` yang berisi label kelas asli untuk setiap baris data berdasarkan kolom `id`.\n","\n","Langkah pertama adalah **menggabungkan** kedua dataset tersebut berdasarkan kolom `id` agar fitur dan label berada dalam satu DataFrame. Setelah itu, setiap fitur kategorikal seperti `petal_length`, `petal_width`, `sepal_length`, dan `sepal_width` diubah menjadi representasi numerik menggunakan `LabelEncoder`, karena model CategoricalNB hanya dapat bekerja dengan data numerik yang merepresentasikan kategori.\n","\n","Selanjutnya, label kelas (`class`) juga di-encode ke dalam bentuk numerik agar dapat digunakan sebagai target (y) dalam pelatihan model. Model **CategoricalNB** kemudian dilatih menggunakan data yang telah di-encode dan digunakan untuk memprediksi kelas dari data tersebut.\n","\n","Setelah proses prediksi selesai, hasilnya dikembalikan lagi ke bentuk label asli (dengan `inverse_transform`) dan disimpan ke file Excel `naive_bayes.xlsx`, yang berisi kolom `id`, `kelas_asli`, dan `kelas_prediksi`. Evaluasi model dilakukan dengan menghitung **akurasi** dan menampilkan **laporan klasifikasi** (precision, recall, dan f1-score untuk setiap kelas), sehingga pengguna bisa menilai seberapa baik model mengenali pola dari data diskritisasi tersebut.\n","\n","Secara keseluruhan, kode ini menunjukkan penerapan Naive Bayes pada data kategorikal, di mana transformasi label sangat penting agar data siap digunakan oleh model klasifikasi.\n"],"metadata":{"id":"TIW7EZyGPQIL"}},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n","from sklearn.naive_bayes import CategoricalNB\n","from sklearn.metrics import classification_report, accuracy_score\n","import pandas as pd\n","\n","# Load both files\n","data_iris = pd.read_excel(\"data_iris_kategori_lengkap.xlsx\")\n","class_asli = pd.read_excel(\"class.xlsx\")\n","\n","# Gabungkan data kategorikal dengan kelas asli berdasarkan 'id'\n","data_gabungan = pd.merge(data_iris, class_asli[['id', 'class']], on='id')\n","\n","# Encode fitur kategorikal (A, B, dst.) ke numerik\n","fitur_kategori = ['petal_length', 'petal_width', 'sepal_length', 'sepal_width']\n","for kolom in fitur_kategori:\n","    encoder = LabelEncoder()\n","    data_gabungan[kolom] = encoder.fit_transform(data_gabungan[kolom])\n","\n","# Encode label kelas\n","label_encoder = LabelEncoder()\n","y = label_encoder.fit_transform(data_gabungan['class'])\n","X = data_gabungan[fitur_kategori]\n","\n","# Model Naive Bayes\n","model = CategoricalNB()\n","model.fit(X, y)\n","y_pred = model.predict(X)\n","\n","# Buat DataFrame hasil prediksi vs kelas asli\n","hasil_prediksi = data_gabungan[['id']].copy()\n","hasil_prediksi['kelas_asli'] = label_encoder.inverse_transform(y)\n","hasil_prediksi['kelas_prediksi'] = label_encoder.inverse_transform(y_pred)\n","\n","# Simpan ke Excel\n","output_path = \"naive_bayes.xlsx\"\n","hasil_prediksi.to_excel(output_path, index=False)\n","\n","# Evaluasi hasil prediksi\n","akurasi = accuracy_score(y, y_pred)\n","laporan_klasifikasi = classification_report(y, y_pred, target_names=label_encoder.classes_)\n","\n","# Tampilkan hasil\n","print(\"\\n=== Hasil Prediksi Kelas ===\")\n","print(hasil_prediksi)\n","\n","print(\"\\n=== Akurasi ===\")\n","print(f\"Akurasi: {akurasi:.2f}\")\n","\n","print(\"\\n=== Laporan Klasifikasi ===\")\n","print(laporan_klasifikasi)"],"metadata":{"id":"NNN2ECwlPXq2","executionInfo":{"status":"ok","timestamp":1749783792594,"user_tz":-420,"elapsed":293,"user":{"displayName":"23-177 Muhammad Hanif","userId":"11387158830586806132"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["=== Hasil Prediksi Kelas ===\n","      id       kelas_asli   kelas_prediksi\n","0      1      Iris-setosa      Iris-setosa\n","1      2      Iris-setosa      Iris-setosa\n","2      3      Iris-setosa      Iris-setosa\n","3      4      Iris-setosa      Iris-setosa\n","4      5      Iris-setosa      Iris-setosa\n","5      6      Iris-setosa      Iris-setosa\n","6      7      Iris-setosa      Iris-setosa\n","7      8      Iris-setosa      Iris-setosa\n","8      9      Iris-setosa      Iris-setosa\n","9     10      Iris-setosa      Iris-setosa\n","10    11      Iris-setosa      Iris-setosa\n","11    12      Iris-setosa      Iris-setosa\n","12    13      Iris-setosa      Iris-setosa\n","13    14      Iris-setosa      Iris-setosa\n","14    15      Iris-setosa      Iris-setosa\n","15    16      Iris-setosa      Iris-setosa\n","16    17      Iris-setosa      Iris-setosa\n","17    18      Iris-setosa      Iris-setosa\n","18    19      Iris-setosa      Iris-setosa\n","19    20      Iris-setosa      Iris-setosa\n","20    21      Iris-setosa      Iris-setosa\n","21    22      Iris-setosa      Iris-setosa\n","22    23      Iris-setosa      Iris-setosa\n","23    24      Iris-setosa      Iris-setosa\n","24    25      Iris-setosa      Iris-setosa\n","25    26      Iris-setosa      Iris-setosa\n","26    27      Iris-setosa      Iris-setosa\n","27    28      Iris-setosa      Iris-setosa\n","28    29      Iris-setosa      Iris-setosa\n","29    30      Iris-setosa      Iris-setosa\n","30    31      Iris-setosa      Iris-setosa\n","31    32      Iris-setosa      Iris-setosa\n","32    33      Iris-setosa      Iris-setosa\n","33    34      Iris-setosa      Iris-setosa\n","34    35      Iris-setosa      Iris-setosa\n","35    36      Iris-setosa      Iris-setosa\n","36    37      Iris-setosa      Iris-setosa\n","37    38      Iris-setosa      Iris-setosa\n","38    39      Iris-setosa      Iris-setosa\n","39    40      Iris-setosa      Iris-setosa\n","40    41      Iris-setosa      Iris-setosa\n","41    42      Iris-setosa      Iris-setosa\n","42    43      Iris-setosa      Iris-setosa\n","43    44      Iris-setosa      Iris-setosa\n","44    45      Iris-setosa      Iris-setosa\n","45    46      Iris-setosa      Iris-setosa\n","46    47      Iris-setosa      Iris-setosa\n","47    48      Iris-setosa      Iris-setosa\n","48    49      Iris-setosa      Iris-setosa\n","49    50      Iris-setosa      Iris-setosa\n","50    51  Iris-versicolor  Iris-versicolor\n","51    52  Iris-versicolor  Iris-versicolor\n","52    53  Iris-versicolor  Iris-versicolor\n","53    54  Iris-versicolor  Iris-versicolor\n","54    55  Iris-versicolor  Iris-versicolor\n","55    56  Iris-versicolor  Iris-versicolor\n","56    57  Iris-versicolor  Iris-versicolor\n","57    58  Iris-versicolor  Iris-versicolor\n","58    59  Iris-versicolor  Iris-versicolor\n","59    60  Iris-versicolor  Iris-versicolor\n","60    61  Iris-versicolor  Iris-versicolor\n","61    62  Iris-versicolor  Iris-versicolor\n","62    63  Iris-versicolor  Iris-versicolor\n","63    64  Iris-versicolor  Iris-versicolor\n","64    65  Iris-versicolor  Iris-versicolor\n","65    66  Iris-versicolor  Iris-versicolor\n","66    67  Iris-versicolor  Iris-versicolor\n","67    68  Iris-versicolor  Iris-versicolor\n","68    69  Iris-versicolor  Iris-versicolor\n","69    70  Iris-versicolor  Iris-versicolor\n","70    71  Iris-versicolor   Iris-virginica\n","71    72  Iris-versicolor  Iris-versicolor\n","72    73  Iris-versicolor  Iris-versicolor\n","73    74  Iris-versicolor  Iris-versicolor\n","74    75  Iris-versicolor  Iris-versicolor\n","75    76  Iris-versicolor  Iris-versicolor\n","76    77  Iris-versicolor  Iris-versicolor\n","77    78  Iris-versicolor  Iris-versicolor\n","78    79  Iris-versicolor  Iris-versicolor\n","79    80  Iris-versicolor  Iris-versicolor\n","80    81  Iris-versicolor  Iris-versicolor\n","81    82  Iris-versicolor  Iris-versicolor\n","82    83  Iris-versicolor  Iris-versicolor\n","83    84  Iris-versicolor  Iris-versicolor\n","84    85  Iris-versicolor  Iris-versicolor\n","85    86  Iris-versicolor  Iris-versicolor\n","86    87  Iris-versicolor  Iris-versicolor\n","87    88  Iris-versicolor  Iris-versicolor\n","88    89  Iris-versicolor  Iris-versicolor\n","89    90  Iris-versicolor  Iris-versicolor\n","90    91  Iris-versicolor  Iris-versicolor\n","91    92  Iris-versicolor  Iris-versicolor\n","92    93  Iris-versicolor  Iris-versicolor\n","93    94  Iris-versicolor  Iris-versicolor\n","94    95  Iris-versicolor  Iris-versicolor\n","95    96  Iris-versicolor  Iris-versicolor\n","96    97  Iris-versicolor  Iris-versicolor\n","97    98  Iris-versicolor  Iris-versicolor\n","98    99  Iris-versicolor  Iris-versicolor\n","99   100  Iris-versicolor  Iris-versicolor\n","100  101   Iris-virginica   Iris-virginica\n","101  102   Iris-virginica   Iris-virginica\n","102  103   Iris-virginica   Iris-virginica\n","103  104   Iris-virginica   Iris-virginica\n","104  105   Iris-virginica   Iris-virginica\n","105  106   Iris-virginica   Iris-virginica\n","106  107   Iris-virginica  Iris-versicolor\n","107  108   Iris-virginica   Iris-virginica\n","108  109   Iris-virginica   Iris-virginica\n","109  110   Iris-virginica   Iris-virginica\n","110  111   Iris-virginica   Iris-virginica\n","111  112   Iris-virginica   Iris-virginica\n","112  113   Iris-virginica   Iris-virginica\n","113  114   Iris-virginica   Iris-virginica\n","114  115   Iris-virginica   Iris-virginica\n","115  116   Iris-virginica   Iris-virginica\n","116  117   Iris-virginica   Iris-virginica\n","117  118   Iris-virginica   Iris-virginica\n","118  119   Iris-virginica   Iris-virginica\n","119  120   Iris-virginica  Iris-versicolor\n","120  121   Iris-virginica   Iris-virginica\n","121  122   Iris-virginica   Iris-virginica\n","122  123   Iris-virginica   Iris-virginica\n","123  124   Iris-virginica   Iris-virginica\n","124  125   Iris-virginica   Iris-virginica\n","125  126   Iris-virginica   Iris-virginica\n","126  127   Iris-virginica   Iris-virginica\n","127  128   Iris-virginica   Iris-virginica\n","128  129   Iris-virginica   Iris-virginica\n","129  130   Iris-virginica   Iris-virginica\n","130  131   Iris-virginica   Iris-virginica\n","131  132   Iris-virginica   Iris-virginica\n","132  133   Iris-virginica   Iris-virginica\n","133  134   Iris-virginica  Iris-versicolor\n","134  135   Iris-virginica  Iris-versicolor\n","135  136   Iris-virginica   Iris-virginica\n","136  137   Iris-virginica   Iris-virginica\n","137  138   Iris-virginica   Iris-virginica\n","138  139   Iris-virginica   Iris-virginica\n","139  140   Iris-virginica   Iris-virginica\n","140  141   Iris-virginica   Iris-virginica\n","141  142   Iris-virginica   Iris-virginica\n","142  143   Iris-virginica   Iris-virginica\n","143  144   Iris-virginica   Iris-virginica\n","144  145   Iris-virginica   Iris-virginica\n","145  146   Iris-virginica   Iris-virginica\n","146  147   Iris-virginica   Iris-virginica\n","147  148   Iris-virginica   Iris-virginica\n","148  149   Iris-virginica   Iris-virginica\n","149  150   Iris-virginica   Iris-virginica\n","\n","=== Akurasi ===\n","Akurasi: 0.97\n","\n","=== Laporan Klasifikasi ===\n","                 precision    recall  f1-score   support\n","\n","    Iris-setosa       1.00      1.00      1.00        50\n","Iris-versicolor       0.92      0.98      0.95        50\n"," Iris-virginica       0.98      0.92      0.95        50\n","\n","       accuracy                           0.97       150\n","      macro avg       0.97      0.97      0.97       150\n","   weighted avg       0.97      0.97      0.97       150"],"metadata":{"id":"GbWrUoirPe1b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Klasifikasi Naive Bayes Data Tanpa Diskritisasi**\n","\n","Kode ini merupakan implementasi dari algoritma **Naive Bayes (GaussianNB)** untuk melakukan klasifikasi pada data **Iris**. Langkah pertama adalah memuat dua dataset yang diperlukan, yaitu `data_iris.xlsx` yang berisi fitur numerik seperti panjang dan lebar kelopak/sepal, serta `class.xlsx` yang berisi label atau kelas asli dari setiap data.\n","\n","Setelah data dimuat, kolom `'id'` dihapus dari data fitur karena tidak relevan dalam proses pelatihan model. Selanjutnya, model **Gaussian Naive Bayes** diinisialisasi dan dilatih menggunakan fitur dari dataset iris (`X`) dan label aktual (`y_true`) dari file kelas. GaussianNB dipilih karena sesuai untuk data numerik dan mengasumsikan bahwa fitur mengikuti distribusi Gaussian (normal).\n","\n","Setelah pelatihan, model digunakan untuk memprediksi kelas berdasarkan fitur yang sama, dan hasil prediksi dibandingkan dengan label asli. Evaluasi model dilakukan dengan menghitung **akurasi**, **matriks konfusi**, dan **laporan klasifikasi** untuk melihat sejauh mana model dapat mengklasifikasikan data dengan benar. Hasil evaluasi ditampilkan di layar, dan juga disimpan dalam file `naive_bayes_classification_results.xlsx` dalam bentuk tabel berisi perbandingan antara kelas asli dan hasil prediksi. Kode ini menunjukkan penggunaan sederhana namun efektif dari Naive Bayes dalam klasifikasi data numerik seperti dataset Iris.\n"],"metadata":{"id":"2DKeVHBAPnKq"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Memuat dataset\n","try:\n","    df_iris = pd.read_excel('data_iris.xlsx')\n","    df_class = pd.read_excel('class.xlsx')\n","except FileNotFoundError as e:\n","    print(f\"Error loading file: {e}. Pastikan file berada di direktori yang sama.\")\n","    exit()\n","\n","# Menyiapkan data\n","# Fitur (X) diambil dari df_iris, mengecualikan kolom 'id'\n","X = df_iris.drop('id', axis=1)\n","\n","# Label sebenarnya (y_true) diambil dari kolom 'class' di df_class\n","y_true = df_class['class']\n","\n","# Memastikan jumlah baris di X dan y_true cocok\n","if X.shape[0] != y_true.shape[0]:\n","    print(\"Error: Jumlah baris pada fitur dan variabel target sebenarnya tidak cocok.\")\n","    exit()\n","\n","# Menginisialisasi model Gaussian Naive Bayes\n","model = GaussianNB()\n","\n","# Melatih model menggunakan fitur dari df_iris dan label sebenarnya dari df_class\n","model.fit(X, y_true)\n","\n","# Membuat prediksi pada fitur yang sama\n","y_pred = model.predict(X)\n","\n","# Membandingkan prediksi dengan kelas aktual (y_true)\n","comparison_df = pd.DataFrame({'True Class': y_true, 'Predicted Class': y_pred})\n","print(\"\\nPerbandingan Kelas Aktual dan Kelas Prediksi:\")\n","print(comparison_df.head())\n","\n","# Mengevaluasi model\n","accuracy = accuracy_score(y_true, y_pred)\n","conf_matrix = confusion_matrix(y_true, y_pred)\n","class_report = classification_report(y_true, y_pred)\n","\n","print(f\"\\nAkurasi: {accuracy:.4f}\")\n","print(\"\\nMatriks Konfusi:\")\n","print(conf_matrix)\n","print(\"\\nLaporan Klasifikasi:\")\n","print(class_report)\n","\n","comparison_df.to_excel('naive_bayes_classification_results.xlsx', index=False)"],"metadata":{"id":"7qURLx2RPpF8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Perbandingan Kelas Aktual dan Kelas Prediksi:\n","    True Class Predicted Class\n","0  Iris-setosa     Iris-setosa\n","1  Iris-setosa     Iris-setosa\n","2  Iris-setosa     Iris-setosa\n","3  Iris-setosa     Iris-setosa\n","4  Iris-setosa     Iris-setosa\n","\n","Akurasi: 0.9600\n","\n","Matriks Konfusi:\n","[[50  0  0]\n"," [ 0 47  3]\n"," [ 0  3 47]]\n","\n","Laporan Klasifikasi:\n","                 precision    recall  f1-score   support\n","\n","    Iris-setosa       1.00      1.00      1.00        50\n","Iris-versicolor       0.94      0.94      0.94        50\n"," Iris-virginica       0.94      0.94      0.94        50\n","\n","       accuracy                           0.96       150\n","      macro avg       0.96      0.96      0.96       150\n","   weighted avg       0.96      0.96      0.96       150"],"metadata":{"id":"RmuIWqfsPsDx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Klasifikasi Decision Tree Data Diskrit**\n","\n","Kode ini merupakan implementasi algoritma **Decision Tree** untuk klasifikasi data **Iris yang telah didiskritisasi**, yaitu data yang fitur-fiturnya telah diubah dari nilai numerik menjadi kategori. Dataset yang digunakan adalah `data_iris_kategori_lengkap.xlsx`, sedangkan label kelas aktual diambil dari file `class.xlsx`. Langkah pertama dalam proses ini adalah memuat kedua file tersebut dan mengekstrak fitur kategorikal seperti `sepal_length`, `sepal_width`, `petal_length`, dan `petal_width`.\n","\n","Karena data bersifat kategorikal, diperlukan proses **One-Hot Encoding** menggunakan `OneHotEncoder` dari Scikit-Learn untuk mengubah nilai kategori menjadi representasi numerik biner. Hasil encoding ini kemudian dikonversi ke dalam DataFrame baru agar dapat digunakan oleh model Decision Tree. Setelah itu, model dilatih menggunakan data yang sudah di-encode, dan prediksi dilakukan terhadap seluruh data.\n","\n","Proses evaluasi dilakukan dengan menghitung **akurasi**, **matriks konfusi**, dan **laporan klasifikasi** untuk menilai kinerja model. Hasil evaluasi ditampilkan di terminal dan juga disimpan ke dalam file Excel `decision_tree_discretized_classification_results.xlsx`, yang berisi perbandingan antara kelas aktual dan hasil prediksi. Kode ini menunjukkan bagaimana menangani data kategorikal dalam machine learning dengan preprocessing yang sesuai, serta bagaimana Decision Tree mampu menangani fitur hasil diskritisasi secara langsung."],"metadata":{"id":"YU1cujtnPv1M"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import train_test_split # Meskipun tidak digunakan untuk split di sini, ini adalah praktik baik\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","from sklearn.preprocessing import OneHotEncoder\n","\n","# --- 1. Memuat data yang sudah didiskritisasi ---\n","try:\n","    df_discretized = pd.read_excel('data_iris_kategori_lengkap.xlsx')\n","    df_true_class = pd.read_excel('class.xlsx')\n","except FileNotFoundError as e:\n","    print(f\"Error loading file: {e}. Pastikan file berada di direktori yang sama.\")\n","    exit()\n","\n","# --- 2. Menyiapkan data ---\n","categorical_features = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n","X_categorical = df_discretized[categorical_features]\n","\n","# Variabel target (y) dari file kelas aktual\n","y = df_true_class['class']\n","\n","encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n","X_encoded = encoder.fit_transform(X_categorical)\n","\n","feature_names = encoder.get_feature_names_out(categorical_features)\n","X_df_encoded = pd.DataFrame(X_encoded, columns=feature_names)\n","\n","if X_df_encoded.shape[0] != y.shape[0]:\n","    print(\"Error: Jumlah baris pada fitur yang di-encode dan variabel target tidak cocok.\")\n","    exit()\n","\n","# --- 3. Melatih pengklasifikasi Decision Tree ---\n","# random_state digunakan untuk reproduksibilitas hasil\n","model = DecisionTreeClassifier(random_state=42)\n","\n","# Melatih model\n","model.fit(X_df_encoded, y)\n","\n","# --- 4. Membuat prediksi ---\n","y_pred = model.predict(X_df_encoded)\n","\n","# --- 5. Mengevaluasi model ---\n","accuracy = accuracy_score(y, y_pred)\n","conf_matrix = confusion_matrix(y, y_pred)\n","class_report = classification_report(y, y_pred)\n","\n","print(f\"\\nAkurasi Model Decision Tree (Data Diskritisasi): {accuracy:.4f}\")\n","print(\"\\nMatriks Konfusi:\")\n","print(conf_matrix)\n","print(\"\\nLaporan Klasifikasi:\")\n","print(class_report)\n","\n","# Secara opsional, simpan perbandingan kelas aktual dan prediksi ke file CSV\n","comparison_df_dt = pd.DataFrame({'True Class': y, 'Predicted Class': y_pred})\n","comparison_df_dt.to_excel('decision_tree_discretized_classification_results.xlsx', index=False)"],"metadata":{"id":"bea49QW6P0UD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Akurasi Model Decision Tree (Data Diskritisasi): 0.9800\n","\n","Matriks Konfusi:\n","[[50  0  0]\n"," [ 0 49  1]\n"," [ 0  2 48]]\n","\n","Laporan Klasifikasi:\n","                 precision    recall  f1-score   support\n","\n","    Iris-setosa       1.00      1.00      1.00        50\n","Iris-versicolor       0.96      0.98      0.97        50\n"," Iris-virginica       0.98      0.96      0.97        50\n","\n","       accuracy                           0.98       150\n","      macro avg       0.98      0.98      0.98       150\n","   weighted avg       0.98      0.98      0.98       150"],"metadata":{"id":"H39y2tNMP3sO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","df= pd.read_excel('decision_tree_discretized_classification_results.xlsx')\n","# Tampilkan semua baris\n","pd.set_option('display.max_rows', None)\n","print(df)"],"metadata":{"id":"rvTnTNEzP9nY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["          True Class  Predicted Class\n","0        Iris-setosa      Iris-setosa\n","1        Iris-setosa      Iris-setosa\n","2        Iris-setosa      Iris-setosa\n","3        Iris-setosa      Iris-setosa\n","4        Iris-setosa      Iris-setosa\n","5        Iris-setosa      Iris-setosa\n","6        Iris-setosa      Iris-setosa\n","7        Iris-setosa      Iris-setosa\n","8        Iris-setosa      Iris-setosa\n","9        Iris-setosa      Iris-setosa\n","10       Iris-setosa      Iris-setosa\n","11       Iris-setosa      Iris-setosa\n","12       Iris-setosa      Iris-setosa\n","13       Iris-setosa      Iris-setosa\n","14       Iris-setosa      Iris-setosa\n","15       Iris-setosa      Iris-setosa\n","16       Iris-setosa      Iris-setosa\n","17       Iris-setosa      Iris-setosa\n","18       Iris-setosa      Iris-setosa\n","19       Iris-setosa      Iris-setosa\n","20       Iris-setosa      Iris-setosa\n","21       Iris-setosa      Iris-setosa\n","22       Iris-setosa      Iris-setosa\n","23       Iris-setosa      Iris-setosa\n","24       Iris-setosa      Iris-setosa\n","25       Iris-setosa      Iris-setosa\n","26       Iris-setosa      Iris-setosa\n","27       Iris-setosa      Iris-setosa\n","28       Iris-setosa      Iris-setosa\n","29       Iris-setosa      Iris-setosa\n","30       Iris-setosa      Iris-setosa\n","31       Iris-setosa      Iris-setosa\n","32       Iris-setosa      Iris-setosa\n","33       Iris-setosa      Iris-setosa\n","34       Iris-setosa      Iris-setosa\n","35       Iris-setosa      Iris-setosa\n","36       Iris-setosa      Iris-setosa\n","37       Iris-setosa      Iris-setosa\n","38       Iris-setosa      Iris-setosa\n","39       Iris-setosa      Iris-setosa\n","40       Iris-setosa      Iris-setosa\n","41       Iris-setosa      Iris-setosa\n","42       Iris-setosa      Iris-setosa\n","43       Iris-setosa      Iris-setosa\n","44       Iris-setosa      Iris-setosa\n","45       Iris-setosa      Iris-setosa\n","46       Iris-setosa      Iris-setosa\n","47       Iris-setosa      Iris-setosa\n","48       Iris-setosa      Iris-setosa\n","49       Iris-setosa      Iris-setosa\n","50   Iris-versicolor  Iris-versicolor\n","51   Iris-versicolor  Iris-versicolor\n","52   Iris-versicolor  Iris-versicolor\n","53   Iris-versicolor  Iris-versicolor\n","54   Iris-versicolor  Iris-versicolor\n","55   Iris-versicolor  Iris-versicolor\n","56   Iris-versicolor  Iris-versicolor\n","57   Iris-versicolor  Iris-versicolor\n","58   Iris-versicolor  Iris-versicolor\n","59   Iris-versicolor  Iris-versicolor\n","60   Iris-versicolor  Iris-versicolor\n","61   Iris-versicolor  Iris-versicolor\n","62   Iris-versicolor  Iris-versicolor\n","63   Iris-versicolor  Iris-versicolor\n","64   Iris-versicolor  Iris-versicolor\n","65   Iris-versicolor  Iris-versicolor\n","66   Iris-versicolor  Iris-versicolor\n","67   Iris-versicolor  Iris-versicolor\n","68   Iris-versicolor  Iris-versicolor\n","69   Iris-versicolor  Iris-versicolor\n","70   Iris-versicolor   Iris-virginica\n","71   Iris-versicolor  Iris-versicolor\n","72   Iris-versicolor  Iris-versicolor\n","73   Iris-versicolor  Iris-versicolor\n","74   Iris-versicolor  Iris-versicolor\n","75   Iris-versicolor  Iris-versicolor\n","76   Iris-versicolor  Iris-versicolor\n","77   Iris-versicolor  Iris-versicolor\n","78   Iris-versicolor  Iris-versicolor\n","79   Iris-versicolor  Iris-versicolor\n","80   Iris-versicolor  Iris-versicolor\n","81   Iris-versicolor  Iris-versicolor\n","82   Iris-versicolor  Iris-versicolor\n","83   Iris-versicolor  Iris-versicolor\n","84   Iris-versicolor  Iris-versicolor\n","85   Iris-versicolor  Iris-versicolor\n","86   Iris-versicolor  Iris-versicolor\n","87   Iris-versicolor  Iris-versicolor\n","88   Iris-versicolor  Iris-versicolor\n","89   Iris-versicolor  Iris-versicolor\n","90   Iris-versicolor  Iris-versicolor\n","91   Iris-versicolor  Iris-versicolor\n","92   Iris-versicolor  Iris-versicolor\n","93   Iris-versicolor  Iris-versicolor\n","94   Iris-versicolor  Iris-versicolor\n","95   Iris-versicolor  Iris-versicolor\n","96   Iris-versicolor  Iris-versicolor\n","97   Iris-versicolor  Iris-versicolor\n","98   Iris-versicolor  Iris-versicolor\n","99   Iris-versicolor  Iris-versicolor\n","100   Iris-virginica   Iris-virginica\n","101   Iris-virginica   Iris-virginica\n","102   Iris-virginica   Iris-virginica\n","103   Iris-virginica   Iris-virginica\n","104   Iris-virginica   Iris-virginica\n","105   Iris-virginica   Iris-virginica\n","106   Iris-virginica   Iris-virginica\n","107   Iris-virginica   Iris-virginica\n","108   Iris-virginica   Iris-virginica\n","109   Iris-virginica   Iris-virginica\n","110   Iris-virginica   Iris-virginica\n","111   Iris-virginica   Iris-virginica\n","112   Iris-virginica   Iris-virginica\n","113   Iris-virginica   Iris-virginica\n","114   Iris-virginica   Iris-virginica\n","115   Iris-virginica   Iris-virginica\n","116   Iris-virginica   Iris-virginica\n","117   Iris-virginica   Iris-virginica\n","118   Iris-virginica   Iris-virginica\n","119   Iris-virginica  Iris-versicolor\n","120   Iris-virginica   Iris-virginica\n","121   Iris-virginica   Iris-virginica\n","122   Iris-virginica   Iris-virginica\n","123   Iris-virginica   Iris-virginica\n","124   Iris-virginica   Iris-virginica\n","125   Iris-virginica   Iris-virginica\n","126   Iris-virginica   Iris-virginica\n","127   Iris-virginica   Iris-virginica\n","128   Iris-virginica   Iris-virginica\n","129   Iris-virginica   Iris-virginica\n","130   Iris-virginica   Iris-virginica\n","131   Iris-virginica   Iris-virginica\n","132   Iris-virginica   Iris-virginica\n","133   Iris-virginica  Iris-versicolor\n","134   Iris-virginica   Iris-virginica\n","135   Iris-virginica   Iris-virginica\n","136   Iris-virginica   Iris-virginica\n","137   Iris-virginica   Iris-virginica\n","138   Iris-virginica   Iris-virginica\n","139   Iris-virginica   Iris-virginica\n","140   Iris-virginica   Iris-virginica\n","141   Iris-virginica   Iris-virginica\n","142   Iris-virginica   Iris-virginica\n","143   Iris-virginica   Iris-virginica\n","144   Iris-virginica   Iris-virginica\n","145   Iris-virginica   Iris-virginica\n","146   Iris-virginica   Iris-virginica\n","147   Iris-virginica   Iris-virginica\n","148   Iris-virginica   Iris-virginica\n","149   Iris-virginica   Iris-virginica"],"metadata":{"id":"3dYew1JEQA_h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Klasifikasi Decision Tree Data Tanpa Diskritisasi**\n","\n","Kode ini merupakan implementasi **algoritma Decision Tree** untuk melakukan klasifikasi pada dataset Iris yang telah dimodifikasi. Proses diawali dengan **memuat dua file Excel**, yaitu `data_iris.xlsx` yang berisi data fitur (seperti `petal_length`, `petal_width`, `sepal_length`, dan `sepal_width`) dan `class.xlsx` yang berisi label kelas aktual dari masing-masing sampel. Setelah itu, fitur dan label dipisahkan ke dalam variabel `X` dan `y`. Kode ini juga menyertakan pengecekan kesesuaian jumlah data antara `X` dan `y` sebagai langkah validasi awal.\n","\n","Selanjutnya, sebuah **model Decision Tree Classifier** dilatih menggunakan seluruh dataset tanpa dilakukan pemisahan data training dan testing, yang sebenarnya dalam praktik terbaik seharusnya menggunakan `train_test_split` untuk menghindari overfitting dan memberikan evaluasi yang lebih realistis terhadap performa model. Setelah model dilatih, dilakukan prediksi terhadap seluruh data, lalu hasil prediksi dibandingkan dengan kelas aktual untuk menghitung **akurasi**, **matriks konfusi**, dan **laporan klasifikasi**.\n","\n","Hasil evaluasi kemudian ditampilkan dalam bentuk teks, dan juga disimpan dalam file Excel `decision_tree_original_iris_classification_results.xlsx` untuk keperluan dokumentasi atau analisis lebih lanjut. Dengan cara ini, proses klasifikasi pada dataset Iris dapat dianalisis secara lebih sistematis dan transparan."],"metadata":{"id":"x8aNOqTKQKcf"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import train_test_split # Termasuk untuk praktik baik\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# --- 1. Memuat data Iris asli ---\n","try:\n","    df_iris_original = pd.read_excel('data_iris.xlsx')\n","    df_true_class = pd.read_excel('class.xlsx')\n","except FileNotFoundError as e:\n","    print(f\"Error loading file: {e}. Pastikan file berada di direktori yang sama.\")\n","    exit()\n","\n","# --- 2. Menyiapkan data ---\n","# Fitur (X) dari data Iris asli, mengecualikan kolom 'id'\n","features = ['petal_length', 'petal_width', 'sepal_length', 'sepal_width']\n","X = df_iris_original[features]\n","\n","# Variabel target (y) dari file kelas aktual\n","y = df_true_class['class']\n","\n","# Memastikan jumlah sampel di X dan y cocok\n","if X.shape[0] != y.shape[0]:\n","    print(\"Error: Jumlah baris pada fitur dan variabel target tidak cocok.\")\n","    exit()\n","\n","# Untuk tujuan demonstrasi ini, kita akan melatih dan mengevaluasi pada seluruh dataset.\n","# Dalam skenario dunia nyata, sangat disarankan untuk menggunakan train_test_split\n","# untuk membagi data menjadi set pelatihan dan pengujian guna mendapatkan evaluasi model yang lebih realistis.\n","# Contoh penggunaan train_test_split:\n","# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# --- 3. Melatih pengklasifikasi Decision Tree ---\n","# random_state digunakan untuk reproduksibilitas hasil\n","model = DecisionTreeClassifier(random_state=42)\n","\n","# Melatih model\n","model.fit(X, y)\n","\n","# --- 4. Membuat prediksi ---\n","y_pred = model.predict(X)\n","\n","# --- 5. Mengevaluasi model ---\n","accuracy = accuracy_score(y, y_pred)\n","conf_matrix = confusion_matrix(y, y_pred)\n","class_report = classification_report(y, y_pred)\n","\n","print(f\"\\nAkurasi Model Decision Tree (Data Iris Asli): {accuracy:.4f}\")\n","print(\"\\nMatriks Konfusi:\")\n","print(conf_matrix)\n","print(\"\\nLaporan Klasifikasi:\")\n","print(class_report)\n","\n","comparison_df_dt_original = pd.DataFrame({'True Class': y, 'Predicted Class': y_pred})\n","comparison_df_dt_original.to_excel('decision_tree_original_iris_classification_results.xlsx', index=False)"],"metadata":{"id":"kuN6t235QMOB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Akurasi Model Decision Tree (Data Iris Asli): 1.0000\n","\n","Matriks Konfusi:\n","[[50  0  0]\n"," [ 0 50  0]\n"," [ 0  0 50]]\n","\n","Laporan Klasifikasi:\n","                 precision    recall  f1-score   support\n","\n","    Iris-setosa       1.00      1.00      1.00        50\n","Iris-versicolor       1.00      1.00      1.00        50\n"," Iris-virginica       1.00      1.00      1.00        50\n","\n","       accuracy                           1.00       150\n","      macro avg       1.00      1.00      1.00       150\n","   weighted avg       1.00      1.00      1.00       150"],"metadata":{"id":"CdHMY3m6QOsE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","df= pd.read_excel('decision_tree_original_iris_classification_results.xlsx')\n","\n","# Tampilkan semua baris\n","pd.set_option('display.max_rows', None)\n","print(df)"],"metadata":{"id":"5S065GjXQirp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["          True Class  Predicted Class\n","0        Iris-setosa      Iris-setosa\n","1        Iris-setosa      Iris-setosa\n","2        Iris-setosa      Iris-setosa\n","3        Iris-setosa      Iris-setosa\n","4        Iris-setosa      Iris-setosa\n","5        Iris-setosa      Iris-setosa\n","6        Iris-setosa      Iris-setosa\n","7        Iris-setosa      Iris-setosa\n","8        Iris-setosa      Iris-setosa\n","9        Iris-setosa      Iris-setosa\n","10       Iris-setosa      Iris-setosa\n","11       Iris-setosa      Iris-setosa\n","12       Iris-setosa      Iris-setosa\n","13       Iris-setosa      Iris-setosa\n","14       Iris-setosa      Iris-setosa\n","15       Iris-setosa      Iris-setosa\n","16       Iris-setosa      Iris-setosa\n","17       Iris-setosa      Iris-setosa\n","18       Iris-setosa      Iris-setosa\n","19       Iris-setosa      Iris-setosa\n","20       Iris-setosa      Iris-setosa\n","21       Iris-setosa      Iris-setosa\n","22       Iris-setosa      Iris-setosa\n","23       Iris-setosa      Iris-setosa\n","24       Iris-setosa      Iris-setosa\n","25       Iris-setosa      Iris-setosa\n","26       Iris-setosa      Iris-setosa\n","27       Iris-setosa      Iris-setosa\n","28       Iris-setosa      Iris-setosa\n","29       Iris-setosa      Iris-setosa\n","30       Iris-setosa      Iris-setosa\n","31       Iris-setosa      Iris-setosa\n","32       Iris-setosa      Iris-setosa\n","33       Iris-setosa      Iris-setosa\n","34       Iris-setosa      Iris-setosa\n","35       Iris-setosa      Iris-setosa\n","36       Iris-setosa      Iris-setosa\n","37       Iris-setosa      Iris-setosa\n","38       Iris-setosa      Iris-setosa\n","39       Iris-setosa      Iris-setosa\n","40       Iris-setosa      Iris-setosa\n","41       Iris-setosa      Iris-setosa\n","42       Iris-setosa      Iris-setosa\n","43       Iris-setosa      Iris-setosa\n","44       Iris-setosa      Iris-setosa\n","45       Iris-setosa      Iris-setosa\n","46       Iris-setosa      Iris-setosa\n","47       Iris-setosa      Iris-setosa\n","48       Iris-setosa      Iris-setosa\n","49       Iris-setosa      Iris-setosa\n","50   Iris-versicolor  Iris-versicolor\n","51   Iris-versicolor  Iris-versicolor\n","52   Iris-versicolor  Iris-versicolor\n","53   Iris-versicolor  Iris-versicolor\n","54   Iris-versicolor  Iris-versicolor\n","55   Iris-versicolor  Iris-versicolor\n","56   Iris-versicolor  Iris-versicolor\n","57   Iris-versicolor  Iris-versicolor\n","58   Iris-versicolor  Iris-versicolor\n","59   Iris-versicolor  Iris-versicolor\n","60   Iris-versicolor  Iris-versicolor\n","61   Iris-versicolor  Iris-versicolor\n","62   Iris-versicolor  Iris-versicolor\n","63   Iris-versicolor  Iris-versicolor\n","64   Iris-versicolor  Iris-versicolor\n","65   Iris-versicolor  Iris-versicolor\n","66   Iris-versicolor  Iris-versicolor\n","67   Iris-versicolor  Iris-versicolor\n","68   Iris-versicolor  Iris-versicolor\n","69   Iris-versicolor  Iris-versicolor\n","70   Iris-versicolor  Iris-versicolor\n","71   Iris-versicolor  Iris-versicolor\n","72   Iris-versicolor  Iris-versicolor\n","73   Iris-versicolor  Iris-versicolor\n","74   Iris-versicolor  Iris-versicolor\n","75   Iris-versicolor  Iris-versicolor\n","76   Iris-versicolor  Iris-versicolor\n","77   Iris-versicolor  Iris-versicolor\n","78   Iris-versicolor  Iris-versicolor\n","79   Iris-versicolor  Iris-versicolor\n","80   Iris-versicolor  Iris-versicolor\n","81   Iris-versicolor  Iris-versicolor\n","82   Iris-versicolor  Iris-versicolor\n","83   Iris-versicolor  Iris-versicolor\n","84   Iris-versicolor  Iris-versicolor\n","85   Iris-versicolor  Iris-versicolor\n","86   Iris-versicolor  Iris-versicolor\n","87   Iris-versicolor  Iris-versicolor\n","88   Iris-versicolor  Iris-versicolor\n","89   Iris-versicolor  Iris-versicolor\n","90   Iris-versicolor  Iris-versicolor\n","91   Iris-versicolor  Iris-versicolor\n","92   Iris-versicolor  Iris-versicolor\n","93   Iris-versicolor  Iris-versicolor\n","94   Iris-versicolor  Iris-versicolor\n","95   Iris-versicolor  Iris-versicolor\n","96   Iris-versicolor  Iris-versicolor\n","97   Iris-versicolor  Iris-versicolor\n","98   Iris-versicolor  Iris-versicolor\n","99   Iris-versicolor  Iris-versicolor\n","100   Iris-virginica   Iris-virginica\n","101   Iris-virginica   Iris-virginica\n","102   Iris-virginica   Iris-virginica\n","103   Iris-virginica   Iris-virginica\n","104   Iris-virginica   Iris-virginica\n","105   Iris-virginica   Iris-virginica\n","106   Iris-virginica   Iris-virginica\n","107   Iris-virginica   Iris-virginica\n","108   Iris-virginica   Iris-virginica\n","109   Iris-virginica   Iris-virginica\n","110   Iris-virginica   Iris-virginica\n","111   Iris-virginica   Iris-virginica\n","112   Iris-virginica   Iris-virginica\n","113   Iris-virginica   Iris-virginica\n","114   Iris-virginica   Iris-virginica\n","115   Iris-virginica   Iris-virginica\n","116   Iris-virginica   Iris-virginica\n","117   Iris-virginica   Iris-virginica\n","118   Iris-virginica   Iris-virginica\n","119   Iris-virginica   Iris-virginica\n","120   Iris-virginica   Iris-virginica\n","121   Iris-virginica   Iris-virginica\n","122   Iris-virginica   Iris-virginica\n","123   Iris-virginica   Iris-virginica\n","124   Iris-virginica   Iris-virginica\n","125   Iris-virginica   Iris-virginica\n","126   Iris-virginica   Iris-virginica\n","127   Iris-virginica   Iris-virginica\n","128   Iris-virginica   Iris-virginica\n","129   Iris-virginica   Iris-virginica\n","130   Iris-virginica   Iris-virginica\n","131   Iris-virginica   Iris-virginica\n","132   Iris-virginica   Iris-virginica\n","133   Iris-virginica   Iris-virginica\n","134   Iris-virginica   Iris-virginica\n","135   Iris-virginica   Iris-virginica\n","136   Iris-virginica   Iris-virginica\n","137   Iris-virginica   Iris-virginica\n","138   Iris-virginica   Iris-virginica\n","139   Iris-virginica   Iris-virginica\n","140   Iris-virginica   Iris-virginica\n","141   Iris-virginica   Iris-virginica\n","142   Iris-virginica   Iris-virginica\n","143   Iris-virginica   Iris-virginica\n","144   Iris-virginica   Iris-virginica\n","145   Iris-virginica   Iris-virginica\n","146   Iris-virginica   Iris-virginica\n","147   Iris-virginica   Iris-virginica\n","148   Iris-virginica   Iris-virginica\n","149   Iris-virginica   Iris-virginica"],"metadata":{"id":"R_FPFOlpQlE2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Kesimpulan**"],"metadata":{"id":"hgceskyOQ53D"}},{"cell_type":"markdown","source":["| **Model**                    | **Akurasi** |\n","| ---------------------------- | ----------- |\n","| Naive Bayes (diskretisasi)   | 0.97        |\n","| Naive Bayes (data asli)      | 0.96        |\n","| Decision Tree (diskretisasi) | 0.98        |\n","| Decision Tree (data asli)    | 1.00        |\n","\n","Secara umum, model Decision Tree menunjukkan performa yang lebih unggul dibandingkan Naive Bayes dalam mengolah dataset Iris, baik pada data asli maupun data yang telah melalui proses diskretisasi. Namun, dampak dari proses diskretisasi ternyata memberikan pengaruh yang berbeda pada masing-masing model, dengan rincian sebagai berikut:\n","\n","Naive Bayes:\n","Proses diskretisasi meningkatkan akurasi model, dari sebelumnya 0.96 menjadi 0.97. Hal ini menunjukkan bahwa Naive Bayes lebih optimal dalam menangani fitur-fitur yang telah dikonversi menjadi kategori. Karakteristik Naive Bayes yang didasarkan pada distribusi probabilistik menjadikannya lebih cocok dengan data kategorikal.\n","\n","Decision Tree:\n","Sebaliknya, akurasi model Decision Tree menurun tipis setelah dilakukan diskretisasi, dari 1.00 menjadi 0.98. Penurunan ini mengindikasikan bahwa Decision Tree mampu mengolah data numerik kontinu dengan sangat baik, bahkan mampu mencapai akurasi sempurna. Diskretisasi justru mengurangi detail informasi numerik yang dimanfaatkan oleh algoritma ini.\n","\n","Kesimpulan Akhir:\n","Diskretisasi bisa menjadi teknik yang bermanfaat untuk meningkatkan kinerja model tertentu seperti Naive Bayes, namun untuk model seperti Decision Tree yang andal dalam menangani data kontinu, mempertahankan bentuk asli fitur bisa lebih menguntungkan."],"metadata":{"id":"sd8zSNuWQ8oj"}}]}