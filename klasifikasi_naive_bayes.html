
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Klasifikasi Naive Bayes &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'klasifikasi_naive_bayes';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="üìù UTS Penambangan Data - Klasifikasi Prediksi Survival Pasien Sirosis" href="proyek_ujiantengahsemester.html" />
    <link rel="prev" title="Local Outlier Factor (LOF)" href="local_outlier_factor_%28lof%29.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="My sample book - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="My sample book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to Penambangan Data
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="data_understanding.html"><strong>Data Understanding</strong></a></li>






<li class="toctree-l1"><a class="reference internal" href="outlier_detection.html"><strong>Outliers Detection Menggunakan Metode K-Nearest Neighbors (KNN)</strong></a></li>






<li class="toctree-l1"><a class="reference internal" href="local_outlier_factor_%28lof%29.html"><strong>Local Outlier Factor (LOF)</strong></a></li>







<li class="toctree-l1 current active"><a class="current reference internal" href="#"><strong>Klasifikasi Naive Bayes</strong></a></li>






<li class="toctree-l1"><a class="reference internal" href="proyek_ujiantengahsemester.html"><strong>üìù UTS Penambangan Data - Klasifikasi Prediksi Survival Pasien Sirosis</strong></a></li>



<li class="toctree-l1"><a class="reference internal" href="algoritma_k-means_clustering.html"><strong>Pengenalan Clustering dan K-Means</strong></a></li>




</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fklasifikasi_naive_bayes.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/klasifikasi_naive_bayes.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Klasifikasi Naive Bayes</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#"><strong>Klasifikasi Naive Bayes</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#apa-itu-naive-bayes"><strong>Apa itu naive bayes‚Ä¶?</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#berikut-adalah-rumus-naive-bayes"><strong>Berikut adalah rumus naive bayes‚Ä¶!</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#contoh-perhitungan"><strong>Contoh Perhitungan</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prior-probabilities"><strong>1. Prior Probabilities</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#likelihood-dengan-laplace-smoothing"><strong>2. Likelihood dengan Laplace Smoothing</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#kalkulasi-probabilitas-naive-bayes"><strong>3. Kalkulasi Probabilitas Na√Øve Bayes</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#jenis-jenis-naive-bayes"><strong>Jenis-Jenis Naive Bayes‚Ä¶!</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#berikut-perbandingan-perhitungan-data-naive-bayes"><strong>Berikut Perbandingan Perhitungan Data Naive Bayes‚Ä¶!</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#berikut-adalah-membandingkan-data-dengan-outliers"><strong>Berikut adalah Membandingkan Data dengan Outliers‚Ä¶!</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#berikut-adalah-membandingkan-data-tanpa-outliers"><strong>Berikut adalah Membandingkan Data tanpa Outliers‚Ä¶!</strong></a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#berikut-adalah-hasil-dari-perhitungan-pada-contoh"><strong>Berikut adalah hasil dari perhitungan pada contoh‚Ä¶!</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#kesimpulan"><strong>Kesimpulan‚Ä¶!</strong></a></li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="klasifikasi-naive-bayes">
<h1><strong>Klasifikasi Naive Bayes</strong><a class="headerlink" href="#klasifikasi-naive-bayes" title="Link to this heading">#</a></h1>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="apa-itu-naive-bayes">
<h1><strong>Apa itu naive bayes‚Ä¶?</strong><a class="headerlink" href="#apa-itu-naive-bayes" title="Link to this heading">#</a></h1>
<p>Na√Øve Bayes adalah salah satu algoritma klasifikasi dalam pembelajaran mesin yang termasuk dalam metode pembelajaran terbimbing (<em>supervised learning</em>). Algoritma ini sering digunakan dalam berbagai tugas klasifikasi seperti klasifikasi teks, filtering spam, analisis sentimen, dan berbagai aplikasi lainnya. Na√Øve Bayes didasarkan pada prinsip probabilitas dan menggunakan Teorema Bayes sebagai dasar perhitungannya. Teorema Bayes memungkinkan kita untuk menghitung kemungkinan suatu kejadian berdasarkan informasi yang telah diketahui sebelumnya. Dalam konteks klasifikasi, algoritma ini menghitung probabilitas suatu kategori berdasarkan fitur-fitur yang diberikan dalam data.</p>
<p>Istilah <em>Na√Øve</em> atau <em>Naif</em> dalam Na√Øve Bayes digunakan karena algoritma ini mengasumsikan bahwa setiap fitur dalam data bersifat independen satu sama lain dalam menentukan kategori akhir. Dengan kata lain, algoritma ini menganggap bahwa tidak ada hubungan antar fitur, meskipun dalam kenyataannya mungkin ada keterkaitan. Sebagai contoh, dalam klasifikasi teks, Na√Øve Bayes mengasumsikan bahwa kemunculan sebuah kata dalam dokumen tidak dipengaruhi oleh kata lain, padahal dalam bahasa alami, kata-kata sering kali memiliki keterkaitan. Meskipun asumsi ini sederhana dan sering kali tidak realistis, algoritma Na√Øve Bayes tetap bekerja dengan baik dalam banyak kasus.</p>
<p>Na√Øve Bayes memiliki beberapa keunggulan, di antaranya adalah kecepatan dan efisiensinya dalam memproses dataset yang besar, kemudahan implementasi dengan perhitungan probabilitas sederhana, serta kemampuannya bekerja dengan baik pada data kategorikal maupun teks. Selain itu, algoritma ini tidak membutuhkan banyak data latih untuk memberikan hasil yang baik. Namun, terdapat pula beberapa kelemahan, seperti asumsi independensi fitur yang sering kali tidak sesuai dengan kondisi nyata, kurangnya akurasi jika fitur saling bergantung satu sama lain, serta sensitivitas terhadap data yang belum pernah ditemui, yang dapat menyebabkan kesalahan jika ada kata atau fitur baru yang tidak muncul dalam data pelatihan.</p>
<p>Secara keseluruhan, meskipun memiliki keterbatasan, algoritma Na√Øve Bayes tetap menjadi salah satu metode klasifikasi yang populer, terutama dalam pengolahan teks dan analisis data berbasis probabilitas. Kecepatan, kesederhanaan, dan efektivitasnya dalam menangani berbagai tugas klasifikasi menjadikannya pilihan yang kuat dalam berbagai aplikasi pembelajaran mesin.</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="berikut-adalah-rumus-naive-bayes">
<h1><strong>Berikut adalah rumus naive bayes‚Ä¶!</strong><a class="headerlink" href="#berikut-adalah-rumus-naive-bayes" title="Link to this heading">#</a></h1>
<p><strong>Na√Øve Bayes Classifier</strong></p>
<p>Na√Øve Bayes adalah metode klasifikasi berdasarkan <strong>Teorema Bayes</strong>. Rumus dasar dari Teorema Bayes adalah:</p>
<div class="math notranslate nohighlight">
\[
P(C|X) = \frac{P(X|C) \cdot P(C)}{P(X)}
\]</div>
<p>Di mana:</p>
<ul class="simple">
<li><p>( P(C|X) ) = Probabilitas kelas ( C ) berdasarkan fitur ( X ) (<em>posterior probability</em>).</p></li>
<li><p>( P(X|C) ) = Probabilitas fitur ( X ) muncul dalam kategori ( C ) (<em>likelihood</em>).</p></li>
<li><p>( P(C) ) = Probabilitas awal dari kelas ( C ) (<em>prior probability</em>).</p></li>
<li><p>( P(X) ) = Probabilitas fitur ( X ) dalam seluruh dataset (<em>evidence</em>).</p></li>
</ul>
<p>Karena dalam Na√Øve Bayes kita mengasumsikan fitur-fitur <strong>bersifat independen</strong>, maka probabilitas gabungan dari beberapa fitur ( X_1, X_2, ‚Ä¶, X_n ) dapat dihitung sebagai:</p>
<div class="math notranslate nohighlight">
\[
P(C|X_1, X_2, ..., X_n) = \frac{P(C) \cdot P(X_1|C) \cdot P(X_2|C) \cdots P(X_n|C)}{P(X_1) \cdot P(X_2) \cdots P(X_n)}
\]</div>
<p>Karena <strong>( P(X) )</strong> sama untuk semua kelas dalam klasifikasi, kita cukup menghitung pembilangnya saja:</p>
<div class="math notranslate nohighlight">
\[
P(C|X_1, X_2, ..., X_n) \propto P(C) \cdot P(X_1|C) \cdot P(X_2|C) \cdots P(X_n|C)
\]</div>
<p>Jika terdapat kemungkinan kata atau fitur belum pernah muncul dalam data latih, maka kita menggunakan <strong>Laplace Smoothing</strong> untuk menghindari probabilitas nol:</p>
<div class="math notranslate nohighlight">
\[
P(X_i|C) = \frac{\text{jumlah } X_i \text{ dalam } C + 1}{\text{total kata dalam } C + |V|}
\]</div>
<p>Di mana:</p>
<ul class="simple">
<li><p>( |V| ) adalah jumlah total kata unik dalam seluruh dataset.</p></li>
<li><p>( 1 ) adalah nilai smoothing untuk menghindari pembagian dengan nol.</p></li>
</ul>
<section id="contoh-perhitungan">
<h2><strong>Contoh Perhitungan</strong><a class="headerlink" href="#contoh-perhitungan" title="Link to this heading">#</a></h2>
<p>Misalkan kita memiliki dataset dengan dua kategori: <strong>Spam</strong> dan <strong>Non-Spam</strong>, dengan informasi berikut:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Kata dalam Email</p></th>
<th class="head"><p>Spam (( C_1 ))</p></th>
<th class="head"><p>Non-Spam (( C_2 ))</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Promo</p></td>
<td><p>3</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-odd"><td><p>Diskon</p></td>
<td><p>2</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-even"><td><p>Transfer</p></td>
<td><p>1</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-odd"><td><p>Sekarang</p></td>
<td><p>2</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-even"><td><p><strong>Total Kata</strong></p></td>
<td><p>8</p></td>
<td><p>5</p></td>
</tr>
</tbody>
</table>
</div>
<p>Jika kita ingin menghitung probabilitas bahwa email <strong>‚ÄúPromo Diskon‚Äù</strong> adalah <strong>Spam</strong>, kita gunakan rumus:</p>
<section id="prior-probabilities">
<h3><strong>1. Prior Probabilities</strong><a class="headerlink" href="#prior-probabilities" title="Link to this heading">#</a></h3>
<div class="math notranslate nohighlight">
\[
P(\text{Spam}) = \frac{\text{Jumlah Email Spam}}{\text{Total Email}}
\]</div>
</section>
<section id="likelihood-dengan-laplace-smoothing">
<h3><strong>2. Likelihood dengan Laplace Smoothing</strong><a class="headerlink" href="#likelihood-dengan-laplace-smoothing" title="Link to this heading">#</a></h3>
<div class="math notranslate nohighlight">
\[
P(\text{Promo} | \text{Spam}) = \frac{3 + 1}{8 + 4} = \frac{4}{12}
\]</div>
<div class="math notranslate nohighlight">
\[
P(\text{Diskon} | \text{Spam}) = \frac{2 + 1}{8 + 4} = \frac{3}{12}
\]</div>
</section>
<section id="kalkulasi-probabilitas-naive-bayes">
<h3><strong>3. Kalkulasi Probabilitas Na√Øve Bayes</strong><a class="headerlink" href="#kalkulasi-probabilitas-naive-bayes" title="Link to this heading">#</a></h3>
<div class="math notranslate nohighlight">
\[
P(\text{Spam} | \text{Promo, Diskon}) \propto P(\text{Spam}) \times P(\text{Promo} | \text{Spam}) \times P(\text{Diskon} | \text{Spam})
\]</div>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="jenis-jenis-naive-bayes">
<h1><strong>Jenis-Jenis Naive Bayes‚Ä¶!</strong><a class="headerlink" href="#jenis-jenis-naive-bayes" title="Link to this heading">#</a></h1>
<p>Naive Bayes merupakan metode klasifikasi yang digunakan untuk berbagai jenis data. Berikut adalah penjelasan mengenai jenis-jenis Naive Bayes yang dapat digunakan sesuai dengan tipe data yang dimiliki:</p>
<p><strong>1. Gaussian Naive Bayes</strong></p>
<p>Gaussian Naive Bayes digunakan untuk data kontinu, seperti pengukuran fisik (misalnya, tinggi badan atau berat badan). Metode ini mengasumsikan bahwa fitur-fitur data mengikuti distribusi normal (Gaussian). Probabilitas suatu fitur dihitung menggunakan distribusi normal dengan rata-rata (( \mu_C )) dan varians (( \sigma_C^2 )) dari kelas tersebut.</p>
<p>Formula probabilitasnya adalah:</p>
<div class="math notranslate nohighlight">
\[
P(X_i | C) = \frac{1}{\sqrt{2 \pi \sigma_C^2}} \exp \left( - \frac{(X_i - \mu_C)^2}{2\sigma_C^2} \right)
\]</div>
<ul class="simple">
<li><p>( X_i ) = nilai fitur ke-( i ) pada data</p></li>
<li><p>( \mu_C ) = rata-rata fitur pada kelas ( C )</p></li>
<li><p>( \sigma_C^2 ) = varians fitur pada kelas ( C )</p></li>
</ul>
<p><strong>Contoh:</strong><br />
Jika kita ingin mengklasifikasikan seseorang sebagai ‚Äútinggi‚Äù atau ‚Äúpendek‚Äù berdasarkan tinggi badan, kita bisa menggunakan Gaussian Na√Øve Bayes dengan distribusi normal untuk fitur tinggi badan pada masing-masing kategori.</p>
<p><strong>2. Multinomial Naive Bayes</strong></p>
<p>Multinomial Naive Bayes paling cocok digunakan untuk data diskrit, seperti frekuensi kemunculan fitur dalam dokumen. Misalnya, dalam klasifikasi teks, kita menghitung probabilitas kata-kata yang muncul dalam dokumen tertentu. Formula probabilitasnya adalah:</p>
<div class="math notranslate nohighlight">
\[
P(X_i | C) = \frac{n_{i,C} + \alpha}{N_C + \alpha \cdot V}
\]</div>
<ul class="simple">
<li><p>( n_{i,C} ) = jumlah kemunculan kata ( i ) dalam kelas ( C )</p></li>
<li><p>( N_C ) = jumlah total kata dalam kelas ( C )</p></li>
<li><p>( \alpha ) = parameter smoothing (biasanya ( \alpha = 1 ) untuk Laplace smoothing)</p></li>
<li><p>( V ) = jumlah total kata unik dalam seluruh dataset</p></li>
</ul>
<p><strong>Contoh:</strong><br />
Jika kita ingin mengklasifikasikan email sebagai ‚ÄúSpam‚Äù atau ‚ÄúNon-Spam‚Äù, kita dapat menghitung probabilitas kata ‚Äúdiskon‚Äù muncul dalam email spam dibandingkan dengan non-spam menggunakan Multinomial Na√Øve Bayes.</p>
<p><strong>3. Bernoulli Naive Bayes</strong></p>
<p>Bernoulli Naive Bayes digunakan untuk data biner, di mana fitur hanya memiliki dua nilai kemungkinan: ada (1) atau tidak ada (0). Probabilitas suatu fitur ( X_i ) muncul dalam kelas ( C ) dihitung dengan rumus berikut:</p>
<div class="math notranslate nohighlight">
\[
P(X_i = 1 | C) = \frac{n_{i,C} + \alpha}{N_C + \alpha}
\]</div>
<ul class="simple">
<li><p>( n_{i,C} ) = jumlah kejadian di mana fitur ( X_i ) ada dalam kelas ( C )</p></li>
<li><p>( N_C ) = jumlah total data dalam kelas ( C )</p></li>
<li><p>( \alpha ) = parameter smoothing (biasanya ( \alpha = 1 ) untuk Laplace smoothing)</p></li>
</ul>
<p><strong>Contoh:</strong><br />
Misalnya, dalam filter spam, kita dapat memeriksa apakah kata ‚Äúdiskon‚Äù ada dalam email (1) atau tidak (0) dan mengklasifikasikan email tersebut sebagai spam atau tidak spam menggunakan Bernoulli Na√Øve Bayes.</p>
<p><strong>Ringkasan Formula Probabilitas</strong></p>
<ol class="arabic simple">
<li><p><strong>Gaussian Naive Bayes</strong>:
$<span class="math notranslate nohighlight">\(
P(X_i | C) = \frac{1}{\sqrt{2 \pi \sigma_C^2}} \exp \left( - \frac{(X_i - \mu_C)^2}{2\sigma_C^2} \right)
\)</span>$</p></li>
<li><p><strong>Multinomial Naive Bayes</strong>:
$<span class="math notranslate nohighlight">\(
P(X_i | C) = \frac{n_{i,C} + \alpha}{N_C + \alpha \cdot V}
\)</span>$</p></li>
<li><p><strong>Bernoulli Naive Bayes</strong>:
$<span class="math notranslate nohighlight">\(
P(X_i = 1 | C) = \frac{n_{i,C} + \alpha}{N_C + \alpha}
\)</span>$</p></li>
</ol>
<p>Dengan rumus-rumus ini, Anda dapat menghitung probabilitas untuk setiap jenis Naive Bayes sesuai dengan data yang Anda miliki dan menentukan kelas yang paling mungkin.</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="berikut-perbandingan-perhitungan-data-naive-bayes">
<h1><strong>Berikut Perbandingan Perhitungan Data Naive Bayes‚Ä¶!</strong><a class="headerlink" href="#berikut-perbandingan-perhitungan-data-naive-bayes" title="Link to this heading">#</a></h1>
<p>Perbandingan yang dilakukan dalam penelitian ini menggunakan dataset Iris yang telah kita kumpulkan pada pertemuan sebelumnya, sehingga mempermudah dalam memperoleh data yang diperlukan. Pada langkah pertama, kita akan menghubungkan dataset Iris tersebut dengan database agar dapat memproses data lebih lanjut. Selanjutnya, perhitungan Naive Bayes dilakukan menggunakan data yang belum diproses, termasuk data yang mengandung outliers atau data kotor. Setelah itu, kita akan membersihkan data tersebut dengan menerapkan teknik Local Outlier Factor (LOF) yang telah dibahas sebelumnya untuk mendeteksi dan menghilangkan outliers dari dataset. Setelah data dibersihkan, kita akan kembali melakukan perhitungan menggunakan Naive Bayes pada data yang sudah bersih dan bebas dari outliers. Pada bagian akhir, kita akan menyajikan hasil dari kedua perhitungan tersebut, yakni perhitungan dengan data kotor dan data yang telah dibersihkan. Hasil tersebut kemudian akan dianalisis untuk mengungkapkan kesimpulan mengenai pengaruh outliers terhadap akurasi dan kinerja algoritma Naive Bayes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Mengkoneksi database dengan python</span>
<span class="c1"># Install library</span>
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>pymysql
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>psycopg2
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>sqlalchemy
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>pandas

<span class="c1"># Import library</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pymysql</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">psycopg2</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sqlalchemy</span><span class="w"> </span><span class="kn">import</span> <span class="n">create_engine</span>

<span class="c1"># for mysql</span>
<span class="n">timeout</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">connection</span> <span class="o">=</span> <span class="n">pymysql</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span>
    <span class="n">charset</span><span class="o">=</span><span class="s2">&quot;utf8mb4&quot;</span><span class="p">,</span>
    <span class="n">connect_timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">,</span>
    <span class="n">cursorclass</span><span class="o">=</span><span class="n">pymysql</span><span class="o">.</span><span class="n">cursors</span><span class="o">.</span><span class="n">DictCursor</span><span class="p">,</span>
    <span class="n">db</span><span class="o">=</span><span class="s2">&quot;defaultdb&quot;</span><span class="p">,</span>
    <span class="n">host</span><span class="o">=</span><span class="s2">&quot;mysql-726cd75-mysqlpendata-11.h.aivencloud.com&quot;</span><span class="p">,</span>
    <span class="n">password</span><span class="o">=</span><span class="s2">&quot;AVNS_LHA80D-LNsKI6wncjfc&quot;</span><span class="p">,</span>
    <span class="n">read_timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">,</span>
    <span class="n">port</span><span class="o">=</span><span class="mi">20734</span><span class="p">,</span>
    <span class="n">user</span><span class="o">=</span><span class="s2">&quot;avnadmin&quot;</span><span class="p">,</span>
    <span class="n">write_timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">mysql_engine</span> <span class="o">=</span> <span class="n">create_engine</span><span class="p">(</span><span class="s2">&quot;mysql+pymysql://avnadmin:AVNS_LHA80D-LNsKI6wncjfc@mysql-726cd75-mysqlpendata-11.h.aivencloud.com:20734/defaultdb&quot;</span><span class="p">)</span>



<span class="c1"># for postgre</span>
<span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">():</span>
    <span class="n">conn</span> <span class="o">=</span> <span class="n">psycopg2</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="s1">&#39;postgres://avnadmin:AVNS__Y6I8K0T7rSnwnRgE1U@pg-3266d3cf-postgresqlpendata-11.h.aivencloud.com:20817/defaultdb?sslmode=require&#39;</span><span class="p">)</span>

    <span class="n">query_sql</span> <span class="o">=</span> <span class="s1">&#39;SELECT VERSION()&#39;</span>

    <span class="n">cur</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">cursor</span><span class="p">()</span>
    <span class="n">cur</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="n">query_sql</span><span class="p">)</span>

    <span class="n">version</span> <span class="o">=</span> <span class="n">cur</span><span class="o">.</span><span class="n">fetchone</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">version</span><span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
<span class="n">postgres_engine</span> <span class="o">=</span> <span class="n">create_engine</span><span class="p">(</span><span class="s2">&quot;postgresql+psycopg2://avnadmin:AVNS__Y6I8K0T7rSnwnRgE1U@pg-3266d3cf-postgresqlpendata-11.h.aivencloud.com:20817/defaultdb&quot;</span><span class="p">)</span>

<span class="c1"># Ambil data dari MySQL</span>
<span class="n">mysql_query</span> <span class="o">=</span> <span class="s2">&quot;SELECT * FROM iris_data&quot;</span>
<span class="n">mysql_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_sql</span><span class="p">(</span><span class="n">mysql_query</span><span class="p">,</span> <span class="n">mysql_engine</span><span class="p">)</span>

<span class="c1"># Ambil data dari PostgreSQL</span>
<span class="n">pg_query</span> <span class="o">=</span> <span class="s1">&#39;SELECT * FROM postgre&#39;</span>
<span class="n">pg_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_sql</span><span class="p">(</span><span class="n">pg_query</span><span class="p">,</span> <span class="n">postgres_engine</span><span class="p">)</span>

<span class="n">merge_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">mysql_df</span><span class="p">,</span> <span class="n">pg_df</span><span class="p">,</span> <span class="n">left_on</span><span class="o">=</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="n">right_on</span><span class="o">=</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;outer&#39;</span><span class="p">)</span>

<span class="c1"># Menampilkan data yang diambil database dan ditampilkan dalam bentuk tabel</span>
<span class="n">selected_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;class&quot;</span><span class="p">,</span> <span class="s2">&quot;petal_length&quot;</span><span class="p">,</span> <span class="s2">&quot;petal_width&quot;</span><span class="p">,</span> <span class="s2">&quot;sepal length&quot;</span><span class="p">,</span> <span class="s2">&quot;sepal width&quot;</span><span class="p">]</span>
<span class="n">filtered_df</span> <span class="o">=</span> <span class="n">merge_df</span><span class="p">[</span><span class="n">selected_columns</span><span class="p">]</span>

<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Berikut ini adalah hasil dari data yang diambil:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">filtered_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: pymysql in /usr/local/lib/python3.11/dist-packages (1.1.1)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: psycopg2 in /usr/local/lib/python3.11/dist-packages (2.9.10)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.11/dist-packages (2.0.39)
Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (3.1.1)
Requirement already satisfied: typing-extensions&gt;=4.6.0 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (4.12.2)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)
Requirement already satisfied: numpy&gt;=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)
Requirement already satisfied: python-dateutil&gt;=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)
Requirement already satisfied: pytz&gt;=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)
Requirement already satisfied: tzdata&gt;=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil&gt;=2.8.2-&gt;pandas) (1.17.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>PostgreSQL 16.8 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 14.2.1 20240912 (Red Hat 14.2.1-3), 64-bit
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Berikut ini adalah hasil dari data yang diambil:

      id           class  petal_length  petal_width  sepal length  sepal width
0      1     Iris-setosa          86.4         70.0          20.1         30.5
1      2     Iris-setosa           1.4          0.2           4.9          3.0
2      3     Iris-setosa           1.3          0.2           4.7          3.2
3      4     Iris-setosa           1.5          0.2           4.6          3.1
4      5     Iris-setosa           1.4          0.2           5.0          3.6
..   ...             ...           ...          ...           ...          ...
145  146  Iris-virginica           5.2          2.3           6.7          3.0
146  147  Iris-virginica           5.0          1.9           6.3          2.5
147  148  Iris-virginica           5.2          2.0           6.5          3.0
148  149  Iris-virginica           5.4          2.3           6.2          3.4
149  150  Iris-virginica           5.1          1.8           5.9          3.0

[150 rows x 6 columns]
</pre></div>
</div>
</div>
</div>
<section id="berikut-adalah-membandingkan-data-dengan-outliers">
<h2><strong>Berikut adalah Membandingkan Data dengan Outliers‚Ä¶!</strong><a class="headerlink" href="#berikut-adalah-membandingkan-data-dengan-outliers" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import yang diperlukan</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.naive_bayes</span><span class="w"> </span><span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># Membuat DataFrame dengan data yang telah disiapkan</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">151</span><span class="p">),</span>
    <span class="s1">&#39;class&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Iris-setosa&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">50</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;Iris-versicolor&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">50</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;Iris-virginica&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">50</span><span class="p">,</span>
    <span class="s1">&#39;petal_length&#39;</span><span class="p">:</span> <span class="n">filtered_df</span><span class="p">[</span><span class="s1">&#39;petal_length&#39;</span><span class="p">],</span>
    <span class="s1">&#39;petal_width&#39;</span><span class="p">:</span> <span class="n">filtered_df</span><span class="p">[</span><span class="s1">&#39;petal_width&#39;</span><span class="p">],</span>
    <span class="s1">&#39;sepal length&#39;</span><span class="p">:</span> <span class="n">filtered_df</span><span class="p">[</span><span class="s1">&#39;sepal length&#39;</span><span class="p">],</span>
    <span class="s1">&#39;sepal width&#39;</span><span class="p">:</span> <span class="n">filtered_df</span><span class="p">[</span><span class="s1">&#39;sepal width&#39;</span><span class="p">]</span>
<span class="p">})</span>

<span class="c1"># === Data Preprocessing ===</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">])</span>  <span class="c1"># Hapus kolom ID karena tidak diperlukan</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">])</span>  <span class="c1"># Fitur (features)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span>  <span class="c1"># Label (target)</span>

<span class="c1"># === Membagi Data menjadi Training dan Testing (80%-20%) ===</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># === Melatih Model Na√Øve Bayes ===</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># === Prediksi &amp; Evaluasi ===</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Akurasi Model Na√Øve Bayes:&quot;</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Akurasi Model Na√Øve Bayes: 1.0
</pre></div>
</div>
</div>
</div>
</section>
<section id="berikut-adalah-membandingkan-data-tanpa-outliers">
<h2><strong>Berikut adalah Membandingkan Data tanpa Outliers‚Ä¶!</strong><a class="headerlink" href="#berikut-adalah-membandingkan-data-tanpa-outliers" title="Link to this heading">#</a></h2>
<p><strong>A. PROSES FILTERING</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Pastikan kolom &#39;class&#39; ada sebelum menghapusnya</span>
<span class="k">if</span> <span class="s1">&#39;class&#39;</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">])</span>  <span class="c1"># Hapus kolom &#39;class&#39; jika ada</span>

<span class="c1"># LOF untuk mendeteksi outlier</span>
<span class="n">lof_model</span> <span class="o">=</span> <span class="n">LocalOutlierFactor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>

<span class="n">lof_labels</span> <span class="o">=</span> <span class="n">lof_model</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>  <span class="c1"># -1 = outlier, 1 = inlier</span>
<span class="n">lof_values</span> <span class="o">=</span> <span class="o">-</span><span class="n">lof_model</span><span class="o">.</span><span class="n">negative_outlier_factor_</span>

<span class="c1"># Tampilkan LOF dan label untuk setiap data point</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Indeks-</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> ‚Üí LOF: </span><span class="si">{</span><span class="n">lof_values</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Label: </span><span class="si">{</span><span class="s1">&#39;Outlier&#39;</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">lof_labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="o">-</span><span class="mi">1</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;Inlier&#39;</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">filtered_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">lof_labels</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># Hanya simpan data yang bukan outlier</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="nn">&lt;ipython-input-3-cfea163ba081&gt;</span> in <span class="ni">&lt;cell line: 0&gt;</span><span class="nt">()</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> 
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="c1"># LOF untuk mendeteksi outlier</span>
<span class="ne">----&gt; </span><span class="mi">6</span> <span class="n">lof_model</span> <span class="o">=</span> <span class="n">LocalOutlierFactor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span> 
<span class="g g-Whitespace">      </span><span class="mi">8</span> <span class="n">lof_labels</span> <span class="o">=</span> <span class="n">lof_model</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>  <span class="c1"># -1 = outlier, 1 = inlier</span>

<span class="ne">NameError</span>: name &#39;LocalOutlierFactor&#39; is not defined
</pre></div>
</div>
</div>
</div>
<p><strong>B. HASIL DARI NAIVE BAYES :</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.naive_bayes</span><span class="w"> </span><span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="n">filtered_data</span> <span class="o">=</span> <span class="n">filtered_data</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>  <span class="c1"># Hindari efek samping pada DataFrame asli</span>

<span class="n">filtered_data</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">lof_labels</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>  <span class="c1"># Ambil label dari data asli yang bukan outlier</span>

<span class="n">filtered_data</span> <span class="o">=</span> <span class="n">filtered_data</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">filtered_data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">])</span>  <span class="c1"># Hanya fitur</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">filtered_data</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span>  <span class="c1"># Label</span>

<span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">5</span><span class="p">:</span>  <span class="c1"># Jika data terlalu sedikit setelah filtering, tampilkan peringatan</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Data terlalu sedikit setelah menghapus outliers. Coba tingkatkan nilai `n_neighbors` pada LOF.&quot;</span><span class="p">)</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># === 5. Prediksi &amp; Evaluasi ===</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Akurasi Model Na√Øve Bayes setelah menghapus outliers:&quot;</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Akurasi Model Na√Øve Bayes setelah menghapus outliers: 0.9642857142857143
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="berikut-adalah-hasil-dari-perhitungan-pada-contoh">
<h1><strong>Berikut adalah hasil dari perhitungan pada contoh‚Ä¶!</strong><a class="headerlink" href="#berikut-adalah-hasil-dari-perhitungan-pada-contoh" title="Link to this heading">#</a></h1>
<p><strong>1. Dengan Outliers (Akurasi = 1.0)</strong></p>
<p>Ketika model melibatkan data yang mengandung <em>outliers</em>, hasil yang diperoleh bisa sangat baik dalam konteks data uji, bahkan mencapai akurasi sempurna, yaitu <strong>1.0</strong>. Hal ini sering menunjukkan bahwa model sangat cocok dengan data latih yang digunakan.</p>
<p>Namun, meskipun akurasi terlihat tinggi, ini bisa menjadi indikasi bahwa model telah mengalami <strong>overfitting</strong>. <strong>Overfitting</strong> terjadi ketika model ‚Äúterlalu terlatih‚Äù pada data yang ada, termasuk noise atau data yang tidak relevan (outliers), sehingga model sangat peka terhadap data latih tersebut. Akibatnya, model ini mungkin hanya bekerja baik dengan data yang sangat mirip dengan data latih, dan tidak dapat menggeneralisasi dengan baik pada data baru yang belum pernah dilihat sebelumnya.</p>
<p>Sebagai analogi, bayangkan seorang siswa yang selalu mendapatkan nilai sempurna dalam ujian karena hanya menghafal soal-soal yang sering keluar dalam ujian sebelumnya. Meskipun siswa tersebut selalu benar, dia mungkin tidak benar-benar memahami konsep di balik soal-soal tersebut. Jika diberikan soal ujian baru, yang tidak ada dalam soal yang dia hafalkan, siswa tersebut bisa saja gagal.</p>
<p><strong>2. Tanpa Outliers (Akurasi = 0.9643 ‚âà 96.4%)</strong></p>
<p>Saat kita menghapus <strong>outliers</strong> dari dataset, akurasi model biasanya sedikit menurun. Dalam contoh ini, akurasi turun menjadi sekitar <strong>96.4%</strong>, yang menunjukkan penurunan kecil dibandingkan dengan model yang menggunakan outliers. Meskipun demikian, <strong>penurunan akurasi ini</strong> sebenarnya mencerminkan <strong>kinerja yang lebih realistis</strong> dalam dunia nyata.</p>
<p>Dengan menghapus outliers, model menjadi lebih <strong>general</strong> dalam hal <strong>kemampuan memprediksi data baru</strong>. Artinya, model tidak hanya belajar pola yang ada dalam data latih, tetapi juga belajar <strong>hubungan yang lebih luas</strong> antara fitur-fitur tanpa terpengaruh oleh data yang mungkin tidak representatif (outliers).</p>
<p>Model ini lebih stabil dan tidak terlalu terpengaruh oleh data yang ekstrem, yang biasanya tidak sesuai dengan pola umum yang ada dalam data. Dengan kata lain, model lebih cenderung untuk menemukan hubungan yang sesungguhnya antara variabel-variabel dalam data, bukan hanya sekadar ‚Äúmenghafal‚Äù pola yang terlalu spesifik dari data yang mengandung outliers.</p>
<p>Sebagai analogi, ini seperti seorang siswa yang benar-benar memahami konsep ujian dan bisa mengerjakan soal-soal baru yang tidak pernah dilatih sebelumnya, meskipun soal-soal tersebut sedikit berbeda. Walaupun nilai yang didapat sedikit lebih rendah, siswa ini lebih siap menghadapi ujian yang baru.</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="kesimpulan">
<h1><strong>Kesimpulan‚Ä¶!</strong><a class="headerlink" href="#kesimpulan" title="Link to this heading">#</a></h1>
<p>Berdasarkan pengamatan ini, <strong>menghapus outliers sedikit mengurangi akurasi</strong>, tetapi ini adalah langkah yang lebih baik dalam konteks penggunaan dunia nyata. Di dunia nyata, data tidak selalu sempurna, dan kita sering kali menghadapi data yang mengandung noise atau outliers. Dengan menghapus outliers, kita meningkatkan <strong>kemampuan model untuk menggeneralisasi</strong>, sehingga model lebih dapat diandalkan untuk memprediksi data yang belum pernah dilihat sebelumnya.</p>
<p>Namun, <strong>jika tujuan utama model adalah untuk mendeteksi anomali</strong> atau mendeteksi data yang sangat berbeda dari pola normal, maka <strong>mempertahankan outliers</strong> bisa sangat berguna. Dalam hal ini, outliers adalah sesuatu yang ingin kita identifikasi, bukan dihilangkan.</p>
<p><strong>Perumpamaan:</strong></p>
<ul class="simple">
<li><p><strong>Dengan Outlier</strong>: Bayangkan belajar dengan kunci jawaban. Anda bisa mendapatkan nilai ujian yang sempurna, tetapi itu tidak mencerminkan pemahaman yang nyata karena Anda hanya menghafal jawaban tanpa benar-benar memahami materi. Model seperti ini hanya cocok dengan data yang mirip dengan data latih dan bisa gagal dengan data baru yang berbeda.</p></li>
<li><p><strong>Tanpa Outlier</strong>: Ini seperti belajar konsep dengan pemahaman yang dalam. Walaupun mungkin Anda tidak mendapatkan nilai sempurna setiap kali, Anda bisa mengerjakan soal-soal baru dengan baik, meskipun soal tersebut tidak pernah Anda temui sebelumnya. Model ini lebih kuat dalam memprediksi data baru, dan lebih bisa diandalkan dalam dunia nyata.</p></li>
</ul>
<p><strong>Pentingnya Generalisasi</strong>:
Menghapus outliers penting dalam memastikan bahwa model dapat menangani <strong>data baru</strong> dan <strong>beragam</strong>. Model yang mampu menggeneralisasi dengan baik akan lebih tahan terhadap variasi yang muncul di dunia nyata, karena model tidak hanya ‚Äúmenghafal‚Äù data yang ada. Sebaliknya, model yang terlalu terlatih dengan outliers cenderung hanya dapat bekerja dengan data yang sangat mirip dengan yang telah dipelajari, yang dapat membuatnya tidak efektif ketika dihadapkan dengan data baru yang berbeda.</p>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="local_outlier_factor_%28lof%29.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><strong>Local Outlier Factor (LOF)</strong></p>
      </div>
    </a>
    <a class="right-next"
       href="proyek_ujiantengahsemester.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><strong>üìù UTS Penambangan Data - Klasifikasi Prediksi Survival Pasien Sirosis</strong></p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#"><strong>Klasifikasi Naive Bayes</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#apa-itu-naive-bayes"><strong>Apa itu naive bayes‚Ä¶?</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#berikut-adalah-rumus-naive-bayes"><strong>Berikut adalah rumus naive bayes‚Ä¶!</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#contoh-perhitungan"><strong>Contoh Perhitungan</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prior-probabilities"><strong>1. Prior Probabilities</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#likelihood-dengan-laplace-smoothing"><strong>2. Likelihood dengan Laplace Smoothing</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#kalkulasi-probabilitas-naive-bayes"><strong>3. Kalkulasi Probabilitas Na√Øve Bayes</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#jenis-jenis-naive-bayes"><strong>Jenis-Jenis Naive Bayes‚Ä¶!</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#berikut-perbandingan-perhitungan-data-naive-bayes"><strong>Berikut Perbandingan Perhitungan Data Naive Bayes‚Ä¶!</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#berikut-adalah-membandingkan-data-dengan-outliers"><strong>Berikut adalah Membandingkan Data dengan Outliers‚Ä¶!</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#berikut-adalah-membandingkan-data-tanpa-outliers"><strong>Berikut adalah Membandingkan Data tanpa Outliers‚Ä¶!</strong></a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#berikut-adalah-hasil-dari-perhitungan-pada-contoh"><strong>Berikut adalah hasil dari perhitungan pada contoh‚Ä¶!</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#kesimpulan"><strong>Kesimpulan‚Ä¶!</strong></a></li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      ¬© Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>